{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from INRIA import epoching, load_MS, test_pipeline\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.estimation import Covariances\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "import shap\n",
    "mne.set_log_level(verbose=\"Warning\")  # set all the mne verbose to warning\n",
    "\n",
    "seed(2002012)\n",
    "\n",
    "# Deep learning specific parameters\n",
    "input_window_samples = 1024\n",
    "n_epochs = 500\n",
    "n_classes = 2\n",
    "batch_size = 32\n",
    "\n",
    "# dictionary for all our testing pipelines\n",
    "pipelines = {}\n",
    "#pipelines['8csp+lda'] = make_pipeline(CSP(n_components=8), LDA())  # baseline comparison CSP+LDA\n",
    "pipelines['MDM'] = make_pipeline(Covariances(estimator='lwf'), MDM(metric='riemann', n_jobs=-1))  # simple Riemannian\n",
    "#pipelines['tangentspace+LR'] = make_pipeline(Covariances(estimator='lwf'),\n",
    "#                                             TangentSpace(metric='riemann'),\n",
    "#                                             LogisticRegression(max_iter=350, n_jobs=-1))  # more realistic Riemannian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class model_wrapper():  # wrap the SK learn pipeline so that SHAP will play nicely\n",
    "    def __init__(self, X_orig, pipeline):\n",
    "        self.epochs = X_orig.shape[0]  # numer of epochs\n",
    "        self.features = X_orig.shape[1]  # number of features (channels)\n",
    "        self.samples = X_orig.shape[2]  # number of samples\n",
    "        self.classifier = pipeline\n",
    "\n",
    "    def convert_2D_3D(self, X):\n",
    "        # Convert from 2D input (X) into original 3D input (X_orig)\n",
    "        #zeros = np.zeros((self.features-X.shape[1], X.shape[0]))  # calculate how many features are excluded\n",
    "        #X = np.append(X, zeros, axis=1)  # pad all excluded features with zeros\n",
    "        return np.reshape(X, (self.epochs, X.shape[1], self.samples)).transpose((1,0))  # undo the transpose as well\n",
    "\n",
    "    \"\"\"\n",
    "    Below we wrap all the sklearn functions that SHAP uses to accept either 2D OR 3D input,\n",
    "    rather than just 2D input. If the input is 2D, we change it to 3D. If it's 3D, we leave it.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if len(X.shape) == 2:\n",
    "            return self.classifier.fit(self.convert_2D_3D(X), y, **fit_params)\n",
    "        else:\n",
    "            return self.classifier.fit(X, y, **fit_params)\n",
    "\n",
    "    def transform(self, X):\n",
    "        if len(X.shape) == 2:\n",
    "            return self.classifier.transform(self.convert_2D_3D(X))\n",
    "        else:\n",
    "            return self.classifier.transform(X)\n",
    "\n",
    "    def predict(self, X, **predict_params):\n",
    "        if len(X.shape) == 2:\n",
    "            return self.classifier.predict(self.convert_2D_3D(X), **predict_params)\n",
    "        else:\n",
    "            return self.classifier.predict(X, **predict_params)\n",
    "\n",
    "    def predict_log_proba(self, X, **predict_log_proba_params):\n",
    "        if len(X.shape) == 2:\n",
    "            return self.classifier.predict_log_proba(self.convert_2D_3D(X), **predict_log_proba_params)\n",
    "        else:\n",
    "            return self.classifier.predict_log_proba(X, **predict_log_proba_params)\n",
    "\n",
    "    def predict_proba(self, X, **predict_proba_params):\n",
    "        if len(X.shape) == 2:\n",
    "            return self.classifier.predict_proba(self.convert_2D_3D(X), **predict_proba_params)\n",
    "        else:\n",
    "            return self.classifier.predict_proba(X, **predict_proba_params)\n",
    "\n",
    "    def score(self, X, y=None, sample_weight=None):\n",
    "        if len(X.shape) == 2:\n",
    "            return self.classifier.score(self.convert_2D_3D(X), y, sample_weight)\n",
    "        else:\n",
    "            return self.classifier.score(X, y, sample_weight)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def preprocess(raw, steps={}):\n",
    "    print(\"Preprocessing raw data...\")  # for progress tracking\n",
    "    \"\"\" preprocess the data\"\"\"\n",
    "    assert isinstance(steps, dict), \"steps must be a dictionary\"\n",
    "    raw.load_data()\n",
    "    if \"drop_channels\" in steps.keys():\n",
    "        # remove the wanted channels\n",
    "        for channel in steps[\"drop_channels\"]:  # for each channel to be dropped...\n",
    "            if channel in raw.ch_names:  # ensure that it is actually a channel in the data\n",
    "                raw.drop_channels(channel)\n",
    "\n",
    "    if \"filter\" in steps.keys():\n",
    "        assert isinstance(steps[\"filter\"], list), \"filter parameters must be a list in the form [l_freq,h_freq]\"\n",
    "        raw.filter(steps[\"filter\"][0], steps[\"filter\"][1])\n",
    "\n",
    "    return raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def epoching(dict, key_session=[], steps_preprocess=None, key_events={\"769\": 0, \"770\": 1}):\n",
    "    print(\"Epoching the data...\")  # for progress tracking\n",
    "    # we are epoching for the RG classifiers\n",
    "    \"\"\"From the dictionary of mne.rawGDF extract all the epochs selected with Key_session\n",
    "     Return the epochs list as X and the label as Y\"\"\"\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    tmin = steps_preprocess[\"tmin\"]\n",
    "    tmax = steps_preprocess[\"tmax\"]\n",
    "    length_epoch = steps_preprocess[\"length\"]\n",
    "    overlap = steps_preprocess[\"overlap\"]\n",
    "    # ---------------------------------------------\n",
    "    X = None\n",
    "    Y = None\n",
    "\n",
    "    for key in key_session:\n",
    "        if steps_preprocess is not None:\n",
    "            _ = preprocess(dict[key], steps_preprocess)\n",
    "\n",
    "        # MNE recommends the following process prior to signal decimation:\n",
    "        current_sfreq = dict[key].info['sfreq']\n",
    "        desired_sfreq = 256  # Hz\n",
    "        decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "        obtained_sfreq = current_sfreq / decim\n",
    "        lowpass_freq = obtained_sfreq / 3.0\n",
    "        dict[key].filter(l_freq=None, h_freq=lowpass_freq, n_jobs=-1)\n",
    "\n",
    "        epoch = mne.Epochs(dict[key], mne.events_from_annotations(dict[key], key_events)[0], tmin=-1, tmax=5,\n",
    "                           baseline=(None, 0), verbose=\"CRITICAL\", decim=decim)[list(key_events.values())]\n",
    "        # NOTE: we are decimating the signal to 256 Hz and only grabbing 2 events to speed up processing\n",
    "\n",
    "        list_start = np.arange(tmin, (tmax + overlap) - length_epoch, overlap)\n",
    "        list_stop = np.arange(tmin + length_epoch, (tmax + overlap), overlap)\n",
    "\n",
    "        for start, stop in zip(list_start, list_stop):\n",
    "            if X is None:\n",
    "                X = epoch.get_data(tmin=start, tmax=stop)\n",
    "                Y = epoch.events[:, 2]\n",
    "\n",
    "            else:\n",
    "                X = np.append(X, epoch.get_data(tmin=start, tmax=stop), axis=0)\n",
    "                Y = np.append(Y, epoch.events[:, 2], axis=0)\n",
    "\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test_pipeline(test, pipelines, session, steps_preprocess):\n",
    "    \"\"\" Take in input the different pipelines to test and return the corresponding classification accuracy\"\"\"\n",
    "    accuracy = pd.DataFrame(np.zeros((len(session), len(pipelines))), index=session, columns=pipelines.keys())\n",
    "\n",
    "    for subject in session:  # this will be something like \"A10\" for MS and \"S06_S1\" for SS\n",
    "        print(\"Running a leave-one-out classification, leaving out every MS subject one at a time...\")  # for progress tracking\n",
    "        train_key = {k: v for k, v in test.items() if subject not in k}  # train on all subjects data EXCEPT one\n",
    "        test_key = {k: v for k, v in test.items() if subject in k}  # test on that subject\n",
    "\n",
    "        X_train, Y_train = epoching(test, train_key, steps_preprocess)  # X = epochs, Y = labels\n",
    "        X_test, Y_test = epoching(test, test_key, steps_preprocess)  # same as above, but test set\n",
    "\n",
    "        for classifier in pipelines.keys():\n",
    "            pipelines[classifier].fit(X_train, Y_train)\n",
    "\n",
    "            if steps_preprocess[\"score\"] == \"TAcc\":\n",
    "\n",
    "                # ---------------------------------------------\n",
    "                tmin = steps_preprocess[\"tmin\"]\n",
    "                tmax = steps_preprocess[\"tmax\"]\n",
    "                length_epoch = steps_preprocess[\"length\"]\n",
    "                overlap = steps_preprocess[\"overlap\"]\n",
    "                # ---------------------------------------------\n",
    "                dist = len(np.arange(tmin, (tmax + overlap) - length_epoch, overlap))\n",
    "\n",
    "                X_estim = pipelines[classifier].transform(X_test)\n",
    "\n",
    "                X_estim_reshape = X_estim.reshape((-1, dist))\n",
    "                X_sum = X_estim_reshape.sum(axis=0)\n",
    "\n",
    "                trial_predict = np.where(X_sum < 0, 0, 1)  # if the sum < 0, left. If >0, predict right\n",
    "                temporary_accuracy = np.where(trial_predict == Y_test[0::dist - 1], 1,\n",
    "                                              0)  # Compare predictions with observations\n",
    "\n",
    "                accuracy[classifier][subject] = temporary_accuracy.mean()\n",
    "\n",
    "            elif steps_preprocess[\"score\"] == \"EAcc\":\n",
    "                try:\n",
    "                    accuracy[classifier][subject] = pipelines[classifier].score(X_test, Y_test)\n",
    "                except:\n",
    "                    accuracy[classifier][subject] = np.nan\n",
    "            elif steps_preprocess[\"score\"] == \"SHAP\":\n",
    "                # convert X_train/X_test to 2D so SHAP doesn't complain\n",
    "                # (492, 27, 256) -> (27, 125952) -> (125952, 27)\n",
    "                test_data = np.reshape(X_test, (X_test.shape[1], X_test.shape[0]*X_test.shape[2])).transpose((1,0))\n",
    "                # wrap pipeline to automatically switch from 2D to 3D data when needed\n",
    "                model = model_wrapper(X_test, pipelines[classifier])\n",
    "\n",
    "                explainer = shap.KernelExplainer(model.predict, X_train, link=\"logit\")\n",
    "                shap_values_single = explainer.shap_values(test_data, nsamples = 100)\n",
    "                accuracy[classifier][subject] = shap_values_single\n",
    "            else:\n",
    "                raise AttributeError(\"The chosen score does not exist!\")\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load_MS(between=False, within=False):\n",
    "    print(\"Loading the MS dataset (all subjects that are available)...\")  # for progress tracking\n",
    "    # Establish master data path\n",
    "    path = os.path.join(\"Data\", \"MS\")\n",
    "\n",
    "    # Load all files for a given range of participants\n",
    "    # Format: [SUB]_[RUN_NAME].gdf\n",
    "\n",
    "    runNames = [\"CE_baseline\", \"OE_baseline\", \"R1_acquisition\", \"R2_acquisition\",\n",
    "                \"R3_onlineT\", \"R4_onlineT\", \"R5_onlineT\",\n",
    "                \"R6_onlineT\"]  # run IDs: CE/OE = closed/open eyes, RX = run #X\n",
    "    subA = [\"A\" + str(i) for i in range(1, 61)]  # 60 participants (Dataset A ; 29 women ; age 19-59, M = 29, SD = 9.32)\n",
    "    subB = [\"B\" + str(i) for i in\n",
    "            range(61, 82)]  # 21 participants (Dataset B ; 8 women ; age 19-37, M = 29, SD = 9.318)\n",
    "    subC = [\"C\" + str(i) for i in\n",
    "            range(82, 88)]  # 6 additional participants (Dataset C; 4 women; age 20-26, M=22; SD=2.34)\n",
    "    subjects = subA + subB + subC\n",
    "    # Note that all data followed the same EEG protocol (MI of left and right hand) with the same channel information\n",
    "\n",
    "    data = {}  # dictionary to hold all our data\n",
    "    for sub in subjects:  # for each subject...\n",
    "        skip = False\n",
    "        fnames = [sub + \"_\" + i + \".gdf\" for i in runNames]  # develop a list of all filenames\n",
    "        sub_data = []  # empty list to hold all of a subject's loaded files\n",
    "        for f in fnames:  # for each file...\n",
    "            fpath = os.path.join(path, sub, f)  # select the correct file\n",
    "            try:\n",
    "                sub_data.append(mne.io.read_raw_gdf(fpath))  # load it into the list\n",
    "            except FileNotFoundError:\n",
    "                skip = True  # if all GDF files are not available, skip this subject (for testing purposes only)\n",
    "        if not skip:\n",
    "            # correct channel type information (to properly label EOG and EMG channels)\n",
    "            new_types = []  # create a new channel types array\n",
    "            for i in sub_data:\n",
    "                for j in i.ch_names:\n",
    "                    if \"EOG\" in j:  # mark ECOG channels\n",
    "                        new_types.append(\"ecog\")\n",
    "                    elif \"EMG\" in j:  # mark EMG channels\n",
    "                        new_types.append(\"emg\")\n",
    "                    else:  # mark the rest as regular EEG\n",
    "                        new_types.append(\"eeg\")\n",
    "                i.set_channel_types(dict(zip(i.ch_names, new_types)))  # apply new channel types to raw object\n",
    "\n",
    "                print(i.ch_names)\n",
    "\n",
    "            data[sub] = sub_data  # save sub_data list into data dictionary\n",
    "\n",
    "    # Current data format: data[subject] holds all 8 raw objects\n",
    "    # data[subject][0] = Closed eyes baseline\n",
    "    # data[subject][1] = Open eyes baseline\n",
    "    # data[subject][2] = Training session 1\n",
    "    # data[subject][3] = Training session 2\n",
    "    # data[subject][4] = Test session 1 (w/ feedback)\n",
    "    # data[subject][5] = Test session 2 (w/ feedback)\n",
    "    # data[subject][6] = Test session 3 (w/ feedback)\n",
    "    # data[subject][7] = Test session 4 (w/ feedback)\n",
    "\n",
    "    if between:\n",
    "        # dic_data_format = participant number (+ _N for train) (+ _N++ for test) : mne raw object\n",
    "        dic_data = {}\n",
    "        for i in data.keys():  # for every subject...\n",
    "            for j in range(1, 7):\n",
    "                session = str(i) + '_' + str(j)\n",
    "                dic_data[session] = data[i][j + 1]  # place their sessions into one dictionary following indexes above\n",
    "        return data, dic_data\n",
    "    if within:\n",
    "        dic_data_train = {}\n",
    "        dic_data_test = {}\n",
    "        for i in data.keys():  # for every subject...\n",
    "            for j in range(1, 3):  # place their training sessions into one dictionary\n",
    "                session = str(i) + '_' + str(j)\n",
    "                dic_data_train[session] = data[i][j + 1]  # following the indexes from the comment above\n",
    "            for j in range(3, 7):  # and their testing sessions into another dictionary\n",
    "                session = str(i) + '_' + str(j)\n",
    "                dic_data_test[session] = data[i][j + 1]  # with the same indexing as the comment block above\n",
    "        return data, dic_data_train, dic_data_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def MS_RG_Between():\n",
    "    # load the MS dataset\n",
    "    data, dic_data = load_MS(between=True)\n",
    "\n",
    "    # run the selected pipelines\n",
    "    session = list(data.keys())  # a list of participants to be used for analysis\n",
    "    steps_preprocess = {\"filter\": [8, 30],  # filter from 8-30Hz\n",
    "                        \"drop_channels\": ['EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd'],  # ignore EOG/EMG channels\n",
    "                        \"tmin\": 0.5, \"tmax\": 4, \"overlap\": 1/16, \"length\": 1,\n",
    "                        \"score\": \"SHAP\"}\n",
    "    accuracy = test_pipeline(dic_data, pipelines, session, steps_preprocess)  # run it!\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the MS dataset (all subjects that are available)...\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n",
      "Running a leave-one-out classification, leaving out every MS subject one at a time...\n",
      "Epoching the data...\n",
      "Preprocessing raw data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mMS_RG_Between\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [7], line 11\u001B[0m, in \u001B[0;36mMS_RG_Between\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(data\u001B[38;5;241m.\u001B[39mkeys())  \u001B[38;5;66;03m# a list of participants to be used for analysis\u001B[39;00m\n\u001B[0;32m      7\u001B[0m steps_preprocess \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilter\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m30\u001B[39m],  \u001B[38;5;66;03m# filter from 8-30Hz\u001B[39;00m\n\u001B[0;32m      8\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdrop_channels\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEOG1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEOG2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEOG3\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEMGg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEMGd\u001B[39m\u001B[38;5;124m'\u001B[39m],  \u001B[38;5;66;03m# ignore EOG/EMG channels\u001B[39;00m\n\u001B[0;32m      9\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtmin\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtmax\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverlap\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m16\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlength\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     10\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSHAP\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m---> 11\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtest_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdic_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipelines\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_preprocess\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# run it!\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m accuracy\n",
      "Cell \u001B[1;32mIn [5], line 10\u001B[0m, in \u001B[0;36mtest_pipeline\u001B[1;34m(test, pipelines, session, steps_preprocess)\u001B[0m\n\u001B[0;32m      7\u001B[0m train_key \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m test\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m subject \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m k}  \u001B[38;5;66;03m# train on all subjects data EXCEPT one\u001B[39;00m\n\u001B[0;32m      8\u001B[0m test_key \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m test\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m subject \u001B[38;5;129;01min\u001B[39;00m k}  \u001B[38;5;66;03m# test on that subject\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m X_train, Y_train \u001B[38;5;241m=\u001B[39m \u001B[43mepoching\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_key\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_preprocess\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# X = epochs, Y = labels\u001B[39;00m\n\u001B[0;32m     11\u001B[0m X_test, Y_test \u001B[38;5;241m=\u001B[39m epoching(test, test_key, steps_preprocess)  \u001B[38;5;66;03m# same as above, but test set\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m classifier \u001B[38;5;129;01min\u001B[39;00m pipelines\u001B[38;5;241m.\u001B[39mkeys():\n",
      "Cell \u001B[1;32mIn [4], line 26\u001B[0m, in \u001B[0;36mepoching\u001B[1;34m(dict, key_session, steps_preprocess, key_events)\u001B[0m\n\u001B[0;32m     24\u001B[0m obtained_sfreq \u001B[38;5;241m=\u001B[39m current_sfreq \u001B[38;5;241m/\u001B[39m decim\n\u001B[0;32m     25\u001B[0m lowpass_freq \u001B[38;5;241m=\u001B[39m obtained_sfreq \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3.0\u001B[39m\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlowpass_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m epoch \u001B[38;5;241m=\u001B[39m mne\u001B[38;5;241m.\u001B[39mEpochs(\u001B[38;5;28mdict\u001B[39m[key], mne\u001B[38;5;241m.\u001B[39mevents_from_annotations(\u001B[38;5;28mdict\u001B[39m[key], key_events)[\u001B[38;5;241m0\u001B[39m], tmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, tmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,\n\u001B[0;32m     29\u001B[0m                    baseline\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m0\u001B[39m), verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCRITICAL\u001B[39m\u001B[38;5;124m\"\u001B[39m, decim\u001B[38;5;241m=\u001B[39mdecim)[\u001B[38;5;28mlist\u001B[39m(key_events\u001B[38;5;241m.\u001B[39mvalues())]\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# NOTE: we are decimating the signal to 256 Hz and only grabbing 2 events to speed up processing\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\mne\\io\\base.py:976\u001B[0m, in \u001B[0;36mBaseRaw.filter\u001B[1;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001B[0m\n\u001B[0;32m    969\u001B[0m \u001B[38;5;129m@copy_doc\u001B[39m(FilterMixin\u001B[38;5;241m.\u001B[39mfilter)\n\u001B[0;32m    970\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfilter\u001B[39m(\u001B[38;5;28mself\u001B[39m, l_freq, h_freq, picks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, filter_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    971\u001B[0m            l_trans_bandwidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, h_trans_bandwidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    974\u001B[0m            skip_by_annotation\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbad_acq_skip\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m    975\u001B[0m            pad\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreflect_limited\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# noqa: D102\u001B[39;00m\n\u001B[1;32m--> 976\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpicks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilter_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml_trans_bandwidth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43mh_trans_bandwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[43miir_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miir_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mphase\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mphase\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfir_window\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfir_window\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfir_design\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfir_design\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_by_annotation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_by_annotation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<decorator-gen-119>:12\u001B[0m, in \u001B[0;36mfilter\u001B[1;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\mne\\filter.py:2023\u001B[0m, in \u001B[0;36mFilterMixin.filter\u001B[1;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001B[0m\n\u001B[0;32m   2019\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m si, (start, stop) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(onsets, ends)):\n\u001B[0;32m   2020\u001B[0m     \u001B[38;5;66;03m# Only output filter params once (for info level), and only warn\u001B[39;00m\n\u001B[0;32m   2021\u001B[0m     \u001B[38;5;66;03m# once about the length criterion (longest segment is too short)\u001B[39;00m\n\u001B[0;32m   2022\u001B[0m     use_verbose \u001B[38;5;241m=\u001B[39m verbose \u001B[38;5;28;01mif\u001B[39;00m si \u001B[38;5;241m==\u001B[39m max_idx \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m-> 2023\u001B[0m     \u001B[43mfilter_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2024\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m:\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msfreq\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2025\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpicks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilter_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml_trans_bandwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_trans_bandwidth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2026\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miir_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mphase\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mphase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2027\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfir_window\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfir_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfir_design\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfir_design\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2028\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_verbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2029\u001B[0m \u001B[38;5;66;03m# update info if filter is applied to all data channels,\u001B[39;00m\n\u001B[0;32m   2030\u001B[0m \u001B[38;5;66;03m# and it's not a band-stop filter\u001B[39;00m\n\u001B[0;32m   2031\u001B[0m _filt_update_info(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo, update_info, l_freq, h_freq)\n",
      "File \u001B[1;32m<decorator-gen-114>:12\u001B[0m, in \u001B[0;36mfilter_data\u001B[1;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\mne\\filter.py:817\u001B[0m, in \u001B[0;36mfilter_data\u001B[1;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001B[0m\n\u001B[0;32m    813\u001B[0m filt \u001B[38;5;241m=\u001B[39m create_filter(\n\u001B[0;32m    814\u001B[0m     data, sfreq, l_freq, h_freq, filter_length, l_trans_bandwidth,\n\u001B[0;32m    815\u001B[0m     h_trans_bandwidth, method, iir_params, phase, fir_window, fir_design)\n\u001B[0;32m    816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfir\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfft\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 817\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43m_overlap_add_filter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mphase\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpicks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    818\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    820\u001B[0m     data \u001B[38;5;241m=\u001B[39m _filtfilt(data, filt, picks, n_jobs, copy)\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\mne\\filter.py:209\u001B[0m, in \u001B[0;36m_overlap_add_filter\u001B[1;34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001B[0m\n\u001B[0;32m    206\u001B[0m         x[p] \u001B[38;5;241m=\u001B[39m _1d_overlap_filter(x[p], \u001B[38;5;28mlen\u001B[39m(h), n_edge, phase,\n\u001B[0;32m    207\u001B[0m                                   cuda_dict, pad, n_fft)\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 209\u001B[0m     data_new \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43mp\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_edge\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mphase\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mcuda_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_fft\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpicks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m pp, p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(picks):\n\u001B[0;32m    212\u001B[0m         x[p] \u001B[38;5;241m=\u001B[39m data_new[pp]\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\joblib\\parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\joblib\\parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[1;32m~\\PycharmProjects\\X-Riemannian\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[0;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[0;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "accuracy = MS_RG_Between()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}