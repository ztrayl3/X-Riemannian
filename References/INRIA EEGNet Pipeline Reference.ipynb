{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras.metrics\n",
    "import mne\n",
    "import os\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import winsound\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "#from EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "mne.set_log_level(verbose=\"Warning\") # set all the mne verbose to warning\n",
    "\n",
    "seed(2002012)\n",
    "set_random_seed(2002012)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have succesfuly acces to the directory :  C:\\Users\\dtrocell\\Documents\\ML\\Big dataset\\signal\n"
     ]
    }
   ],
   "source": [
    "#init_path = \"\\\\\\\\bor-nas1.bordeaux.inria.fr\\\\potiocdata\\BCI\\\\2022 BCI OPEN DATA\\\\BCI Database - Copie\\\\Signals\"\n",
    "init_path = \"C:\\\\Users\\dtrocell\\Documents\\ML\\Big dataset\\signal\"\n",
    "files_dir=os.listdir(init_path)[1:4]\n",
    "participant_dir= [os.listdir(osp.join(init_path,files_dir[i])) for i in range(len(files_dir))]\n",
    "print(\"you have succesfuly acces to the directory : \",init_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "participant_dir[0].remove(\"A40\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def collect_data(files_dir, participant_dir):\n",
    "    dic_data={}\n",
    "\n",
    "    for i in range(len(files_dir)):\n",
    "        for j in range(len(participant_dir[i])):\n",
    "            #Train dataset\n",
    "            dic_data[participant_dir[i][j]+\"_1\"]= mne.io.read_raw_gdf(osp.join(init_path,files_dir[i],participant_dir[i][j],participant_dir[i][j]+\"_R1_acquisition.gdf\"), verbose=\"CRITICAL\")\n",
    "            dic_data[participant_dir[i][j]+\"_2\"]= mne.io.read_raw_gdf(osp.join(init_path,files_dir[i],participant_dir[i][j],participant_dir[i][j]+\"_R2_acquisition.gdf\"), verbose=\"CRITICAL\")\n",
    "\n",
    "            #Test dataset\n",
    "            dic_data[participant_dir[i][j]+\"_3\"]= mne.io.read_raw_gdf(osp.join(init_path,files_dir[i],participant_dir[i][j],participant_dir[i][j]+\"_R3_onlineT.gdf\"), verbose=\"CRITICAL\")\n",
    "            dic_data[participant_dir[i][j]+\"_4\"]= mne.io.read_raw_gdf(osp.join(init_path,files_dir[i],participant_dir[i][j],participant_dir[i][j]+\"_R4_onlineT.gdf\"), verbose=\"CRITICAL\")\n",
    "            try : # allow to manage the one where there is no _5 and _6 files\n",
    "                dic_data[participant_dir[i][j]+\"_5\"]= mne.io.read_raw_gdf(osp.join(init_path,files_dir[i],participant_dir[i][j],participant_dir[i][j]+\"_R5_onlineT.gdf\"), verbose=\"CRITICAL\")\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            try :\n",
    "                dic_data[participant_dir[i][j]+\"_6\"]= mne.io.read_raw_gdf(osp.join(init_path,files_dir[i],participant_dir[i][j],participant_dir[i][j]+\"_R6_onlineT.gdf\"), verbose=\"CRITICAL\")\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "    return dic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START extraction data\n",
      "extraction data DONE\n"
     ]
    }
   ],
   "source": [
    "print(\"START extraction data\")\n",
    "dic_data =  collect_data(files_dir, participant_dir)\n",
    "print(\"extraction data DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def create_key(df , train = 1 , test = 1 ):\n",
    "\n",
    "    if \"A59\" in df :\n",
    "        keys = np.empty(shape= len(df) * train *2 + (len(df) * test * 4) -2*test ,  dtype=  np.dtype('<U8'))\n",
    "    else :\n",
    "        keys = np.empty(shape= len(df) * train *2 + (len(df) * test * 4) ,  dtype=  np.dtype('<U8'))\n",
    "    i = 0\n",
    "    for  val  in df :\n",
    "        if train :\n",
    "            keys[i : i+2] = [val+\"_1\" ,val+\"_2\"]\n",
    "            i += 2\n",
    "        if test :\n",
    "            if val == \"A59\":\n",
    "                keys[i : i+2] =  [val+\"_3\" ,val+\"_4\"]\n",
    "                i+= 2\n",
    "            else :\n",
    "                keys[i : i+4] =  [val+\"_3\" ,val+\"_4\",  val+\"_5\", val+\"_6\"]\n",
    "                i+=4\n",
    "\n",
    "    return keys\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(raw, steps = {}):\n",
    "    \"\"\" preprocess the data\"\"\"\n",
    "    assert isinstance(steps, dict), \"les steps doivent être un dictionnaire d'étapes\"\n",
    "    raw.load_data()\n",
    "    if \"drop_channels\" in steps.keys():\n",
    "        #remove the wanted channels\n",
    "        for channel in steps[\"drop_channels\"] : #Pour chaque channel  a supprimer\n",
    "            if channel in raw.ch_names: raw.drop_channels(channel) # Vérifie qu'il est present et le supprime\n",
    "\n",
    "    if \"filter\" in steps.keys():\n",
    "        assert isinstance(steps[\"filter\"], list), \"les paramètres de 'filter' doivent une liste suivant cette forme [l_freq,h_freq]\"\n",
    "        raw.filter(steps[\"filter\"][0], steps[\"filter\"][1], verbose= None)\n",
    "\n",
    "\n",
    "    return raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def epoching(dict, key_session =[], steps_preprocess = None , key_events={\"769\":0 ,\"770\":1}) :\n",
    "    \"\"\"From the dictionary of mne.rawGDF extract all the epochs selected with Key_session\n",
    "     Return the epochs list as X and tje label as Y\"\"\"\n",
    "\n",
    "    #---------------------------------------------\n",
    "    tmin= steps_preprocess[\"tmin\"]\n",
    "    tmax = steps_preprocess[\"tmax\"]\n",
    "    length_epoch = steps_preprocess[\"lenght\"]\n",
    "    overlap = steps_preprocess[\"overlap\"]\n",
    "    #---------------------------------------------\n",
    "\n",
    "    list_start = np.arange(tmin, (tmax +overlap)- length_epoch, overlap)\n",
    "    list_stop = np.arange(tmin+length_epoch, (tmax+overlap), overlap)\n",
    "\n",
    "    #n_chans = len(dict[key_session[0]].ch_names) - len(steps_preprocess[\"drop_channels\"])\n",
    "    n_chans = 27 # must be changed if we drop more channels\n",
    "    time_step = int(length_epoch  * dict[key_session[0]].info['sfreq'])\n",
    "    n_events = len(list_start)* 40 * len(key_session) # 40 represent the number of events in each raw data\n",
    "\n",
    "    X= np.zeros((n_events, n_chans, time_step))\n",
    "    Y= np.zeros((n_events))\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #for key in tqdm(key_session , desc=\"epoching\"):\n",
    "    for key in key_session :\n",
    "\n",
    "        if steps_preprocess is not None :\n",
    "            _ =  preprocess(dict[key],steps_preprocess)\n",
    "\n",
    "        epoch= mne.Epochs(dict[key], mne.events_from_annotations(dict[key],key_events)[0], tmin= -1 , tmax= 5 , baseline=(None, 0))\n",
    "\n",
    "        assert len(epoch.events[:,2]) == 40, ( \"'%s' don't have 40 events it actually have %s \" % (key , len(epoch.events[:,2])) )\n",
    "\n",
    "\n",
    "        for start, stop in zip(list_start, list_stop):\n",
    "\n",
    "            X[i : i +40 ] = epoch.get_data(tmin=start , tmax=stop)\n",
    "            Y[i : i +40 ] = epoch.events[:,2]\n",
    "            i += 40\n",
    "\n",
    "    Y = one_hot(Y , depth= 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return X,Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfert Learning RPA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data extraction and split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtrocell\\AppData\\Local\\Temp\\ipykernel_32756\\221401765.py:25: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  data =data.drop([\"A40\" , \"A59\"], axis=0)\n"
     ]
    }
   ],
   "source": [
    "inline_accuracy = [84.375, 55.625, 98.125, 51.25, 51.25, 65.625, 47.5, 56.225, 66.25, 82.5, 51.875, 60, 65, 49.375,\n",
    "                   75.625, 49.375, 45.625, 82.5, 98.125, 83.125, 56.875, 88.75, 51.875, 93.125, 81.25, 65.625, 45.625,\n",
    "                   48.125, 52.5, 40.625, 52.5, 55.5, 62.5, 48.125, 90.625, 70, 47.5, 62.5, 81.25, 49.0625, 51.875,\n",
    "                   51.875, 55, 56.25, 54.375, 54.375, 46.25, 56.625, 55, 52.5, 64.375, 88.75, 46.25, 47.5, 91.875,\n",
    "                   99.375, 48.75, 66.25, 60, 56.25, 84.375, 90.625, 60, 50, 82.5, 58.75, 51.875, 55, 60.625, 55.625,\n",
    "                   47.5, 44.375, 86.25, 68.125, 71.875, 80.625, 53.75, 55, 97.5, 49.375, 55, 49.375, 44.375, 76.25,\n",
    "                   80.625, 62.5, 73.125]\n",
    "\n",
    "inline_order = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\",\n",
    "                \"A17\", \"A18\", \"A19\", \"A20\", \"A21\", \"A22\", \"A23\", \"A24\", \"A25\", \"A26\", \"A27\", \"A28\", \"A29\", \"A30\", \"A31\",\n",
    "                \"A32\", \"A33\", \"A34\", \"A35\", \"A36\", \"A37\", \"A38\", \"A39\", \"A40\", \"A41\", \"A42\", \"A43\", \"A44\", \"A45\", \"A46\",\n",
    "                \"A47\", \"A48\", \"A49\", \"A50\", \"A51\", \"A52\", \"A53\", \"A54\", \"A55\", \"A56\", \"A57\", \"A58\", \"A59\", \"A60\", \"B61\",\n",
    "                \"B62\", \"B63\", \"B64\", \"B65\", \"B66\", \"B67\", \"B68\", \"B69\", \"B70\", \"B71\", \"B72\", \"B73\", \"B74\", \"B75\", \"B76\",\n",
    "                \"B77\", \"B78\", \"B79\", \"B80\", \"B81\", \"C82\", \"C83\", \"C84\", \"C85\", \"C86\", \"C87\"]\n",
    "\n",
    "inline_age = [1993, 1993, 1969, 1982, 1985, 1970, 1997, 1992, 1996, 1997, 1997, 1993, 1997, 1994, 1988, 1996, 1997,\n",
    "              1995, 1985, 1996, 1988, 1989, 1994, 1985, 1999, 1998, 1981, 1995, 1997, 1996, 1978, 1969, 1992, 1993,\n",
    "              1993, 1990, 1959, 1973, 1996, 1999, 1989, 1994, 1980, 1988, 1977, 1993, 1990, 1997, 1981, 1997, 1975,\n",
    "              1997, 1991, 1989, 1996, 1998, 1996, 1996, 1991, 1968, 1992, 2002, 2000, 1985, 1998, 1979, 1978, 1999,\n",
    "              1984, 1998, 1997, 1993, 1969, 1996, 1998, 1998, 1978, 1999, 1994, 1995, 1997, 1995, 1997, 2001, 1991,\n",
    "              2000, 2000]\n",
    "\n",
    "data = pd.DataFrame({\"accuracy\": inline_accuracy, \"age\": inline_age}, index=[inline_order])\n",
    "data[\"age\"] = 2021 - data[\"age\"]\n",
    "data =data.drop([\"A40\" , \"A59\"], axis=0)\n",
    "\n",
    "age_cat = [(19,23), (23, 24), (24, 27), (27,30), (30,40), (40, 62)]\n",
    "dict_age = {}\n",
    "for age_min, age_max in age_cat:\n",
    "\n",
    "     dict_age[(age_min, age_max)] = [x[0] for x in data[np.logical_and(data[\"age\"] > age_min, data[\"age\"] <= age_max)].index]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "#\n",
    "# train_gen = DataGenerator(X_train, Y_train, 64)\n",
    "# valid_train_gen = DataGenerator(X_valid_train, Y_valid_train, 64)\n",
    "# valid_test_gen = DataGenerator(X_valid_test, Y_valid_test, 64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EEG NET"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model extracted from this article : https://iopscience.iop.org/article/10.1088/1741-2552/aace8c/pdf.  Vernon J Lawhern et al."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "def EEGNet(nb_classes, Chans = 64, Samples = 128,\n",
    "           dropoutRate = 0.25, kernLength = 64, F1 = 8,\n",
    "           D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'SpatialDropout2D'):\n",
    "    \"\"\" Keras Implementation of EEGNet\n",
    "    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n",
    "    Note that this implements the newest version of EEGNet and NOT the earlier\n",
    "    version (version v1 and v2 on arxiv). We strongly recommend using this\n",
    "    architecture as it performs much better and has nicer properties than\n",
    "    our earlier version. For example:\n",
    "\n",
    "        1. Depthwise Convolutions to learn spatial filters within a\n",
    "        temporal convolution. The use of the depth_multiplier option maps\n",
    "        exactly to the number of spatial filters learned within a temporal\n",
    "        filter. This matches the setup of algorithms like FBCSP which learn\n",
    "        spatial filters within each filter in a filter-bank. This also limits\n",
    "        the number of free parameters to fit when compared to a fully-connected\n",
    "        convolution.\n",
    "\n",
    "        2. Separable Convolutions to learn how to optimally combine spatial\n",
    "        filters across temporal bands. Separable Convolutions are Depthwise\n",
    "        Convolutions followed by (1x1) Pointwise Convolutions.\n",
    "\n",
    "\n",
    "    While the original paper used Dropout, we found that SpatialDropout2D\n",
    "    sometimes produced slightly better results for classification of ERP\n",
    "    signals. However, SpatialDropout2D significantly reduced performance\n",
    "    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n",
    "    the default Dropout in most cases.\n",
    "\n",
    "    Assumes the input signal is sampled at 128Hz. If you want to use this model\n",
    "    for any other sampling rate you will need to modify the lengths of temporal\n",
    "    kernels and average pooling size in blocks 1 and 2 as needed (double the\n",
    "    kernel lengths for double the sampling rate, etc). Note that we haven't\n",
    "    tested the model performance with this rule so this may not work well.\n",
    "\n",
    "    The model with default parameters gives the EEGNet-8,2 model as discussed\n",
    "    in the paper. This model should do pretty well in general, although it is\n",
    "\tadvised to do some model searching to get optimal performance on your\n",
    "\tparticular dataset.\n",
    "    We set F2 = F1 * D (number of input filters = number of output filters) for\n",
    "    the SeparableConv2D layer. We haven't extensively tested other values of this\n",
    "    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n",
    "    overcomplete). We believe the main parameters to focus on are F1 and D.\n",
    "    Inputs:\n",
    "\n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.\n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D.\n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                          input_shape = (Chans, Samples, 1),\n",
    "                          use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "\n",
    "    dense        = Dense(nb_classes, name = 'dense',\n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "n_chans = 27\n",
    "input_window_samples = 1024\n",
    "# sfreq = dic_data_train['A1_1'].info[\"sfreq\"]\n",
    "# ch_names = dic_data_train['A1_1'].info[\"ch_names\"]\n",
    "n_epochs = 500\n",
    "cuda = torch.cuda.is_available()\n",
    "# device = 'cuda' if cuda else 'cpu'\n",
    "n_classes = 2\n",
    "batch_size = 32\n",
    "\n",
    "steps_preprocess = {\"filter\" : [8,30],\n",
    "                    \"drop_channels\" : ['EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd'] ,\n",
    "                    \"tmin\" : 0.5 , \"tmax\" : 2.5, \"overlap\" :1, \"lenght\": 2,\n",
    "                    \"score\" : \"TAcc\"}\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=50, monitor=\"loss\"),\n",
    "    ModelCheckpoint(filepath='./model/best_model.h5', save_best_only=True),\n",
    "    TensorBoard(log_dir='./logs'),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_preprocess\n",
    "isinstance(steps_preprocess[\"filter\"], list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3759 - binary_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [06:22<1:16:27, 382.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4675 - binary_accuracy: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [12:00<1:05:21, 356.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0903 - binary_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [16:12<51:24, 308.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6396 - binary_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [21:28<46:42, 311.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5255 - binary_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [24:55<36:30, 273.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8068 - binary_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [31:39<37:07, 318.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6028 - binary_accuracy: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [36:25<30:45, 307.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4675 - binary_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [43:14<28:19, 339.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2351 - binary_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [48:42<22:25, 336.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4306 - binary_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [55:29<17:54, 358.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3942 - binary_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [1:02:16<12:26, 373.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5661 - binary_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [1:06:08<05:29, 329.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3421 - binary_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [1:13:57<00:00, 341.34s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7040 - binary_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [07:11<1:19:09, 431.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3743 - binary_accuracy: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [14:25<1:12:09, 432.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7903 - binary_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [21:35<1:04:44, 431.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5324 - binary_accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [28:20<56:07, 420.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1823 - binary_accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [34:20<46:33, 399.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2135 - binary_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [38:24<34:37, 346.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7336 - binary_accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [42:19<25:50, 310.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6705 - binary_accuracy: 0.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [47:17<20:25, 306.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5119 - binary_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [53:41<16:31, 330.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7214 - binary_accuracy: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [58:50<10:47, 323.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6732 - binary_accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [1:05:24<05:45, 345.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5774 - binary_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [1:12:01<00:00, 360.12s/it]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6363 - binary_accuracy: 0.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/17 [09:23<2:30:18, 563.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6560 - binary_accuracy: 0.6062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [18:34<2:19:03, 556.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6911 - binary_accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3/17 [23:41<1:43:12, 442.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3600 - binary_accuracy: 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4/17 [30:02<1:30:38, 418.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4633 - binary_accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [38:08<1:28:28, 442.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5748 - binary_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [45:14<1:20:07, 437.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8165 - binary_accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [51:13<1:08:33, 411.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9772 - binary_accuracy: 0.4938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8/17 [58:09<1:01:56, 412.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1017 - binary_accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [1:07:10<1:00:22, 452.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9623 - binary_accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [1:15:56<55:28, 475.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5792 - binary_accuracy: 0.7875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11/17 [1:25:06<49:50, 498.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2690 - binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [1:34:07<42:36, 511.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6924 - binary_accuracy: 0.5562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 13/17 [1:39:15<29:59, 449.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5033 - binary_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14/17 [1:47:53<23:31, 470.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.1854 - binary_accuracy: 0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [1:57:02<16:27, 493.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8149 - binary_accuracy: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [2:03:15<07:37, 457.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7191 - binary_accuracy: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [2:12:22<00:00, 467.19s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4736 - binary_accuracy: 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [05:06<56:06, 306.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6431 - binary_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [09:47<48:38, 291.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1713 - binary_accuracy: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [16:14<50:13, 334.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8578 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [22:40<47:23, 355.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6917 - binary_accuracy: 0.6062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [29:07<42:47, 366.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7688 - binary_accuracy: 0.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [35:33<37:19, 373.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6491 - binary_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [40:21<28:46, 345.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7587 - binary_accuracy: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [46:45<23:51, 357.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5983 - binary_accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [53:10<18:18, 366.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4648 - binary_accuracy: 0.8062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [59:35<12:23, 371.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7351 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [1:06:05<06:17, 377.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8710 - binary_accuracy: 0.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [1:11:12<00:00, 356.05s/it]\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9212 - binary_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [08:58<2:14:40, 538.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6958 - binary_accuracy: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [14:45<1:39:18, 425.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7250 - binary_accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [22:52<1:38:19, 453.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3960 - binary_accuracy: 0.7688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [31:28<1:35:38, 478.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6470 - binary_accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [39:44<1:28:53, 484.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6695 - binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [46:44<1:17:07, 462.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2897 - binary_accuracy: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [55:33<1:12:37, 484.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7767 - binary_accuracy: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [1:04:20<1:06:23, 497.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6947 - binary_accuracy: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [1:11:33<55:44, 477.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1008 - binary_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [1:20:18<49:13, 492.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9155 - binary_accuracy: 0.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [1:29:02<41:49, 501.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7222 - binary_accuracy: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [1:37:45<33:54, 508.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7547 - binary_accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [1:46:32<25:41, 513.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6658 - binary_accuracy: 0.6313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [1:54:03<16:30, 495.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8382 - binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [2:02:32<08:19, 499.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5391 - binary_accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [2:11:14<00:00, 492.17s/it]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6951 - binary_accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [08:09<1:46:01, 489.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8195 - binary_accuracy: 0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [16:03<1:36:05, 480.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6307 - binary_accuracy: 0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [23:27<1:24:59, 463.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7118 - binary_accuracy: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [31:17<1:17:41, 466.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6780 - binary_accuracy: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [39:03<1:09:56, 466.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6440 - binary_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [46:47<1:02:02, 465.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9130 - binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [54:27<54:05, 463.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7436 - binary_accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [1:02:04<46:10, 461.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7089 - binary_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [1:09:34<38:10, 458.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7618 - binary_accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [1:17:01<30:17, 454.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6852 - binary_accuracy: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [1:24:26<22:35, 451.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7387 - binary_accuracy: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [1:31:53<15:00, 450.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4017 - binary_accuracy: 0.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [1:39:18<07:28, 448.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7435 - binary_accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [1:46:44<00:00, 457.44s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creer la liste accuracy -> ce seras data\n",
    "data[\"accuracy_eegnet\"] = [0]*data.shape[0]\n",
    "# pour chaque groupe\n",
    "\n",
    "for group in dict_age.values():\n",
    "\n",
    "    for i_group in tqdm(range(len(group))):\n",
    "\n",
    "\n",
    "        train_id = group.copy()\n",
    "        test_id = train_id.pop(i_group)\n",
    "\n",
    "\n",
    "\n",
    "        key_train_valid  = create_key(train_id , train = 1 , test = 1 )\n",
    "        key_test  = create_key([test_id] , train = 0 , test = 1 )\n",
    "\n",
    "        mask =np.array([True,True, True ,True, False, False] *  int(key_train_valid.shape[0]/6))\n",
    "        np.random.shuffle(mask)\n",
    "        key_train = key_train_valid[mask]\n",
    "        key_valid = key_train_valid[~mask]\n",
    "\n",
    "        X_train, Y_train = epoching(dic_data,key_train, steps_preprocess)\n",
    "        X_valid, Y_valid = epoching(dic_data,key_valid, steps_preprocess)\n",
    "        X_test, Y_test = epoching(dic_data,key_test, steps_preprocess)\n",
    "\n",
    "        train_gen = DataGenerator(X_train, Y_train, 64)\n",
    "        valid_gen = DataGenerator(X_valid, Y_valid, 64)\n",
    "        test_gen = DataGenerator(X_test, Y_test, 64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model = EEGNet(nb_classes=n_classes, Chans=n_chans, Samples=input_window_samples)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=BinaryAccuracy())\n",
    "\n",
    "        fit_model =  model.fit(x= train_gen,\n",
    "                               batch_size = batch_size,\n",
    "                               epochs = n_epochs ,\n",
    "                               callbacks= my_callbacks,\n",
    "                               validation_data= valid_gen,\n",
    "                               verbose = 0)\n",
    "\n",
    "        model = load_model(\"./model/best_model.h5\")\n",
    "\n",
    "        data.loc[group[i_group], \"accuracy_eegnet\" ]= model.evaluate(x= test_gen)[1]\n",
    "\n",
    "# apprendre le modele en leave one out\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "     accuracy  age  accuracy_eegnet\nA59    60.000   30              0.0\nB62    90.625   19              0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>age</th>\n      <th>accuracy_eegnet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A59</th>\n      <td>60.000</td>\n      <td>30</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>B62</th>\n      <td>90.625</td>\n      <td>19</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"accuracy_eegnet\"] == 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "data_cleaned =data[data[\"accuracy_eegnet\"] != 0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtrocell\\AppData\\Local\\Temp\\ipykernel_32756\\878435877.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['accuracy'] = data_cleaned['accuracy'] *0.01\n"
     ]
    }
   ],
   "source": [
    "data_cleaned['accuracy'] = data_cleaned['accuracy'] *0.01"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "data_cleaned.to_csv(\"././results/age_adaptive5beans.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Comparaison des performances entre deux models')"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ax1 = data_cleaned.plot.scatter(x='accuracy',y='accuracy_eegnet', c='DarkBlue')\n",
    "ax1.plot([0.4,1],[0.4,1], c=\"red\")\n",
    "ax1.set_title(\"Comparaison des performances entre deux models\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy            0.706731\n",
      "age                22.076923\n",
      "accuracy_eegnet     0.767308\n",
      "dtype: float64\n",
      "accuracy            0.574792\n",
      "age                24.000000\n",
      "accuracy_eegnet     0.625000\n",
      "dtype: float64\n",
      "accuracy            0.632721\n",
      "age                25.705882\n",
      "accuracy_eegnet     0.668015\n",
      "dtype: float64\n",
      "accuracy            0.639563\n",
      "age                28.583333\n",
      "accuracy_eegnet     0.625000\n",
      "dtype: float64\n",
      "accuracy            0.623828\n",
      "age                34.812500\n",
      "accuracy_eegnet     0.626172\n",
      "dtype: float64\n",
      "accuracy            0.615982\n",
      "age                48.000000\n",
      "accuracy_eegnet     0.581250\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "liste = []\n",
    "for val in dict_age.values():\n",
    "    print(data_cleaned.loc[val].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "     accuracy  age  accuracy_eegnet\nA25   0.81250   22          0.87500\nA26   0.65625   23          0.76250\nA56   0.99375   23          0.97500\nB63   0.60000   21          0.65000\nB65   0.82500   23          0.75000\nB68   0.55000   22          0.46875\nB70   0.55625   23          0.58125\nB75   0.71875   23          0.86250\nB76   0.80625   23          0.92500\nB78   0.55000   22          0.77500\nC84   0.76250   20          0.81250\nC86   0.62500   21          0.68750\nC87   0.73125   21          0.85000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>age</th>\n      <th>accuracy_eegnet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A25</th>\n      <td>0.81250</td>\n      <td>22</td>\n      <td>0.87500</td>\n    </tr>\n    <tr>\n      <th>A26</th>\n      <td>0.65625</td>\n      <td>23</td>\n      <td>0.76250</td>\n    </tr>\n    <tr>\n      <th>A56</th>\n      <td>0.99375</td>\n      <td>23</td>\n      <td>0.97500</td>\n    </tr>\n    <tr>\n      <th>B63</th>\n      <td>0.60000</td>\n      <td>21</td>\n      <td>0.65000</td>\n    </tr>\n    <tr>\n      <th>B65</th>\n      <td>0.82500</td>\n      <td>23</td>\n      <td>0.75000</td>\n    </tr>\n    <tr>\n      <th>B68</th>\n      <td>0.55000</td>\n      <td>22</td>\n      <td>0.46875</td>\n    </tr>\n    <tr>\n      <th>B70</th>\n      <td>0.55625</td>\n      <td>23</td>\n      <td>0.58125</td>\n    </tr>\n    <tr>\n      <th>B75</th>\n      <td>0.71875</td>\n      <td>23</td>\n      <td>0.86250</td>\n    </tr>\n    <tr>\n      <th>B76</th>\n      <td>0.80625</td>\n      <td>23</td>\n      <td>0.92500</td>\n    </tr>\n    <tr>\n      <th>B78</th>\n      <td>0.55000</td>\n      <td>22</td>\n      <td>0.77500</td>\n    </tr>\n    <tr>\n      <th>C84</th>\n      <td>0.76250</td>\n      <td>20</td>\n      <td>0.81250</td>\n    </tr>\n    <tr>\n      <th>C86</th>\n      <td>0.62500</td>\n      <td>21</td>\n      <td>0.68750</td>\n    </tr>\n    <tr>\n      <th>C87</th>\n      <td>0.73125</td>\n      <td>21</td>\n      <td>0.85000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.loc[val]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "n_chans = 27\n",
    "input_window_samples = 1024\n",
    "# sfreq = dic_data_train['A1_1'].info[\"sfreq\"]\n",
    "# ch_names = dic_data_train['A1_1'].info[\"ch_names\"]\n",
    "n_epochs = 500\n",
    "cuda = torch.cuda.is_available()\n",
    "# device = 'cuda' if cuda else 'cpu'\n",
    "n_classes = 2\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = EEGNet(nb_classes = n_classes, Chans = n_chans, Samples = input_window_samples)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam' , metrics= BinaryAccuracy())\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience= 50, monitor = \"loss\"),\n",
    "    ModelCheckpoint(filepath='./model/model.{epoch:02d}-{val_loss:.2f}.h5', save_best_only=True),\n",
    "    TensorBoard(log_dir='./logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 27, 1024, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 27, 1024, 8)       512       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 27, 1024, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthwi  (None, 1, 1024, 16)      432       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1, 1024, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 1024, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 1, 256, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d (SpatialD  (None, 1, 256, 16)       0         \n",
      " ropout2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 1, 256, 16)       512       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1, 256, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 256, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 1, 32, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d_1 (Spatia  (None, 1, 32, 16)        0         \n",
      " lDropout2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 1026      \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,642\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "432/432 [==============================] - 7s 14ms/step - loss: 0.6937 - binary_accuracy: 0.4963 - val_loss: 0.6952 - val_binary_accuracy: 0.5007\n",
      "Epoch 2/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6937 - binary_accuracy: 0.5025 - val_loss: 0.7479 - val_binary_accuracy: 0.5007\n",
      "Epoch 3/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6928 - binary_accuracy: 0.5127 - val_loss: 0.6941 - val_binary_accuracy: 0.4935\n",
      "Epoch 4/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6923 - binary_accuracy: 0.5172 - val_loss: 0.6953 - val_binary_accuracy: 0.4993\n",
      "Epoch 5/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6924 - binary_accuracy: 0.5203 - val_loss: 0.9121 - val_binary_accuracy: 0.4993\n",
      "Epoch 6/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6915 - binary_accuracy: 0.5218 - val_loss: 0.7133 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6919 - binary_accuracy: 0.5202 - val_loss: 0.6974 - val_binary_accuracy: 0.4967\n",
      "Epoch 8/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6902 - binary_accuracy: 0.5300 - val_loss: 0.7066 - val_binary_accuracy: 0.5007\n",
      "Epoch 9/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6896 - binary_accuracy: 0.5350 - val_loss: 0.6956 - val_binary_accuracy: 0.5026\n",
      "Epoch 10/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6884 - binary_accuracy: 0.5341 - val_loss: 0.9674 - val_binary_accuracy: 0.5007\n",
      "Epoch 11/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6838 - binary_accuracy: 0.5548 - val_loss: 0.6850 - val_binary_accuracy: 0.5339\n",
      "Epoch 12/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6788 - binary_accuracy: 0.5676 - val_loss: 0.7401 - val_binary_accuracy: 0.5059\n",
      "Epoch 13/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6671 - binary_accuracy: 0.5926 - val_loss: 0.7381 - val_binary_accuracy: 0.5221\n",
      "Epoch 14/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6593 - binary_accuracy: 0.6027 - val_loss: 1.5698 - val_binary_accuracy: 0.5007\n",
      "Epoch 15/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6495 - binary_accuracy: 0.6144 - val_loss: 0.6931 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6429 - binary_accuracy: 0.6266 - val_loss: 0.6904 - val_binary_accuracy: 0.5475\n",
      "Epoch 17/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6388 - binary_accuracy: 0.6283 - val_loss: 0.7758 - val_binary_accuracy: 0.5410\n",
      "Epoch 18/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6360 - binary_accuracy: 0.6322 - val_loss: 1.1102 - val_binary_accuracy: 0.5085\n",
      "Epoch 19/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6307 - binary_accuracy: 0.6340 - val_loss: 0.9670 - val_binary_accuracy: 0.5117\n",
      "Epoch 20/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6284 - binary_accuracy: 0.6348 - val_loss: 1.0399 - val_binary_accuracy: 0.5059\n",
      "Epoch 21/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6263 - binary_accuracy: 0.6393 - val_loss: 0.6852 - val_binary_accuracy: 0.5599\n",
      "Epoch 22/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6245 - binary_accuracy: 0.6416 - val_loss: 0.8581 - val_binary_accuracy: 0.5430\n",
      "Epoch 23/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6223 - binary_accuracy: 0.6414 - val_loss: 0.6767 - val_binary_accuracy: 0.5775\n",
      "Epoch 24/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6216 - binary_accuracy: 0.6453 - val_loss: 0.7735 - val_binary_accuracy: 0.5404\n",
      "Epoch 25/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6201 - binary_accuracy: 0.6468 - val_loss: 0.6516 - val_binary_accuracy: 0.5964\n",
      "Epoch 26/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6173 - binary_accuracy: 0.6469 - val_loss: 0.6356 - val_binary_accuracy: 0.6126\n",
      "Epoch 27/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6196 - binary_accuracy: 0.6427 - val_loss: 0.6711 - val_binary_accuracy: 0.5898\n",
      "Epoch 28/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6206 - binary_accuracy: 0.6431 - val_loss: 0.6239 - val_binary_accuracy: 0.6406\n",
      "Epoch 29/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6170 - binary_accuracy: 0.6497 - val_loss: 0.8065 - val_binary_accuracy: 0.5404\n",
      "Epoch 30/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6171 - binary_accuracy: 0.6484 - val_loss: 3.3370 - val_binary_accuracy: 0.5007\n",
      "Epoch 31/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6167 - binary_accuracy: 0.6492 - val_loss: 1.0523 - val_binary_accuracy: 0.5169\n",
      "Epoch 32/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6156 - binary_accuracy: 0.6470 - val_loss: 1.6107 - val_binary_accuracy: 0.4993\n",
      "Epoch 33/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6108 - binary_accuracy: 0.6506 - val_loss: 1.6622 - val_binary_accuracy: 0.5007\n",
      "Epoch 34/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6144 - binary_accuracy: 0.6515 - val_loss: 1.6394 - val_binary_accuracy: 0.5020\n",
      "Epoch 35/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6139 - binary_accuracy: 0.6468 - val_loss: 0.6347 - val_binary_accuracy: 0.6159\n",
      "Epoch 36/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6181 - binary_accuracy: 0.6485 - val_loss: 1.6658 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6118 - binary_accuracy: 0.6492 - val_loss: 1.4682 - val_binary_accuracy: 0.5007\n",
      "Epoch 38/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6152 - binary_accuracy: 0.6508 - val_loss: 2.7348 - val_binary_accuracy: 0.4993\n",
      "Epoch 39/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6083 - binary_accuracy: 0.6481 - val_loss: 2.4684 - val_binary_accuracy: 0.4993\n",
      "Epoch 40/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6134 - binary_accuracy: 0.6521 - val_loss: 4.3762 - val_binary_accuracy: 0.5007\n",
      "Epoch 41/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6137 - binary_accuracy: 0.6503 - val_loss: 1.8299 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6130 - binary_accuracy: 0.6544 - val_loss: 1.7984 - val_binary_accuracy: 0.4993\n",
      "Epoch 43/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6100 - binary_accuracy: 0.6492 - val_loss: 0.9231 - val_binary_accuracy: 0.5039\n",
      "Epoch 44/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6090 - binary_accuracy: 0.6553 - val_loss: 0.6395 - val_binary_accuracy: 0.6289\n",
      "Epoch 45/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6078 - binary_accuracy: 0.6557 - val_loss: 3.5618 - val_binary_accuracy: 0.5007\n",
      "Epoch 46/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6088 - binary_accuracy: 0.6535 - val_loss: 1.0036 - val_binary_accuracy: 0.5091\n",
      "Epoch 47/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6106 - binary_accuracy: 0.6522 - val_loss: 0.8784 - val_binary_accuracy: 0.5234\n",
      "Epoch 48/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6092 - binary_accuracy: 0.6542 - val_loss: 2.2748 - val_binary_accuracy: 0.4993\n",
      "Epoch 49/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6119 - binary_accuracy: 0.6480 - val_loss: 1.2118 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6099 - binary_accuracy: 0.6574 - val_loss: 2.6126 - val_binary_accuracy: 0.4993\n",
      "Epoch 51/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6083 - binary_accuracy: 0.6557 - val_loss: 2.7176 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6099 - binary_accuracy: 0.6519 - val_loss: 0.6417 - val_binary_accuracy: 0.6263\n",
      "Epoch 53/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6078 - binary_accuracy: 0.6555 - val_loss: 0.6206 - val_binary_accuracy: 0.6452\n",
      "Epoch 54/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6071 - binary_accuracy: 0.6554 - val_loss: 0.9680 - val_binary_accuracy: 0.5169\n",
      "Epoch 55/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6058 - binary_accuracy: 0.6549 - val_loss: 0.7525 - val_binary_accuracy: 0.5534\n",
      "Epoch 56/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6112 - binary_accuracy: 0.6562 - val_loss: 1.6218 - val_binary_accuracy: 0.4993\n",
      "Epoch 57/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6069 - binary_accuracy: 0.6589 - val_loss: 1.4170 - val_binary_accuracy: 0.4993\n",
      "Epoch 58/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6110 - binary_accuracy: 0.6537 - val_loss: 1.4871 - val_binary_accuracy: 0.4993\n",
      "Epoch 59/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6102 - binary_accuracy: 0.6501 - val_loss: 1.9145 - val_binary_accuracy: 0.4993\n",
      "Epoch 60/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6074 - binary_accuracy: 0.6557 - val_loss: 3.7088 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6066 - binary_accuracy: 0.6597 - val_loss: 7.0655 - val_binary_accuracy: 0.5007\n",
      "Epoch 62/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6095 - binary_accuracy: 0.6551 - val_loss: 5.2826 - val_binary_accuracy: 0.5007\n",
      "Epoch 63/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6067 - binary_accuracy: 0.6591 - val_loss: 0.9865 - val_binary_accuracy: 0.5169\n",
      "Epoch 64/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6085 - binary_accuracy: 0.6570 - val_loss: 2.8475 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6044 - binary_accuracy: 0.6575 - val_loss: 4.1925 - val_binary_accuracy: 0.5007\n",
      "Epoch 66/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6070 - binary_accuracy: 0.6531 - val_loss: 1.6716 - val_binary_accuracy: 0.5000\n",
      "Epoch 67/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6057 - binary_accuracy: 0.6547 - val_loss: 0.9633 - val_binary_accuracy: 0.5182\n",
      "Epoch 68/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6091 - binary_accuracy: 0.6564 - val_loss: 0.8410 - val_binary_accuracy: 0.5039\n",
      "Epoch 69/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6070 - binary_accuracy: 0.6540 - val_loss: 8.2183 - val_binary_accuracy: 0.5007\n",
      "Epoch 70/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6058 - binary_accuracy: 0.6565 - val_loss: 1.5388 - val_binary_accuracy: 0.4993\n",
      "Epoch 71/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6065 - binary_accuracy: 0.6570 - val_loss: 1.1712 - val_binary_accuracy: 0.5046\n",
      "Epoch 72/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6059 - binary_accuracy: 0.6611 - val_loss: 0.7106 - val_binary_accuracy: 0.5671\n",
      "Epoch 73/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6069 - binary_accuracy: 0.6565 - val_loss: 1.3402 - val_binary_accuracy: 0.5065\n",
      "Epoch 74/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.6056 - binary_accuracy: 0.6608 - val_loss: 0.9720 - val_binary_accuracy: 0.4993\n",
      "Epoch 75/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6079 - binary_accuracy: 0.6607 - val_loss: 8.0966 - val_binary_accuracy: 0.5007\n",
      "Epoch 76/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6043 - binary_accuracy: 0.6654 - val_loss: 0.6341 - val_binary_accuracy: 0.6178\n",
      "Epoch 77/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6036 - binary_accuracy: 0.6591 - val_loss: 0.8837 - val_binary_accuracy: 0.5007\n",
      "Epoch 78/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6033 - binary_accuracy: 0.6663 - val_loss: 4.6858 - val_binary_accuracy: 0.4993\n",
      "Epoch 79/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6072 - binary_accuracy: 0.6626 - val_loss: 0.9974 - val_binary_accuracy: 0.5195\n",
      "Epoch 80/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6041 - binary_accuracy: 0.6642 - val_loss: 5.2722 - val_binary_accuracy: 0.5007\n",
      "Epoch 81/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6055 - binary_accuracy: 0.6529 - val_loss: 0.7863 - val_binary_accuracy: 0.5046\n",
      "Epoch 82/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6044 - binary_accuracy: 0.6636 - val_loss: 1.6659 - val_binary_accuracy: 0.5000\n",
      "Epoch 83/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6036 - binary_accuracy: 0.6627 - val_loss: 1.0395 - val_binary_accuracy: 0.5007\n",
      "Epoch 84/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6024 - binary_accuracy: 0.6601 - val_loss: 0.6451 - val_binary_accuracy: 0.6094\n",
      "Epoch 85/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6046 - binary_accuracy: 0.6592 - val_loss: 1.6620 - val_binary_accuracy: 0.5000\n",
      "Epoch 86/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6030 - binary_accuracy: 0.6610 - val_loss: 1.1565 - val_binary_accuracy: 0.5091\n",
      "Epoch 87/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6016 - binary_accuracy: 0.6675 - val_loss: 1.7170 - val_binary_accuracy: 0.4993\n",
      "Epoch 88/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6034 - binary_accuracy: 0.6698 - val_loss: 6.9123 - val_binary_accuracy: 0.5007\n",
      "Epoch 89/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6013 - binary_accuracy: 0.6652 - val_loss: 1.5055 - val_binary_accuracy: 0.5033\n",
      "Epoch 90/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6048 - binary_accuracy: 0.6613 - val_loss: 2.1690 - val_binary_accuracy: 0.4993\n",
      "Epoch 91/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6013 - binary_accuracy: 0.6641 - val_loss: 8.2298 - val_binary_accuracy: 0.5007\n",
      "Epoch 92/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5976 - binary_accuracy: 0.6671 - val_loss: 1.6179 - val_binary_accuracy: 0.5000\n",
      "Epoch 93/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6008 - binary_accuracy: 0.6602 - val_loss: 4.8240 - val_binary_accuracy: 0.5007\n",
      "Epoch 94/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6011 - binary_accuracy: 0.6594 - val_loss: 0.7998 - val_binary_accuracy: 0.5020\n",
      "Epoch 95/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6052 - binary_accuracy: 0.6595 - val_loss: 0.9152 - val_binary_accuracy: 0.5085\n",
      "Epoch 96/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6018 - binary_accuracy: 0.6604 - val_loss: 13.3682 - val_binary_accuracy: 0.5007\n",
      "Epoch 97/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6031 - binary_accuracy: 0.6672 - val_loss: 12.3992 - val_binary_accuracy: 0.5007\n",
      "Epoch 98/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6022 - binary_accuracy: 0.6659 - val_loss: 0.8526 - val_binary_accuracy: 0.5026\n",
      "Epoch 99/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6025 - binary_accuracy: 0.6662 - val_loss: 0.8333 - val_binary_accuracy: 0.5697\n",
      "Epoch 100/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6002 - binary_accuracy: 0.6663 - val_loss: 1.4204 - val_binary_accuracy: 0.5085\n",
      "Epoch 101/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6069 - binary_accuracy: 0.6599 - val_loss: 0.6473 - val_binary_accuracy: 0.6185\n",
      "Epoch 102/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6037 - binary_accuracy: 0.6597 - val_loss: 0.6728 - val_binary_accuracy: 0.6003\n",
      "Epoch 103/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6019 - binary_accuracy: 0.6629 - val_loss: 1.7107 - val_binary_accuracy: 0.5007\n",
      "Epoch 104/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6012 - binary_accuracy: 0.6676 - val_loss: 2.4882 - val_binary_accuracy: 0.5000\n",
      "Epoch 105/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6003 - binary_accuracy: 0.6633 - val_loss: 2.7840 - val_binary_accuracy: 0.4993\n",
      "Epoch 106/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6035 - binary_accuracy: 0.6630 - val_loss: 1.9266 - val_binary_accuracy: 0.5000\n",
      "Epoch 107/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6030 - binary_accuracy: 0.6620 - val_loss: 0.6741 - val_binary_accuracy: 0.5729\n",
      "Epoch 108/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5999 - binary_accuracy: 0.6623 - val_loss: 11.2005 - val_binary_accuracy: 0.5007\n",
      "Epoch 109/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5998 - binary_accuracy: 0.6644 - val_loss: 0.7195 - val_binary_accuracy: 0.5189\n",
      "Epoch 110/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6016 - binary_accuracy: 0.6667 - val_loss: 0.7156 - val_binary_accuracy: 0.5410\n",
      "Epoch 111/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5996 - binary_accuracy: 0.6681 - val_loss: 5.9021 - val_binary_accuracy: 0.5007\n",
      "Epoch 112/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5973 - binary_accuracy: 0.6655 - val_loss: 0.6126 - val_binary_accuracy: 0.6387\n",
      "Epoch 113/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5975 - binary_accuracy: 0.6701 - val_loss: 0.9628 - val_binary_accuracy: 0.5208\n",
      "Epoch 114/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6003 - binary_accuracy: 0.6688 - val_loss: 1.0257 - val_binary_accuracy: 0.5078\n",
      "Epoch 115/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5997 - binary_accuracy: 0.6678 - val_loss: 1.0663 - val_binary_accuracy: 0.5007\n",
      "Epoch 116/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6016 - binary_accuracy: 0.6635 - val_loss: 2.4404 - val_binary_accuracy: 0.4993\n",
      "Epoch 117/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5966 - binary_accuracy: 0.6678 - val_loss: 1.9639 - val_binary_accuracy: 0.4993\n",
      "Epoch 118/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5958 - binary_accuracy: 0.6692 - val_loss: 0.6062 - val_binary_accuracy: 0.6439\n",
      "Epoch 119/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5988 - binary_accuracy: 0.6698 - val_loss: 0.6808 - val_binary_accuracy: 0.5697\n",
      "Epoch 120/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6003 - binary_accuracy: 0.6651 - val_loss: 3.8208 - val_binary_accuracy: 0.5000\n",
      "Epoch 121/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5975 - binary_accuracy: 0.6664 - val_loss: 0.6327 - val_binary_accuracy: 0.6283\n",
      "Epoch 122/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6010 - binary_accuracy: 0.6670 - val_loss: 4.8228 - val_binary_accuracy: 0.4993\n",
      "Epoch 123/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5991 - binary_accuracy: 0.6693 - val_loss: 1.5761 - val_binary_accuracy: 0.5007\n",
      "Epoch 124/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5973 - binary_accuracy: 0.6666 - val_loss: 1.0222 - val_binary_accuracy: 0.5098\n",
      "Epoch 125/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5997 - binary_accuracy: 0.6623 - val_loss: 1.4979 - val_binary_accuracy: 0.5130\n",
      "Epoch 126/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5963 - binary_accuracy: 0.6687 - val_loss: 2.2617 - val_binary_accuracy: 0.5000\n",
      "Epoch 127/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5945 - binary_accuracy: 0.6738 - val_loss: 1.6393 - val_binary_accuracy: 0.5007\n",
      "Epoch 128/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5983 - binary_accuracy: 0.6726 - val_loss: 2.4208 - val_binary_accuracy: 0.4993\n",
      "Epoch 129/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5999 - binary_accuracy: 0.6663 - val_loss: 0.7151 - val_binary_accuracy: 0.5228\n",
      "Epoch 130/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5979 - binary_accuracy: 0.6680 - val_loss: 1.4553 - val_binary_accuracy: 0.5020\n",
      "Epoch 131/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5945 - binary_accuracy: 0.6701 - val_loss: 0.7141 - val_binary_accuracy: 0.5749\n",
      "Epoch 132/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5976 - binary_accuracy: 0.6674 - val_loss: 1.0194 - val_binary_accuracy: 0.5000\n",
      "Epoch 133/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5963 - binary_accuracy: 0.6753 - val_loss: 1.4642 - val_binary_accuracy: 0.5000\n",
      "Epoch 134/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5979 - binary_accuracy: 0.6678 - val_loss: 0.6352 - val_binary_accuracy: 0.6452\n",
      "Epoch 135/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6001 - binary_accuracy: 0.6673 - val_loss: 2.2400 - val_binary_accuracy: 0.4993\n",
      "Epoch 136/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5993 - binary_accuracy: 0.6664 - val_loss: 1.2296 - val_binary_accuracy: 0.5072\n",
      "Epoch 137/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5983 - binary_accuracy: 0.6732 - val_loss: 2.3891 - val_binary_accuracy: 0.4993\n",
      "Epoch 138/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5991 - binary_accuracy: 0.6648 - val_loss: 1.9693 - val_binary_accuracy: 0.5000\n",
      "Epoch 139/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5949 - binary_accuracy: 0.6743 - val_loss: 6.7657 - val_binary_accuracy: 0.5007\n",
      "Epoch 140/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6008 - binary_accuracy: 0.6654 - val_loss: 0.7979 - val_binary_accuracy: 0.5059\n",
      "Epoch 141/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5979 - binary_accuracy: 0.6683 - val_loss: 0.6872 - val_binary_accuracy: 0.5801\n",
      "Epoch 142/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5981 - binary_accuracy: 0.6672 - val_loss: 1.8151 - val_binary_accuracy: 0.4993\n",
      "Epoch 143/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5941 - binary_accuracy: 0.6721 - val_loss: 1.9576 - val_binary_accuracy: 0.4993\n",
      "Epoch 144/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5936 - binary_accuracy: 0.6692 - val_loss: 2.4332 - val_binary_accuracy: 0.5007\n",
      "Epoch 145/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5978 - binary_accuracy: 0.6697 - val_loss: 18.0693 - val_binary_accuracy: 0.5007\n",
      "Epoch 146/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5969 - binary_accuracy: 0.6717 - val_loss: 1.4578 - val_binary_accuracy: 0.5000\n",
      "Epoch 147/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5952 - binary_accuracy: 0.6730 - val_loss: 1.1478 - val_binary_accuracy: 0.5169\n",
      "Epoch 148/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5938 - binary_accuracy: 0.6697 - val_loss: 12.0527 - val_binary_accuracy: 0.5007\n",
      "Epoch 149/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5964 - binary_accuracy: 0.6667 - val_loss: 2.1592 - val_binary_accuracy: 0.5000\n",
      "Epoch 150/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5921 - binary_accuracy: 0.6772 - val_loss: 1.7590 - val_binary_accuracy: 0.4993\n",
      "Epoch 151/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.6021 - binary_accuracy: 0.6681 - val_loss: 10.4386 - val_binary_accuracy: 0.5007\n",
      "Epoch 152/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5983 - binary_accuracy: 0.6683 - val_loss: 11.7050 - val_binary_accuracy: 0.5007\n",
      "Epoch 153/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5951 - binary_accuracy: 0.6740 - val_loss: 15.7972 - val_binary_accuracy: 0.5007\n",
      "Epoch 154/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5943 - binary_accuracy: 0.6728 - val_loss: 1.4114 - val_binary_accuracy: 0.5026\n",
      "Epoch 155/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5976 - binary_accuracy: 0.6722 - val_loss: 12.6859 - val_binary_accuracy: 0.5007\n",
      "Epoch 156/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5924 - binary_accuracy: 0.6723 - val_loss: 0.7623 - val_binary_accuracy: 0.5072\n",
      "Epoch 157/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5981 - binary_accuracy: 0.6717 - val_loss: 2.7290 - val_binary_accuracy: 0.5000\n",
      "Epoch 158/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5982 - binary_accuracy: 0.6680 - val_loss: 3.5369 - val_binary_accuracy: 0.5007\n",
      "Epoch 159/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5967 - binary_accuracy: 0.6712 - val_loss: 1.3434 - val_binary_accuracy: 0.5013\n",
      "Epoch 160/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5943 - binary_accuracy: 0.6712 - val_loss: 1.3587 - val_binary_accuracy: 0.5013\n",
      "Epoch 161/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5960 - binary_accuracy: 0.6712 - val_loss: 0.8623 - val_binary_accuracy: 0.5280\n",
      "Epoch 162/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5951 - binary_accuracy: 0.6747 - val_loss: 0.9275 - val_binary_accuracy: 0.5358\n",
      "Epoch 163/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5953 - binary_accuracy: 0.6657 - val_loss: 1.4059 - val_binary_accuracy: 0.5039\n",
      "Epoch 164/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5917 - binary_accuracy: 0.6777 - val_loss: 11.6271 - val_binary_accuracy: 0.5007\n",
      "Epoch 165/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5942 - binary_accuracy: 0.6747 - val_loss: 2.3570 - val_binary_accuracy: 0.4993\n",
      "Epoch 166/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5924 - binary_accuracy: 0.6749 - val_loss: 0.6581 - val_binary_accuracy: 0.6100\n",
      "Epoch 167/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5984 - binary_accuracy: 0.6677 - val_loss: 0.8055 - val_binary_accuracy: 0.5286\n",
      "Epoch 168/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5935 - binary_accuracy: 0.6750 - val_loss: 4.0483 - val_binary_accuracy: 0.4993\n",
      "Epoch 169/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5972 - binary_accuracy: 0.6705 - val_loss: 1.7228 - val_binary_accuracy: 0.4993\n",
      "Epoch 170/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5973 - binary_accuracy: 0.6676 - val_loss: 1.2213 - val_binary_accuracy: 0.4993\n",
      "Epoch 171/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5973 - binary_accuracy: 0.6698 - val_loss: 3.7974 - val_binary_accuracy: 0.5007\n",
      "Epoch 172/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5949 - binary_accuracy: 0.6731 - val_loss: 6.8870 - val_binary_accuracy: 0.5007\n",
      "Epoch 173/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5965 - binary_accuracy: 0.6656 - val_loss: 8.1126 - val_binary_accuracy: 0.5007\n",
      "Epoch 174/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5938 - binary_accuracy: 0.6712 - val_loss: 2.4255 - val_binary_accuracy: 0.4993\n",
      "Epoch 175/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5988 - binary_accuracy: 0.6700 - val_loss: 0.6763 - val_binary_accuracy: 0.5697\n",
      "Epoch 176/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5925 - binary_accuracy: 0.6798 - val_loss: 5.9386 - val_binary_accuracy: 0.4993\n",
      "Epoch 177/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5960 - binary_accuracy: 0.6651 - val_loss: 2.2576 - val_binary_accuracy: 0.5000\n",
      "Epoch 178/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5920 - binary_accuracy: 0.6727 - val_loss: 30.9727 - val_binary_accuracy: 0.5007\n",
      "Epoch 179/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5941 - binary_accuracy: 0.6708 - val_loss: 1.5802 - val_binary_accuracy: 0.5000\n",
      "Epoch 180/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5919 - binary_accuracy: 0.6743 - val_loss: 11.5065 - val_binary_accuracy: 0.5007\n",
      "Epoch 181/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5920 - binary_accuracy: 0.6749 - val_loss: 1.0005 - val_binary_accuracy: 0.4993\n",
      "Epoch 182/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5951 - binary_accuracy: 0.6761 - val_loss: 11.0979 - val_binary_accuracy: 0.5007\n",
      "Epoch 183/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5935 - binary_accuracy: 0.6745 - val_loss: 7.1165 - val_binary_accuracy: 0.5007\n",
      "Epoch 184/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5941 - binary_accuracy: 0.6759 - val_loss: 4.4293 - val_binary_accuracy: 0.5007\n",
      "Epoch 185/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5962 - binary_accuracy: 0.6737 - val_loss: 2.4053 - val_binary_accuracy: 0.4993\n",
      "Epoch 186/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5976 - binary_accuracy: 0.6701 - val_loss: 11.4442 - val_binary_accuracy: 0.5007\n",
      "Epoch 187/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5985 - binary_accuracy: 0.6638 - val_loss: 1.7762 - val_binary_accuracy: 0.5000\n",
      "Epoch 188/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5967 - binary_accuracy: 0.6738 - val_loss: 10.2468 - val_binary_accuracy: 0.5007\n",
      "Epoch 189/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5955 - binary_accuracy: 0.6712 - val_loss: 1.4205 - val_binary_accuracy: 0.5007\n",
      "Epoch 190/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5992 - binary_accuracy: 0.6633 - val_loss: 0.6929 - val_binary_accuracy: 0.5488\n",
      "Epoch 191/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5928 - binary_accuracy: 0.6746 - val_loss: 2.2753 - val_binary_accuracy: 0.5007\n",
      "Epoch 192/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5940 - binary_accuracy: 0.6759 - val_loss: 4.5045 - val_binary_accuracy: 0.5007\n",
      "Epoch 193/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5920 - binary_accuracy: 0.6719 - val_loss: 3.2573 - val_binary_accuracy: 0.5000\n",
      "Epoch 194/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5950 - binary_accuracy: 0.6781 - val_loss: 2.8958 - val_binary_accuracy: 0.5007\n",
      "Epoch 195/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5917 - binary_accuracy: 0.6730 - val_loss: 4.6586 - val_binary_accuracy: 0.5007\n",
      "Epoch 196/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5934 - binary_accuracy: 0.6734 - val_loss: 0.7664 - val_binary_accuracy: 0.5710\n",
      "Epoch 197/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5937 - binary_accuracy: 0.6719 - val_loss: 1.3233 - val_binary_accuracy: 0.5020\n",
      "Epoch 198/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5932 - binary_accuracy: 0.6735 - val_loss: 0.7192 - val_binary_accuracy: 0.5397\n",
      "Epoch 199/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5915 - binary_accuracy: 0.6780 - val_loss: 3.8923 - val_binary_accuracy: 0.5007\n",
      "Epoch 200/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5903 - binary_accuracy: 0.6738 - val_loss: 3.7008 - val_binary_accuracy: 0.4993\n",
      "Epoch 201/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5936 - binary_accuracy: 0.6727 - val_loss: 2.8486 - val_binary_accuracy: 0.5000\n",
      "Epoch 202/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5929 - binary_accuracy: 0.6770 - val_loss: 1.1795 - val_binary_accuracy: 0.4993\n",
      "Epoch 203/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5913 - binary_accuracy: 0.6741 - val_loss: 1.5205 - val_binary_accuracy: 0.5000\n",
      "Epoch 204/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5946 - binary_accuracy: 0.6762 - val_loss: 1.1754 - val_binary_accuracy: 0.5052\n",
      "Epoch 205/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5897 - binary_accuracy: 0.6814 - val_loss: 6.2160 - val_binary_accuracy: 0.4993\n",
      "Epoch 206/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5925 - binary_accuracy: 0.6708 - val_loss: 4.8501 - val_binary_accuracy: 0.5007\n",
      "Epoch 207/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5888 - binary_accuracy: 0.6806 - val_loss: 0.7157 - val_binary_accuracy: 0.5814\n",
      "Epoch 208/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5904 - binary_accuracy: 0.6806 - val_loss: 1.1749 - val_binary_accuracy: 0.5026\n",
      "Epoch 209/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5959 - binary_accuracy: 0.6703 - val_loss: 0.9722 - val_binary_accuracy: 0.5039\n",
      "Epoch 210/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5974 - binary_accuracy: 0.6701 - val_loss: 23.2848 - val_binary_accuracy: 0.5007\n",
      "Epoch 211/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5920 - binary_accuracy: 0.6768 - val_loss: 4.7797 - val_binary_accuracy: 0.5007\n",
      "Epoch 212/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5892 - binary_accuracy: 0.6764 - val_loss: 14.2088 - val_binary_accuracy: 0.5007\n",
      "Epoch 213/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5946 - binary_accuracy: 0.6738 - val_loss: 3.4191 - val_binary_accuracy: 0.4993\n",
      "Epoch 214/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5960 - binary_accuracy: 0.6700 - val_loss: 0.6823 - val_binary_accuracy: 0.5729\n",
      "Epoch 215/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5938 - binary_accuracy: 0.6707 - val_loss: 2.3062 - val_binary_accuracy: 0.5000\n",
      "Epoch 216/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5927 - binary_accuracy: 0.6719 - val_loss: 15.4599 - val_binary_accuracy: 0.5007\n",
      "Epoch 217/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5911 - binary_accuracy: 0.6763 - val_loss: 7.9804 - val_binary_accuracy: 0.5007\n",
      "Epoch 218/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5907 - binary_accuracy: 0.6770 - val_loss: 7.3170 - val_binary_accuracy: 0.5007\n",
      "Epoch 219/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5934 - binary_accuracy: 0.6734 - val_loss: 0.9589 - val_binary_accuracy: 0.5280\n",
      "Epoch 220/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5958 - binary_accuracy: 0.6694 - val_loss: 19.9929 - val_binary_accuracy: 0.5007\n",
      "Epoch 221/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5954 - binary_accuracy: 0.6725 - val_loss: 0.8493 - val_binary_accuracy: 0.5039\n",
      "Epoch 222/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5883 - binary_accuracy: 0.6777 - val_loss: 6.2979 - val_binary_accuracy: 0.5007\n",
      "Epoch 223/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5897 - binary_accuracy: 0.6806 - val_loss: 27.8474 - val_binary_accuracy: 0.5007\n",
      "Epoch 224/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5899 - binary_accuracy: 0.6723 - val_loss: 1.0832 - val_binary_accuracy: 0.5007\n",
      "Epoch 225/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5969 - binary_accuracy: 0.6666 - val_loss: 2.3440 - val_binary_accuracy: 0.4993\n",
      "Epoch 226/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5946 - binary_accuracy: 0.6761 - val_loss: 3.3706 - val_binary_accuracy: 0.5007\n",
      "Epoch 227/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5936 - binary_accuracy: 0.6722 - val_loss: 3.8981 - val_binary_accuracy: 0.4993\n",
      "Epoch 228/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5921 - binary_accuracy: 0.6767 - val_loss: 0.9496 - val_binary_accuracy: 0.5013\n",
      "Epoch 229/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5915 - binary_accuracy: 0.6772 - val_loss: 1.8802 - val_binary_accuracy: 0.5000\n",
      "Epoch 230/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5939 - binary_accuracy: 0.6747 - val_loss: 10.5258 - val_binary_accuracy: 0.5007\n",
      "Epoch 231/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5892 - binary_accuracy: 0.6756 - val_loss: 7.2639 - val_binary_accuracy: 0.5007\n",
      "Epoch 232/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5943 - binary_accuracy: 0.6725 - val_loss: 0.6502 - val_binary_accuracy: 0.6139\n",
      "Epoch 233/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5898 - binary_accuracy: 0.6769 - val_loss: 5.4837 - val_binary_accuracy: 0.4993\n",
      "Epoch 234/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5926 - binary_accuracy: 0.6696 - val_loss: 0.9785 - val_binary_accuracy: 0.5059\n",
      "Epoch 235/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5934 - binary_accuracy: 0.6738 - val_loss: 2.2833 - val_binary_accuracy: 0.5000\n",
      "Epoch 236/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5947 - binary_accuracy: 0.6691 - val_loss: 3.6186 - val_binary_accuracy: 0.4993\n",
      "Epoch 237/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5906 - binary_accuracy: 0.6737 - val_loss: 3.2650 - val_binary_accuracy: 0.5007\n",
      "Epoch 238/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5969 - binary_accuracy: 0.6722 - val_loss: 13.1679 - val_binary_accuracy: 0.5007\n",
      "Epoch 239/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5957 - binary_accuracy: 0.6705 - val_loss: 7.1075 - val_binary_accuracy: 0.5007\n",
      "Epoch 240/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5898 - binary_accuracy: 0.6774 - val_loss: 0.8051 - val_binary_accuracy: 0.5143\n",
      "Epoch 241/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5895 - binary_accuracy: 0.6725 - val_loss: 1.9143 - val_binary_accuracy: 0.4993\n",
      "Epoch 242/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5984 - binary_accuracy: 0.6693 - val_loss: 6.5784 - val_binary_accuracy: 0.4993\n",
      "Epoch 243/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5906 - binary_accuracy: 0.6790 - val_loss: 11.0931 - val_binary_accuracy: 0.5007\n",
      "Epoch 244/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5957 - binary_accuracy: 0.6734 - val_loss: 23.6599 - val_binary_accuracy: 0.5007\n",
      "Epoch 245/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5902 - binary_accuracy: 0.6758 - val_loss: 1.8755 - val_binary_accuracy: 0.4993\n",
      "Epoch 246/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5919 - binary_accuracy: 0.6737 - val_loss: 4.4254 - val_binary_accuracy: 0.5007\n",
      "Epoch 247/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5914 - binary_accuracy: 0.6685 - val_loss: 2.4634 - val_binary_accuracy: 0.4993\n",
      "Epoch 248/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5944 - binary_accuracy: 0.6735 - val_loss: 0.9773 - val_binary_accuracy: 0.5234\n",
      "Epoch 249/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5909 - binary_accuracy: 0.6758 - val_loss: 7.1191 - val_binary_accuracy: 0.5007\n",
      "Epoch 250/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5955 - binary_accuracy: 0.6738 - val_loss: 0.6267 - val_binary_accuracy: 0.6328\n",
      "Epoch 251/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5945 - binary_accuracy: 0.6758 - val_loss: 0.9066 - val_binary_accuracy: 0.5091\n",
      "Epoch 252/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5900 - binary_accuracy: 0.6780 - val_loss: 1.0004 - val_binary_accuracy: 0.5013\n",
      "Epoch 253/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5913 - binary_accuracy: 0.6740 - val_loss: 2.7539 - val_binary_accuracy: 0.4993\n",
      "Epoch 254/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5929 - binary_accuracy: 0.6743 - val_loss: 0.6211 - val_binary_accuracy: 0.6569\n",
      "Epoch 255/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5980 - binary_accuracy: 0.6666 - val_loss: 3.2593 - val_binary_accuracy: 0.4993\n",
      "Epoch 256/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5974 - binary_accuracy: 0.6691 - val_loss: 1.9834 - val_binary_accuracy: 0.4993\n",
      "Epoch 257/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5906 - binary_accuracy: 0.6783 - val_loss: 2.6438 - val_binary_accuracy: 0.5000\n",
      "Epoch 258/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5912 - binary_accuracy: 0.6751 - val_loss: 1.2805 - val_binary_accuracy: 0.4993\n",
      "Epoch 259/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5864 - binary_accuracy: 0.6814 - val_loss: 5.2781 - val_binary_accuracy: 0.5007\n",
      "Epoch 260/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5949 - binary_accuracy: 0.6728 - val_loss: 4.5792 - val_binary_accuracy: 0.4993\n",
      "Epoch 261/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5902 - binary_accuracy: 0.6766 - val_loss: 2.8191 - val_binary_accuracy: 0.5000\n",
      "Epoch 262/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5921 - binary_accuracy: 0.6763 - val_loss: 5.0425 - val_binary_accuracy: 0.5007\n",
      "Epoch 263/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5912 - binary_accuracy: 0.6757 - val_loss: 0.6177 - val_binary_accuracy: 0.6458\n",
      "Epoch 264/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5963 - binary_accuracy: 0.6700 - val_loss: 0.6728 - val_binary_accuracy: 0.5879\n",
      "Epoch 265/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5920 - binary_accuracy: 0.6755 - val_loss: 8.2126 - val_binary_accuracy: 0.5007\n",
      "Epoch 266/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5929 - binary_accuracy: 0.6759 - val_loss: 8.6959 - val_binary_accuracy: 0.5007\n",
      "Epoch 267/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5909 - binary_accuracy: 0.6769 - val_loss: 2.9115 - val_binary_accuracy: 0.4993\n",
      "Epoch 268/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5944 - binary_accuracy: 0.6691 - val_loss: 1.2184 - val_binary_accuracy: 0.4993\n",
      "Epoch 269/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5929 - binary_accuracy: 0.6770 - val_loss: 5.7713 - val_binary_accuracy: 0.4993\n",
      "Epoch 270/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5934 - binary_accuracy: 0.6795 - val_loss: 1.6025 - val_binary_accuracy: 0.5000\n",
      "Epoch 271/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5933 - binary_accuracy: 0.6744 - val_loss: 14.9027 - val_binary_accuracy: 0.5007\n",
      "Epoch 272/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5898 - binary_accuracy: 0.6781 - val_loss: 3.8266 - val_binary_accuracy: 0.4993\n",
      "Epoch 273/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5955 - binary_accuracy: 0.6725 - val_loss: 3.1380 - val_binary_accuracy: 0.4993\n",
      "Epoch 274/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5932 - binary_accuracy: 0.6735 - val_loss: 5.7740 - val_binary_accuracy: 0.4993\n",
      "Epoch 275/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5916 - binary_accuracy: 0.6740 - val_loss: 2.4950 - val_binary_accuracy: 0.4993\n",
      "Epoch 276/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5964 - binary_accuracy: 0.6777 - val_loss: 2.7182 - val_binary_accuracy: 0.4993\n",
      "Epoch 277/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5935 - binary_accuracy: 0.6734 - val_loss: 0.7741 - val_binary_accuracy: 0.5208\n",
      "Epoch 278/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5955 - binary_accuracy: 0.6685 - val_loss: 0.6968 - val_binary_accuracy: 0.5462\n",
      "Epoch 279/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5896 - binary_accuracy: 0.6787 - val_loss: 0.7847 - val_binary_accuracy: 0.5365\n",
      "Epoch 280/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5922 - binary_accuracy: 0.6676 - val_loss: 5.5064 - val_binary_accuracy: 0.5007\n",
      "Epoch 281/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5970 - binary_accuracy: 0.6770 - val_loss: 2.4891 - val_binary_accuracy: 0.4993\n",
      "Epoch 282/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5913 - binary_accuracy: 0.6780 - val_loss: 29.6315 - val_binary_accuracy: 0.5007\n",
      "Epoch 283/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5915 - binary_accuracy: 0.6731 - val_loss: 19.4136 - val_binary_accuracy: 0.5007\n",
      "Epoch 284/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5950 - binary_accuracy: 0.6733 - val_loss: 2.6365 - val_binary_accuracy: 0.5000\n",
      "Epoch 285/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5976 - binary_accuracy: 0.6705 - val_loss: 16.5003 - val_binary_accuracy: 0.5007\n",
      "Epoch 286/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5938 - binary_accuracy: 0.6773 - val_loss: 11.3508 - val_binary_accuracy: 0.5007\n",
      "Epoch 287/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5951 - binary_accuracy: 0.6748 - val_loss: 4.4309 - val_binary_accuracy: 0.4993\n",
      "Epoch 288/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5910 - binary_accuracy: 0.6745 - val_loss: 2.2387 - val_binary_accuracy: 0.5000\n",
      "Epoch 289/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5900 - binary_accuracy: 0.6737 - val_loss: 20.8123 - val_binary_accuracy: 0.5007\n",
      "Epoch 290/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5918 - binary_accuracy: 0.6777 - val_loss: 1.1807 - val_binary_accuracy: 0.4993\n",
      "Epoch 291/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5912 - binary_accuracy: 0.6766 - val_loss: 15.8974 - val_binary_accuracy: 0.5007\n",
      "Epoch 292/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5908 - binary_accuracy: 0.6739 - val_loss: 1.7484 - val_binary_accuracy: 0.5000\n",
      "Epoch 293/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5916 - binary_accuracy: 0.6772 - val_loss: 0.7573 - val_binary_accuracy: 0.5228\n",
      "Epoch 294/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5907 - binary_accuracy: 0.6806 - val_loss: 2.9551 - val_binary_accuracy: 0.5007\n",
      "Epoch 295/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5923 - binary_accuracy: 0.6721 - val_loss: 3.4172 - val_binary_accuracy: 0.4993\n",
      "Epoch 296/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5934 - binary_accuracy: 0.6743 - val_loss: 6.5026 - val_binary_accuracy: 0.5007\n",
      "Epoch 297/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5927 - binary_accuracy: 0.6769 - val_loss: 1.9243 - val_binary_accuracy: 0.5007\n",
      "Epoch 298/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5946 - binary_accuracy: 0.6750 - val_loss: 0.9472 - val_binary_accuracy: 0.5182\n",
      "Epoch 299/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5887 - binary_accuracy: 0.6806 - val_loss: 2.3737 - val_binary_accuracy: 0.4993\n",
      "Epoch 300/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5897 - binary_accuracy: 0.6784 - val_loss: 19.1448 - val_binary_accuracy: 0.5007\n",
      "Epoch 301/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5898 - binary_accuracy: 0.6751 - val_loss: 9.1227 - val_binary_accuracy: 0.5007\n",
      "Epoch 302/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5951 - binary_accuracy: 0.6740 - val_loss: 4.3820 - val_binary_accuracy: 0.4993\n",
      "Epoch 303/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5920 - binary_accuracy: 0.6746 - val_loss: 2.1800 - val_binary_accuracy: 0.4993\n",
      "Epoch 304/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5880 - binary_accuracy: 0.6804 - val_loss: 3.3091 - val_binary_accuracy: 0.4993\n",
      "Epoch 305/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5869 - binary_accuracy: 0.6790 - val_loss: 12.7557 - val_binary_accuracy: 0.5007\n",
      "Epoch 306/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5936 - binary_accuracy: 0.6732 - val_loss: 4.1747 - val_binary_accuracy: 0.5007\n",
      "Epoch 307/500\n",
      "432/432 [==============================] - 6s 13ms/step - loss: 0.5930 - binary_accuracy: 0.6717 - val_loss: 2.6489 - val_binary_accuracy: 0.5000\n",
      "Epoch 308/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5898 - binary_accuracy: 0.6727 - val_loss: 1.3275 - val_binary_accuracy: 0.5000\n",
      "Epoch 309/500\n",
      "432/432 [==============================] - 6s 14ms/step - loss: 0.5917 - binary_accuracy: 0.6773 - val_loss: 12.7547 - val_binary_accuracy: 0.5007\n"
     ]
    }
   ],
   "source": [
    "fit_model =  model.fit(x= X_train_pre,\n",
    "                       y= Y_train_pre,\n",
    "                       batch_size = batch_size,\n",
    "                       epochs = n_epochs ,\n",
    "                       callbacks= my_callbacks,\n",
    "                       validation_data= (X_train_post,Y_train_post))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [56]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model\u001B[38;5;241m.\u001B[39mevaluate(x\u001B[38;5;241m=\u001B[39m \u001B[43mX_test\u001B[49m, y \u001B[38;5;241m=\u001B[39mY_test)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(x= X_test, y =Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6781 - binary_accuracy: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6780735850334167, 0.6499999761581421]"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model('.\\model\\model.94-0.63.h5')\n",
    "best_model.evaluate(x= X_valid_train, y = Y_valid_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6697 - binary_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6696761250495911, 0.6000000238418579]"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x= X_valid_test, y = Y_valid_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6279 - binary_accuracy: 0.6504\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6279155611991882, 0.650390625]"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(x= X_train_post, y = Y_train_post)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 2s 49ms/step - loss: 0.5796 - binary_accuracy: 0.6830 - val_loss: 1.0856 - val_binary_accuracy: 0.5026\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5492 - binary_accuracy: 0.7091 - val_loss: 2.3417 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5424 - binary_accuracy: 0.7239 - val_loss: 1.2540 - val_binary_accuracy: 0.5073\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5320 - binary_accuracy: 0.7261 - val_loss: 0.6867 - val_binary_accuracy: 0.5741\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5353 - binary_accuracy: 0.7193 - val_loss: 0.7174 - val_binary_accuracy: 0.5343\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5340 - binary_accuracy: 0.7403 - val_loss: 1.1373 - val_binary_accuracy: 0.5235\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5353 - binary_accuracy: 0.7222 - val_loss: 0.6469 - val_binary_accuracy: 0.6497\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5305 - binary_accuracy: 0.7182 - val_loss: 1.4313 - val_binary_accuracy: 0.5073\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5260 - binary_accuracy: 0.7369 - val_loss: 1.6819 - val_binary_accuracy: 0.5087\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.5226 - binary_accuracy: 0.7403 - val_loss: 0.9278 - val_binary_accuracy: 0.5314\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x235104cb1f0>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(x= valid_train_gen ,\n",
    "               batch_size = batch_size,\n",
    "               callbacks= my_callbacks ,\n",
    "               epochs= 10 ,\n",
    "               validation_data= valid_test_gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['A8', 'B75', 'A45', 'A56', 'A37', 'B77', 'A60', 'B62', 'A28', 'A4',\n       'A22', 'B70', 'A33', 'A59', 'B73', 'A20', 'A36', 'A29', 'A58',\n       'A14', 'C84', 'A16'], dtype=object)"
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_path = \"C:\\\\Users\\dtrocell\\Documents\\ML\\Big dataset\\signal\"\n",
    "valid_dataset = np.array(pd.read_csv(init_path+\"\\\\validkey.csv\", index_col=0).index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "files_dir=os.listdir(init_path)[:3]\n",
    "\n",
    "participant_dir = [[],[],[]]\n",
    "for val in valid_dataset :\n",
    "    if val[0] == \"A\":\n",
    "        participant_dir[0].append(val)\n",
    "    elif val[0] == \"B\":\n",
    "        participant_dir[1].append(val)\n",
    "    elif val[0] == \"C\":\n",
    "        participant_dir[2].append(val)\n",
    "    else:\n",
    "        print(\"erreur\")\n",
    "\n",
    "dic_data =  collect_data(files_dir, participant_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "directory_model = '.\\model\\model.118-0.61.h5'\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience= 10, monitor = \"loss\"),\n",
    "    ModelCheckpoint(filepath='./model/best_model_finetuned.h5', save_best_only=True),\n",
    "    TensorBoard(log_dir='./logs'),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "steps_preprocess = {\"filter\" : [8,30],\n",
    "                    \"drop_channels\" : ['EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd'] ,\n",
    "                    \"tmin\" : 0.5 , \"tmax\" : 2.5, \"overlap\" :1, \"lenght\": 2,\n",
    "                    \"score\" : \"TAcc\"}\n",
    "#\n",
    "# def create_key(df , train = 1 , test_1 = 1 , test_2 = 1):\n",
    "#\n",
    "#     keys = np.array([])\n",
    "#\n",
    "#     for  val  in df :\n",
    "#         if train :\n",
    "#             keys = np.append(keys, [val+\"_1\" ,val+\"_2\"])\n",
    "#         if test_1 :\n",
    "#                 keys = np.append(keys, [val+\"_3\" ,val+\"_4\"])\n",
    "#         if test_2 :\n",
    "#             if val != \"A59\":\n",
    "#                 keys = np.append(keys, [val+\"_5\" ,val+\"_6\"])\n",
    "#     return keys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.95it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.02it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6421 - binary_accuracy: 0.6375\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.7509 - binary_accuracy: 0.5250 - val_loss: 0.7360 - val_binary_accuracy: 0.4875\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6762 - binary_accuracy: 0.5500 - val_loss: 0.7307 - val_binary_accuracy: 0.4750\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6586 - binary_accuracy: 0.6000 - val_loss: 0.7236 - val_binary_accuracy: 0.4500\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6377 - binary_accuracy: 0.6750 - val_loss: 0.7151 - val_binary_accuracy: 0.4875\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6185 - binary_accuracy: 0.7000 - val_loss: 0.7141 - val_binary_accuracy: 0.4875\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5759 - binary_accuracy: 0.7625 - val_loss: 0.7278 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5678 - binary_accuracy: 0.8000 - val_loss: 0.7609 - val_binary_accuracy: 0.5375\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5429 - binary_accuracy: 0.8375 - val_loss: 0.8176 - val_binary_accuracy: 0.4875\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5305 - binary_accuracy: 0.7625 - val_loss: 0.8118 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5164 - binary_accuracy: 0.7375 - val_loss: 0.8809 - val_binary_accuracy: 0.4750\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5282 - binary_accuracy: 0.7750 - val_loss: 1.0313 - val_binary_accuracy: 0.4750\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5123 - binary_accuracy: 0.8250 - val_loss: 1.0531 - val_binary_accuracy: 0.4750\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4940 - binary_accuracy: 0.7750 - val_loss: 1.1878 - val_binary_accuracy: 0.4750\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5219 - binary_accuracy: 0.7875 - val_loss: 1.2094 - val_binary_accuracy: 0.4750\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4888 - binary_accuracy: 0.8125 - val_loss: 1.0741 - val_binary_accuracy: 0.4750\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4822 - binary_accuracy: 0.8250 - val_loss: 1.0732 - val_binary_accuracy: 0.4875\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4717 - binary_accuracy: 0.8000 - val_loss: 1.1458 - val_binary_accuracy: 0.4875\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4625 - binary_accuracy: 0.8250 - val_loss: 1.4671 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4584 - binary_accuracy: 0.8375 - val_loss: 1.7648 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4505 - binary_accuracy: 0.8375 - val_loss: 1.8250 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4536 - binary_accuracy: 0.8000 - val_loss: 1.8867 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4491 - binary_accuracy: 0.8625 - val_loss: 1.9305 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4374 - binary_accuracy: 0.8500 - val_loss: 1.8814 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4432 - binary_accuracy: 0.8375 - val_loss: 2.2893 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4515 - binary_accuracy: 0.8125 - val_loss: 2.4489 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4372 - binary_accuracy: 0.8375 - val_loss: 2.8023 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4310 - binary_accuracy: 0.8375 - val_loss: 3.0020 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4354 - binary_accuracy: 0.8375 - val_loss: 3.0544 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4207 - binary_accuracy: 0.8500 - val_loss: 3.0393 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4047 - binary_accuracy: 0.8500 - val_loss: 3.3056 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4332 - binary_accuracy: 0.8500 - val_loss: 3.3475 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4278 - binary_accuracy: 0.9000 - val_loss: 3.2320 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4158 - binary_accuracy: 0.8625 - val_loss: 3.2553 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3902 - binary_accuracy: 0.9000 - val_loss: 3.2912 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4170 - binary_accuracy: 0.8750 - val_loss: 3.4128 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4346 - binary_accuracy: 0.8125 - val_loss: 3.4280 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4053 - binary_accuracy: 0.9125 - val_loss: 3.3975 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3973 - binary_accuracy: 0.8875 - val_loss: 3.5503 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4101 - binary_accuracy: 0.8750 - val_loss: 3.6134 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4159 - binary_accuracy: 0.8875 - val_loss: 3.7399 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4045 - binary_accuracy: 0.8500 - val_loss: 3.7231 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4071 - binary_accuracy: 0.9125 - val_loss: 3.6743 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3919 - binary_accuracy: 0.8750 - val_loss: 3.4314 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3896 - binary_accuracy: 0.8750 - val_loss: 3.1718 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3921 - binary_accuracy: 0.8625 - val_loss: 2.8846 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4021 - binary_accuracy: 0.9125 - val_loss: 2.6253 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3899 - binary_accuracy: 0.9000 - val_loss: 2.3288 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4013 - binary_accuracy: 0.9000 - val_loss: 1.9502 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3582 - binary_accuracy: 0.9125 - val_loss: 1.6819 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3861 - binary_accuracy: 0.9250 - val_loss: 1.3542 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.3816 - binary_accuracy: 0.9000 - val_loss: 1.1071 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3968 - binary_accuracy: 0.9125 - val_loss: 1.1582 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3812 - binary_accuracy: 0.9000 - val_loss: 1.5765 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4035 - binary_accuracy: 0.9000 - val_loss: 1.9757 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3662 - binary_accuracy: 0.9125 - val_loss: 2.0876 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3823 - binary_accuracy: 0.9000 - val_loss: 1.7011 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3552 - binary_accuracy: 0.9125 - val_loss: 1.4828 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3903 - binary_accuracy: 0.9375 - val_loss: 1.3666 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3478 - binary_accuracy: 0.9125 - val_loss: 1.3216 - val_binary_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3727 - binary_accuracy: 0.9500 - val_loss: 1.2856 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3860 - binary_accuracy: 0.9000 - val_loss: 1.2463 - val_binary_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3839 - binary_accuracy: 0.9125 - val_loss: 1.3291 - val_binary_accuracy: 0.5000\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3697 - binary_accuracy: 0.9000 - val_loss: 1.6393 - val_binary_accuracy: 0.5000\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3657 - binary_accuracy: 0.9125 - val_loss: 1.8488 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3806 - binary_accuracy: 0.9250 - val_loss: 1.9395 - val_binary_accuracy: 0.5000\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3611 - binary_accuracy: 0.8750 - val_loss: 1.8679 - val_binary_accuracy: 0.5000\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3551 - binary_accuracy: 0.9125 - val_loss: 1.7240 - val_binary_accuracy: 0.5000\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3592 - binary_accuracy: 0.9000 - val_loss: 1.5219 - val_binary_accuracy: 0.5000\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3350 - binary_accuracy: 0.9500 - val_loss: 1.7097 - val_binary_accuracy: 0.5000\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3849 - binary_accuracy: 0.9125 - val_loss: 2.0439 - val_binary_accuracy: 0.5000\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3713 - binary_accuracy: 0.8875 - val_loss: 2.0171 - val_binary_accuracy: 0.5000\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3512 - binary_accuracy: 0.9125 - val_loss: 1.7981 - val_binary_accuracy: 0.5000\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3556 - binary_accuracy: 0.9125 - val_loss: 1.6525 - val_binary_accuracy: 0.5000\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3299 - binary_accuracy: 0.9500 - val_loss: 1.4894 - val_binary_accuracy: 0.5000\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3642 - binary_accuracy: 0.8750 - val_loss: 1.3246 - val_binary_accuracy: 0.5000\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3687 - binary_accuracy: 0.9125 - val_loss: 1.2104 - val_binary_accuracy: 0.5000\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3440 - binary_accuracy: 0.9375 - val_loss: 1.0072 - val_binary_accuracy: 0.5000\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3332 - binary_accuracy: 0.9375 - val_loss: 0.9012 - val_binary_accuracy: 0.4875\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3642 - binary_accuracy: 0.9250 - val_loss: 0.8226 - val_binary_accuracy: 0.5250\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3547 - binary_accuracy: 0.8875 - val_loss: 0.8590 - val_binary_accuracy: 0.5000\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3452 - binary_accuracy: 0.9000 - val_loss: 1.1602 - val_binary_accuracy: 0.5000\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3396 - binary_accuracy: 0.9000 - val_loss: 1.2776 - val_binary_accuracy: 0.5000\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3541 - binary_accuracy: 0.9000 - val_loss: 1.3347 - val_binary_accuracy: 0.5000\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3469 - binary_accuracy: 0.9250 - val_loss: 1.5404 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7040 - binary_accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.41it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.41it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6426 - binary_accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6566 - binary_accuracy: 0.6125\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.7323 - binary_accuracy: 0.4625 - val_loss: 0.7128 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.6668 - binary_accuracy: 0.5875 - val_loss: 0.7389 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6617 - binary_accuracy: 0.5875 - val_loss: 0.7696 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6287 - binary_accuracy: 0.7125 - val_loss: 0.8121 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6124 - binary_accuracy: 0.8000 - val_loss: 0.8362 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5942 - binary_accuracy: 0.7625 - val_loss: 0.8179 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5608 - binary_accuracy: 0.7875 - val_loss: 0.7524 - val_binary_accuracy: 0.5125\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5396 - binary_accuracy: 0.8250 - val_loss: 0.7117 - val_binary_accuracy: 0.4875\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5493 - binary_accuracy: 0.8125 - val_loss: 0.7425 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5019 - binary_accuracy: 0.8375 - val_loss: 0.7698 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4898 - binary_accuracy: 0.8875 - val_loss: 0.8009 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4969 - binary_accuracy: 0.8625 - val_loss: 0.8050 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4864 - binary_accuracy: 0.9000 - val_loss: 0.8570 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4738 - binary_accuracy: 0.8875 - val_loss: 0.9985 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4462 - binary_accuracy: 0.9250 - val_loss: 1.2289 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4720 - binary_accuracy: 0.8750 - val_loss: 1.4608 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4639 - binary_accuracy: 0.8750 - val_loss: 1.5117 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4229 - binary_accuracy: 0.9250 - val_loss: 1.4478 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4355 - binary_accuracy: 0.8875 - val_loss: 1.3114 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4565 - binary_accuracy: 0.9000 - val_loss: 1.0036 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4389 - binary_accuracy: 0.8875 - val_loss: 0.8184 - val_binary_accuracy: 0.4875\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4303 - binary_accuracy: 0.9000 - val_loss: 0.7913 - val_binary_accuracy: 0.4625\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4164 - binary_accuracy: 0.9250 - val_loss: 0.8965 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4264 - binary_accuracy: 0.9125 - val_loss: 1.0276 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4097 - binary_accuracy: 0.9125 - val_loss: 1.1262 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4163 - binary_accuracy: 0.8750 - val_loss: 1.1586 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3938 - binary_accuracy: 0.9375 - val_loss: 1.1722 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4060 - binary_accuracy: 0.9250 - val_loss: 1.0551 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4138 - binary_accuracy: 0.9500 - val_loss: 0.9484 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4102 - binary_accuracy: 0.9375 - val_loss: 0.8734 - val_binary_accuracy: 0.4625\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3930 - binary_accuracy: 0.9500 - val_loss: 0.8496 - val_binary_accuracy: 0.4500\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3944 - binary_accuracy: 0.9250 - val_loss: 0.9434 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4069 - binary_accuracy: 0.9125 - val_loss: 0.8623 - val_binary_accuracy: 0.4500\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3570 - binary_accuracy: 0.9625 - val_loss: 0.7578 - val_binary_accuracy: 0.5125\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4017 - binary_accuracy: 0.9250 - val_loss: 0.7773 - val_binary_accuracy: 0.4875\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4065 - binary_accuracy: 0.9250 - val_loss: 0.9046 - val_binary_accuracy: 0.4750\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3915 - binary_accuracy: 0.9500 - val_loss: 0.9217 - val_binary_accuracy: 0.4875\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3910 - binary_accuracy: 0.9375 - val_loss: 0.9286 - val_binary_accuracy: 0.4875\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3791 - binary_accuracy: 0.9250 - val_loss: 0.9391 - val_binary_accuracy: 0.4875\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3785 - binary_accuracy: 0.9125 - val_loss: 1.0705 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3665 - binary_accuracy: 0.9250 - val_loss: 1.0270 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3737 - binary_accuracy: 0.9500 - val_loss: 0.9278 - val_binary_accuracy: 0.4750\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3808 - binary_accuracy: 0.9375 - val_loss: 0.8753 - val_binary_accuracy: 0.4625\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3817 - binary_accuracy: 0.9125 - val_loss: 0.9113 - val_binary_accuracy: 0.4750\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6365 - binary_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.94it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6969 - binary_accuracy: 0.5250\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.6869 - binary_accuracy: 0.5375 - val_loss: 0.7144 - val_binary_accuracy: 0.3875\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6639 - binary_accuracy: 0.5750 - val_loss: 0.7136 - val_binary_accuracy: 0.4500\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6660 - binary_accuracy: 0.6000 - val_loss: 0.7120 - val_binary_accuracy: 0.4375\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6347 - binary_accuracy: 0.7000 - val_loss: 0.7080 - val_binary_accuracy: 0.4875\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5880 - binary_accuracy: 0.8250 - val_loss: 0.7146 - val_binary_accuracy: 0.4625\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5843 - binary_accuracy: 0.7625 - val_loss: 0.7639 - val_binary_accuracy: 0.5125\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5551 - binary_accuracy: 0.8250 - val_loss: 0.8859 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5486 - binary_accuracy: 0.7875 - val_loss: 0.9833 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5066 - binary_accuracy: 0.8500 - val_loss: 1.1114 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5117 - binary_accuracy: 0.8125 - val_loss: 1.1868 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5279 - binary_accuracy: 0.7500 - val_loss: 1.1653 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4884 - binary_accuracy: 0.8250 - val_loss: 1.2248 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4842 - binary_accuracy: 0.8250 - val_loss: 1.3168 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4962 - binary_accuracy: 0.8125 - val_loss: 1.3475 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4545 - binary_accuracy: 0.8375 - val_loss: 1.2429 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4663 - binary_accuracy: 0.8250 - val_loss: 1.2327 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4757 - binary_accuracy: 0.8500 - val_loss: 1.2814 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4467 - binary_accuracy: 0.8750 - val_loss: 1.2347 - val_binary_accuracy: 0.5125\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4709 - binary_accuracy: 0.8625 - val_loss: 1.2142 - val_binary_accuracy: 0.5125\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4567 - binary_accuracy: 0.8625 - val_loss: 1.1789 - val_binary_accuracy: 0.5125\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4607 - binary_accuracy: 0.8500 - val_loss: 1.1256 - val_binary_accuracy: 0.5125\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4164 - binary_accuracy: 0.9375 - val_loss: 1.1485 - val_binary_accuracy: 0.5125\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4250 - binary_accuracy: 0.9000 - val_loss: 1.2206 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4405 - binary_accuracy: 0.8875 - val_loss: 1.3312 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3969 - binary_accuracy: 0.9250 - val_loss: 1.4910 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4075 - binary_accuracy: 0.8750 - val_loss: 1.6197 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4058 - binary_accuracy: 0.8875 - val_loss: 1.7597 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4327 - binary_accuracy: 0.8750 - val_loss: 1.7682 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4035 - binary_accuracy: 0.9125 - val_loss: 1.7060 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4022 - binary_accuracy: 0.8375 - val_loss: 1.7692 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3875 - binary_accuracy: 0.9500 - val_loss: 1.8063 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4057 - binary_accuracy: 0.9000 - val_loss: 1.8287 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4058 - binary_accuracy: 0.9250 - val_loss: 1.7763 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4057 - binary_accuracy: 0.9125 - val_loss: 1.7018 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4070 - binary_accuracy: 0.9125 - val_loss: 1.5974 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4073 - binary_accuracy: 0.9000 - val_loss: 1.5790 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4156 - binary_accuracy: 0.8875 - val_loss: 1.5948 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4148 - binary_accuracy: 0.8625 - val_loss: 1.6028 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3995 - binary_accuracy: 0.9125 - val_loss: 1.5551 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4232 - binary_accuracy: 0.8750 - val_loss: 1.5149 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3947 - binary_accuracy: 0.9125 - val_loss: 1.3971 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6975 - binary_accuracy: 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.14it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.10it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2678 - binary_accuracy: 0.9375\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.8002 - binary_accuracy: 0.5500 - val_loss: 0.6644 - val_binary_accuracy: 0.6000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5752 - binary_accuracy: 0.8375 - val_loss: 0.5944 - val_binary_accuracy: 0.7125\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4427 - binary_accuracy: 0.9250 - val_loss: 0.5584 - val_binary_accuracy: 0.6875\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3478 - binary_accuracy: 0.9375 - val_loss: 0.5837 - val_binary_accuracy: 0.6375\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2817 - binary_accuracy: 0.9625 - val_loss: 0.6516 - val_binary_accuracy: 0.5750\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2408 - binary_accuracy: 0.9500 - val_loss: 0.7477 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2158 - binary_accuracy: 0.9625 - val_loss: 0.7951 - val_binary_accuracy: 0.5625\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2051 - binary_accuracy: 0.9500 - val_loss: 0.6981 - val_binary_accuracy: 0.5875\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2090 - binary_accuracy: 0.9500 - val_loss: 0.5473 - val_binary_accuracy: 0.7000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1670 - binary_accuracy: 0.9875 - val_loss: 0.4402 - val_binary_accuracy: 0.7875\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1780 - binary_accuracy: 0.9500 - val_loss: 0.3806 - val_binary_accuracy: 0.8250\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1619 - binary_accuracy: 1.0000 - val_loss: 0.3685 - val_binary_accuracy: 0.8250\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1507 - binary_accuracy: 0.9875 - val_loss: 0.3246 - val_binary_accuracy: 0.8750\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1583 - binary_accuracy: 0.9875 - val_loss: 0.3149 - val_binary_accuracy: 0.8875\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1414 - binary_accuracy: 0.9875 - val_loss: 0.3168 - val_binary_accuracy: 0.8875\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1327 - binary_accuracy: 1.0000 - val_loss: 0.2983 - val_binary_accuracy: 0.8875\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1433 - binary_accuracy: 0.9625 - val_loss: 0.2903 - val_binary_accuracy: 0.8875\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1487 - binary_accuracy: 0.9875 - val_loss: 0.2874 - val_binary_accuracy: 0.9000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1358 - binary_accuracy: 0.9625 - val_loss: 0.3327 - val_binary_accuracy: 0.8625\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1317 - binary_accuracy: 1.0000 - val_loss: 0.4494 - val_binary_accuracy: 0.7500\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1229 - binary_accuracy: 1.0000 - val_loss: 0.8075 - val_binary_accuracy: 0.5375\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1262 - binary_accuracy: 0.9875 - val_loss: 1.0095 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1272 - binary_accuracy: 0.9875 - val_loss: 1.0640 - val_binary_accuracy: 0.5250\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1405 - binary_accuracy: 0.9750 - val_loss: 1.1879 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1318 - binary_accuracy: 1.0000 - val_loss: 1.2547 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1291 - binary_accuracy: 1.0000 - val_loss: 1.2277 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1497 - binary_accuracy: 0.9750 - val_loss: 1.1698 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1362 - binary_accuracy: 1.0000 - val_loss: 1.1833 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1249 - binary_accuracy: 1.0000 - val_loss: 1.1622 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1414 - binary_accuracy: 0.9875 - val_loss: 1.2270 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1302 - binary_accuracy: 0.9750 - val_loss: 1.2650 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1581 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.22it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.17it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6576 - binary_accuracy: 0.6375\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.7438 - binary_accuracy: 0.5125 - val_loss: 0.6826 - val_binary_accuracy: 0.5375\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6852 - binary_accuracy: 0.5500 - val_loss: 0.6912 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6407 - binary_accuracy: 0.6625 - val_loss: 0.7239 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6033 - binary_accuracy: 0.8250 - val_loss: 0.8065 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5832 - binary_accuracy: 0.8000 - val_loss: 0.8995 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5417 - binary_accuracy: 0.8375 - val_loss: 0.9792 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5140 - binary_accuracy: 0.8250 - val_loss: 1.0933 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4745 - binary_accuracy: 0.8875 - val_loss: 1.0154 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4943 - binary_accuracy: 0.8250 - val_loss: 0.9528 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4691 - binary_accuracy: 0.8250 - val_loss: 0.9056 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4570 - binary_accuracy: 0.8125 - val_loss: 1.0144 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4410 - binary_accuracy: 0.8500 - val_loss: 0.9342 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4162 - binary_accuracy: 0.9125 - val_loss: 0.8635 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4202 - binary_accuracy: 0.8875 - val_loss: 0.8099 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3957 - binary_accuracy: 0.8875 - val_loss: 0.6986 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4062 - binary_accuracy: 0.8625 - val_loss: 0.6582 - val_binary_accuracy: 0.5875\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3871 - binary_accuracy: 0.9250 - val_loss: 0.6433 - val_binary_accuracy: 0.6500\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4036 - binary_accuracy: 0.8125 - val_loss: 0.6429 - val_binary_accuracy: 0.7000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4008 - binary_accuracy: 0.8875 - val_loss: 0.7275 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3997 - binary_accuracy: 0.8625 - val_loss: 0.7215 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3827 - binary_accuracy: 0.8625 - val_loss: 0.6526 - val_binary_accuracy: 0.5750\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3760 - binary_accuracy: 0.9250 - val_loss: 0.6721 - val_binary_accuracy: 0.5875\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3490 - binary_accuracy: 0.9250 - val_loss: 0.9032 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3870 - binary_accuracy: 0.9500 - val_loss: 1.3864 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3642 - binary_accuracy: 0.8625 - val_loss: 1.6392 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3672 - binary_accuracy: 0.9125 - val_loss: 1.8010 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3578 - binary_accuracy: 0.9125 - val_loss: 1.7594 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3728 - binary_accuracy: 0.9125 - val_loss: 1.7114 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3304 - binary_accuracy: 0.9375 - val_loss: 1.5118 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3496 - binary_accuracy: 0.9125 - val_loss: 1.3951 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3576 - binary_accuracy: 0.8875 - val_loss: 1.3803 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3528 - binary_accuracy: 0.9250 - val_loss: 1.1451 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3285 - binary_accuracy: 0.9250 - val_loss: 1.0476 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3367 - binary_accuracy: 0.9125 - val_loss: 1.0714 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3351 - binary_accuracy: 0.9375 - val_loss: 1.1287 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3550 - binary_accuracy: 0.9125 - val_loss: 1.3253 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3570 - binary_accuracy: 0.8750 - val_loss: 1.5272 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3623 - binary_accuracy: 0.9125 - val_loss: 1.7778 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3184 - binary_accuracy: 0.9250 - val_loss: 1.7623 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3382 - binary_accuracy: 0.9250 - val_loss: 1.4523 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3348 - binary_accuracy: 0.9500 - val_loss: 0.8594 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3720 - binary_accuracy: 0.9250 - val_loss: 0.6530 - val_binary_accuracy: 0.6000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3349 - binary_accuracy: 0.9250 - val_loss: 0.6312 - val_binary_accuracy: 0.6750\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3133 - binary_accuracy: 0.9750 - val_loss: 0.6231 - val_binary_accuracy: 0.6250\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3179 - binary_accuracy: 0.9625 - val_loss: 0.6178 - val_binary_accuracy: 0.7000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3118 - binary_accuracy: 0.9500 - val_loss: 0.7088 - val_binary_accuracy: 0.5625\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3108 - binary_accuracy: 0.9125 - val_loss: 0.9088 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3333 - binary_accuracy: 0.9375 - val_loss: 1.2898 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3093 - binary_accuracy: 0.9375 - val_loss: 1.5440 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3291 - binary_accuracy: 0.9250 - val_loss: 1.6284 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3199 - binary_accuracy: 0.9500 - val_loss: 1.7028 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3313 - binary_accuracy: 0.9250 - val_loss: 1.7377 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3374 - binary_accuracy: 0.9250 - val_loss: 1.6211 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3256 - binary_accuracy: 0.9125 - val_loss: 1.4472 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3243 - binary_accuracy: 0.9375 - val_loss: 1.1713 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3167 - binary_accuracy: 0.9250 - val_loss: 0.9186 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3153 - binary_accuracy: 0.9125 - val_loss: 0.7593 - val_binary_accuracy: 0.5125\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3081 - binary_accuracy: 0.9375 - val_loss: 0.6615 - val_binary_accuracy: 0.5875\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3265 - binary_accuracy: 0.9625 - val_loss: 0.6298 - val_binary_accuracy: 0.6000\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3265 - binary_accuracy: 0.9250 - val_loss: 0.6906 - val_binary_accuracy: 0.5250\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2963 - binary_accuracy: 0.9625 - val_loss: 0.6609 - val_binary_accuracy: 0.5375\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3055 - binary_accuracy: 0.9500 - val_loss: 0.6462 - val_binary_accuracy: 0.5750\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3281 - binary_accuracy: 0.9375 - val_loss: 0.6687 - val_binary_accuracy: 0.5125\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3082 - binary_accuracy: 0.9375 - val_loss: 0.7613 - val_binary_accuracy: 0.5250\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2968 - binary_accuracy: 0.9250 - val_loss: 0.9355 - val_binary_accuracy: 0.5125\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2866 - binary_accuracy: 0.9875 - val_loss: 1.0008 - val_binary_accuracy: 0.5125\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3037 - binary_accuracy: 0.9500 - val_loss: 0.9410 - val_binary_accuracy: 0.5125\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3028 - binary_accuracy: 0.9250 - val_loss: 0.8429 - val_binary_accuracy: 0.5250\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3011 - binary_accuracy: 0.9500 - val_loss: 0.8553 - val_binary_accuracy: 0.5250\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3251 - binary_accuracy: 0.9125 - val_loss: 0.8828 - val_binary_accuracy: 0.5125\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2974 - binary_accuracy: 0.9500 - val_loss: 0.9450 - val_binary_accuracy: 0.5125\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3027 - binary_accuracy: 0.9625 - val_loss: 0.9863 - val_binary_accuracy: 0.5000\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2810 - binary_accuracy: 0.9750 - val_loss: 0.9579 - val_binary_accuracy: 0.5125\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2691 - binary_accuracy: 0.9625 - val_loss: 0.8911 - val_binary_accuracy: 0.5125\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2986 - binary_accuracy: 0.9500 - val_loss: 0.8055 - val_binary_accuracy: 0.5250\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3111 - binary_accuracy: 0.9750 - val_loss: 0.7404 - val_binary_accuracy: 0.5250\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2839 - binary_accuracy: 0.9875 - val_loss: 0.7158 - val_binary_accuracy: 0.5250\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2804 - binary_accuracy: 0.9625 - val_loss: 0.6823 - val_binary_accuracy: 0.5250\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3089 - binary_accuracy: 0.9125 - val_loss: 0.6757 - val_binary_accuracy: 0.5250\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3041 - binary_accuracy: 0.9125 - val_loss: 0.6674 - val_binary_accuracy: 0.5375\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2898 - binary_accuracy: 0.9500 - val_loss: 0.6328 - val_binary_accuracy: 0.6000\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2778 - binary_accuracy: 0.9625 - val_loss: 0.6177 - val_binary_accuracy: 0.6750\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2851 - binary_accuracy: 0.9625 - val_loss: 0.6144 - val_binary_accuracy: 0.6750\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2812 - binary_accuracy: 0.9625 - val_loss: 0.6082 - val_binary_accuracy: 0.7000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6683 - binary_accuracy: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.50it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.63it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7015 - binary_accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6841 - binary_accuracy: 0.5250\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.7357 - binary_accuracy: 0.4375 - val_loss: 0.7071 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - binary_accuracy: 0.5000 - val_loss: 0.7122 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6791 - binary_accuracy: 0.5750 - val_loss: 0.7079 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6686 - binary_accuracy: 0.6375 - val_loss: 0.6987 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6571 - binary_accuracy: 0.7250 - val_loss: 0.6947 - val_binary_accuracy: 0.5125\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6381 - binary_accuracy: 0.7375 - val_loss: 0.6936 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6222 - binary_accuracy: 0.7875 - val_loss: 0.6943 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6244 - binary_accuracy: 0.7750 - val_loss: 0.6923 - val_binary_accuracy: 0.4750\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6051 - binary_accuracy: 0.7625 - val_loss: 0.6914 - val_binary_accuracy: 0.5625\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5875 - binary_accuracy: 0.7875 - val_loss: 0.6912 - val_binary_accuracy: 0.5375\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5792 - binary_accuracy: 0.8375 - val_loss: 0.6915 - val_binary_accuracy: 0.5375\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5605 - binary_accuracy: 0.8750 - val_loss: 0.6978 - val_binary_accuracy: 0.5125\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5619 - binary_accuracy: 0.8000 - val_loss: 0.7096 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5443 - binary_accuracy: 0.9125 - val_loss: 0.7141 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5539 - binary_accuracy: 0.8000 - val_loss: 0.7215 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5235 - binary_accuracy: 0.8375 - val_loss: 0.7286 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5124 - binary_accuracy: 0.8625 - val_loss: 0.7485 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5366 - binary_accuracy: 0.8375 - val_loss: 0.7647 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5075 - binary_accuracy: 0.9000 - val_loss: 0.7843 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5052 - binary_accuracy: 0.8625 - val_loss: 0.7948 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4942 - binary_accuracy: 0.8500 - val_loss: 0.8085 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4943 - binary_accuracy: 0.9000 - val_loss: 0.8350 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4872 - binary_accuracy: 0.8875 - val_loss: 0.8853 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4905 - binary_accuracy: 0.9000 - val_loss: 0.9472 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4743 - binary_accuracy: 0.9375 - val_loss: 1.0333 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4714 - binary_accuracy: 0.9125 - val_loss: 1.1133 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4879 - binary_accuracy: 0.8625 - val_loss: 1.1387 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4791 - binary_accuracy: 0.9000 - val_loss: 1.1533 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4633 - binary_accuracy: 0.9125 - val_loss: 1.2282 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4596 - binary_accuracy: 0.9125 - val_loss: 1.3094 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4685 - binary_accuracy: 0.9000 - val_loss: 1.4142 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4359 - binary_accuracy: 0.9375 - val_loss: 1.5920 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4623 - binary_accuracy: 0.9125 - val_loss: 1.7409 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4462 - binary_accuracy: 0.9250 - val_loss: 1.9334 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4483 - binary_accuracy: 0.9750 - val_loss: 1.9705 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4576 - binary_accuracy: 0.9125 - val_loss: 1.7418 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4333 - binary_accuracy: 0.9000 - val_loss: 1.6478 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4439 - binary_accuracy: 0.9125 - val_loss: 1.4954 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4443 - binary_accuracy: 0.9250 - val_loss: 1.1690 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4504 - binary_accuracy: 0.9375 - val_loss: 0.9814 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4173 - binary_accuracy: 0.9125 - val_loss: 0.9301 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4346 - binary_accuracy: 0.9375 - val_loss: 1.1493 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4252 - binary_accuracy: 0.9500 - val_loss: 1.2433 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4020 - binary_accuracy: 0.9750 - val_loss: 1.2058 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4203 - binary_accuracy: 0.9500 - val_loss: 1.1614 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4335 - binary_accuracy: 0.9500 - val_loss: 1.2589 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4184 - binary_accuracy: 0.9500 - val_loss: 1.3288 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4385 - binary_accuracy: 0.9000 - val_loss: 1.4721 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4221 - binary_accuracy: 0.9750 - val_loss: 1.6821 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4223 - binary_accuracy: 0.9625 - val_loss: 1.7280 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4095 - binary_accuracy: 0.9250 - val_loss: 1.5860 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4166 - binary_accuracy: 0.9250 - val_loss: 1.4685 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4054 - binary_accuracy: 0.9625 - val_loss: 1.3816 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4148 - binary_accuracy: 0.9500 - val_loss: 1.3137 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6984 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.19it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.27it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6429 - binary_accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6227 - binary_accuracy: 0.6875\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7184 - binary_accuracy: 0.5500 - val_loss: 0.7189 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6641 - binary_accuracy: 0.6250 - val_loss: 0.7119 - val_binary_accuracy: 0.4750\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6418 - binary_accuracy: 0.6625 - val_loss: 0.7045 - val_binary_accuracy: 0.4750\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5809 - binary_accuracy: 0.8375 - val_loss: 0.7013 - val_binary_accuracy: 0.5375\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5554 - binary_accuracy: 0.8250 - val_loss: 0.6990 - val_binary_accuracy: 0.5625\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5310 - binary_accuracy: 0.8250 - val_loss: 0.7075 - val_binary_accuracy: 0.4875\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5055 - binary_accuracy: 0.8625 - val_loss: 0.7291 - val_binary_accuracy: 0.5125\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4709 - binary_accuracy: 0.9125 - val_loss: 0.7384 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4681 - binary_accuracy: 0.8750 - val_loss: 0.7161 - val_binary_accuracy: 0.5250\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4381 - binary_accuracy: 0.9000 - val_loss: 0.7089 - val_binary_accuracy: 0.5250\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4556 - binary_accuracy: 0.8875 - val_loss: 0.7300 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4308 - binary_accuracy: 0.9375 - val_loss: 0.7654 - val_binary_accuracy: 0.5125\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4221 - binary_accuracy: 0.8750 - val_loss: 0.8056 - val_binary_accuracy: 0.4875\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4067 - binary_accuracy: 0.9250 - val_loss: 0.8449 - val_binary_accuracy: 0.4875\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4128 - binary_accuracy: 0.9000 - val_loss: 0.8838 - val_binary_accuracy: 0.4875\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4126 - binary_accuracy: 0.9500 - val_loss: 0.9692 - val_binary_accuracy: 0.4875\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3948 - binary_accuracy: 0.9000 - val_loss: 1.0867 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3846 - binary_accuracy: 0.9250 - val_loss: 1.1040 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3888 - binary_accuracy: 0.9000 - val_loss: 1.0775 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3991 - binary_accuracy: 0.9375 - val_loss: 1.0372 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3865 - binary_accuracy: 0.9375 - val_loss: 1.0142 - val_binary_accuracy: 0.4875\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3943 - binary_accuracy: 0.9000 - val_loss: 0.9837 - val_binary_accuracy: 0.4875\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3779 - binary_accuracy: 0.9500 - val_loss: 0.8820 - val_binary_accuracy: 0.4875\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4088 - binary_accuracy: 0.9000 - val_loss: 0.8059 - val_binary_accuracy: 0.4875\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3555 - binary_accuracy: 0.9250 - val_loss: 0.7908 - val_binary_accuracy: 0.4875\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3637 - binary_accuracy: 0.9125 - val_loss: 0.8072 - val_binary_accuracy: 0.4875\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3664 - binary_accuracy: 0.8875 - val_loss: 0.8427 - val_binary_accuracy: 0.4875\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3844 - binary_accuracy: 0.9375 - val_loss: 0.8693 - val_binary_accuracy: 0.4875\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3627 - binary_accuracy: 0.9875 - val_loss: 0.8980 - val_binary_accuracy: 0.4875\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3737 - binary_accuracy: 0.9625 - val_loss: 0.9122 - val_binary_accuracy: 0.4875\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3693 - binary_accuracy: 0.9375 - val_loss: 0.8233 - val_binary_accuracy: 0.4875\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3764 - binary_accuracy: 0.9375 - val_loss: 0.7684 - val_binary_accuracy: 0.4875\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3786 - binary_accuracy: 0.9750 - val_loss: 0.7247 - val_binary_accuracy: 0.5750\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3737 - binary_accuracy: 0.9250 - val_loss: 0.7068 - val_binary_accuracy: 0.6000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3495 - binary_accuracy: 0.9750 - val_loss: 0.7028 - val_binary_accuracy: 0.6000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3796 - binary_accuracy: 0.9375 - val_loss: 0.7018 - val_binary_accuracy: 0.5750\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3593 - binary_accuracy: 0.9250 - val_loss: 0.7005 - val_binary_accuracy: 0.6000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3704 - binary_accuracy: 0.9375 - val_loss: 0.6999 - val_binary_accuracy: 0.5625\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3747 - binary_accuracy: 0.9250 - val_loss: 0.7027 - val_binary_accuracy: 0.5250\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3613 - binary_accuracy: 0.9625 - val_loss: 0.7063 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3655 - binary_accuracy: 0.9250 - val_loss: 0.7092 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3689 - binary_accuracy: 0.9250 - val_loss: 0.7209 - val_binary_accuracy: 0.5125\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3621 - binary_accuracy: 0.9500 - val_loss: 0.7524 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3367 - binary_accuracy: 0.9375 - val_loss: 0.7724 - val_binary_accuracy: 0.5250\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3442 - binary_accuracy: 0.9625 - val_loss: 0.7663 - val_binary_accuracy: 0.4875\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3570 - binary_accuracy: 0.9250 - val_loss: 0.7665 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3440 - binary_accuracy: 0.9375 - val_loss: 0.7704 - val_binary_accuracy: 0.4875\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3525 - binary_accuracy: 0.8875 - val_loss: 0.7730 - val_binary_accuracy: 0.5125\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3534 - binary_accuracy: 0.9375 - val_loss: 0.7653 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3636 - binary_accuracy: 0.9500 - val_loss: 0.7631 - val_binary_accuracy: 0.5125\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3338 - binary_accuracy: 0.9500 - val_loss: 0.7386 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3315 - binary_accuracy: 0.9500 - val_loss: 0.7237 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3260 - binary_accuracy: 0.9625 - val_loss: 0.7047 - val_binary_accuracy: 0.5500\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3384 - binary_accuracy: 0.9625 - val_loss: 0.7018 - val_binary_accuracy: 0.5875\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3166 - binary_accuracy: 0.9750 - val_loss: 0.7203 - val_binary_accuracy: 0.5875\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3311 - binary_accuracy: 0.9625 - val_loss: 0.7335 - val_binary_accuracy: 0.6000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3199 - binary_accuracy: 0.9750 - val_loss: 0.7367 - val_binary_accuracy: 0.6000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3414 - binary_accuracy: 0.9500 - val_loss: 0.7173 - val_binary_accuracy: 0.5875\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3449 - binary_accuracy: 0.9500 - val_loss: 0.7097 - val_binary_accuracy: 0.5625\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3711 - binary_accuracy: 0.9375 - val_loss: 0.7216 - val_binary_accuracy: 0.5125\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3390 - binary_accuracy: 0.9375 - val_loss: 0.7872 - val_binary_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3295 - binary_accuracy: 0.9750 - val_loss: 0.8487 - val_binary_accuracy: 0.5000\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3421 - binary_accuracy: 0.9875 - val_loss: 0.8836 - val_binary_accuracy: 0.5000\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3188 - binary_accuracy: 0.9500 - val_loss: 0.9353 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3436 - binary_accuracy: 0.9500 - val_loss: 0.9245 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6568 - binary_accuracy: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.59it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.79it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4013 - binary_accuracy: 0.9000\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9247 - binary_accuracy: 0.4250 - val_loss: 0.6686 - val_binary_accuracy: 0.6000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6523 - binary_accuracy: 0.6625 - val_loss: 0.6136 - val_binary_accuracy: 0.7250\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5222 - binary_accuracy: 0.8125 - val_loss: 0.6436 - val_binary_accuracy: 0.5750\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4546 - binary_accuracy: 0.8750 - val_loss: 0.7975 - val_binary_accuracy: 0.5125\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3990 - binary_accuracy: 0.8750 - val_loss: 1.0537 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3544 - binary_accuracy: 0.9125 - val_loss: 1.3695 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3452 - binary_accuracy: 0.9250 - val_loss: 1.6483 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3121 - binary_accuracy: 0.9375 - val_loss: 1.7705 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2903 - binary_accuracy: 0.9500 - val_loss: 1.7075 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2894 - binary_accuracy: 0.9375 - val_loss: 1.8373 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2875 - binary_accuracy: 0.9500 - val_loss: 2.0583 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2772 - binary_accuracy: 0.9250 - val_loss: 2.1525 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2925 - binary_accuracy: 0.9375 - val_loss: 2.0465 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2583 - binary_accuracy: 0.9750 - val_loss: 1.9931 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2759 - binary_accuracy: 0.9500 - val_loss: 2.0491 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2391 - binary_accuracy: 0.9625 - val_loss: 2.1621 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2509 - binary_accuracy: 0.9500 - val_loss: 2.3578 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2539 - binary_accuracy: 0.9625 - val_loss: 2.6013 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2505 - binary_accuracy: 0.9500 - val_loss: 2.8398 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2401 - binary_accuracy: 0.9750 - val_loss: 2.9571 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2365 - binary_accuracy: 0.9875 - val_loss: 3.0704 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2649 - binary_accuracy: 0.9375 - val_loss: 3.0943 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2318 - binary_accuracy: 0.9875 - val_loss: 3.2205 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2472 - binary_accuracy: 0.9625 - val_loss: 3.2791 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2292 - binary_accuracy: 0.9875 - val_loss: 3.1242 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2664 - binary_accuracy: 0.9375 - val_loss: 2.9428 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2143 - binary_accuracy: 0.9875 - val_loss: 2.7931 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2420 - binary_accuracy: 0.9500 - val_loss: 2.6818 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2218 - binary_accuracy: 0.9875 - val_loss: 2.6653 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2484 - binary_accuracy: 0.9750 - val_loss: 2.5855 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2283 - binary_accuracy: 0.9875 - val_loss: 2.3406 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2194 - binary_accuracy: 1.0000 - val_loss: 2.1092 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2522 - binary_accuracy: 0.9500 - val_loss: 1.9974 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2154 - binary_accuracy: 0.9750 - val_loss: 2.0190 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2155 - binary_accuracy: 0.9625 - val_loss: 1.9965 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2464 - binary_accuracy: 0.9750 - val_loss: 1.9325 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2959 - binary_accuracy: 0.9000 - val_loss: 1.9049 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3555 - binary_accuracy: 0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.49it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.45it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6371 - binary_accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6829 - binary_accuracy: 0.5750\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.7715 - binary_accuracy: 0.4875 - val_loss: 0.7129 - val_binary_accuracy: 0.4750\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6792 - binary_accuracy: 0.5750 - val_loss: 0.7023 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6547 - binary_accuracy: 0.7250 - val_loss: 0.6882 - val_binary_accuracy: 0.4500\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6121 - binary_accuracy: 0.7375 - val_loss: 0.6854 - val_binary_accuracy: 0.4875\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5891 - binary_accuracy: 0.7250 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5639 - binary_accuracy: 0.7375 - val_loss: 0.6930 - val_binary_accuracy: 0.5125\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5424 - binary_accuracy: 0.8250 - val_loss: 0.6810 - val_binary_accuracy: 0.5500\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5212 - binary_accuracy: 0.7500 - val_loss: 0.6649 - val_binary_accuracy: 0.5500\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5099 - binary_accuracy: 0.8000 - val_loss: 0.6640 - val_binary_accuracy: 0.6375\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4905 - binary_accuracy: 0.8375 - val_loss: 0.6870 - val_binary_accuracy: 0.5875\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.4683 - binary_accuracy: 0.8625 - val_loss: 0.7196 - val_binary_accuracy: 0.5500\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4974 - binary_accuracy: 0.8125 - val_loss: 0.7255 - val_binary_accuracy: 0.5500\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4684 - binary_accuracy: 0.8250 - val_loss: 0.7307 - val_binary_accuracy: 0.5500\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4453 - binary_accuracy: 0.8625 - val_loss: 0.7201 - val_binary_accuracy: 0.5625\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4492 - binary_accuracy: 0.8500 - val_loss: 0.6977 - val_binary_accuracy: 0.6000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4367 - binary_accuracy: 0.8875 - val_loss: 0.6845 - val_binary_accuracy: 0.6125\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4241 - binary_accuracy: 0.8625 - val_loss: 0.6735 - val_binary_accuracy: 0.6125\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4110 - binary_accuracy: 0.8750 - val_loss: 0.6679 - val_binary_accuracy: 0.6250\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4403 - binary_accuracy: 0.8375 - val_loss: 0.6700 - val_binary_accuracy: 0.6250\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4771 - binary_accuracy: 0.7875 - val_loss: 0.6741 - val_binary_accuracy: 0.6125\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4359 - binary_accuracy: 0.8625 - val_loss: 0.6621 - val_binary_accuracy: 0.6000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4340 - binary_accuracy: 0.8625 - val_loss: 0.6616 - val_binary_accuracy: 0.5750\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3992 - binary_accuracy: 0.9125 - val_loss: 0.6644 - val_binary_accuracy: 0.6000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4003 - binary_accuracy: 0.8875 - val_loss: 0.6701 - val_binary_accuracy: 0.5750\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4186 - binary_accuracy: 0.8625 - val_loss: 0.6687 - val_binary_accuracy: 0.5875\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4147 - binary_accuracy: 0.8750 - val_loss: 0.6642 - val_binary_accuracy: 0.6000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3902 - binary_accuracy: 0.8750 - val_loss: 0.6558 - val_binary_accuracy: 0.6000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4144 - binary_accuracy: 0.8875 - val_loss: 0.6536 - val_binary_accuracy: 0.6000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3843 - binary_accuracy: 0.9125 - val_loss: 0.6502 - val_binary_accuracy: 0.6125\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4015 - binary_accuracy: 0.8625 - val_loss: 0.6482 - val_binary_accuracy: 0.6250\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3727 - binary_accuracy: 0.9500 - val_loss: 0.6537 - val_binary_accuracy: 0.6000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4062 - binary_accuracy: 0.9125 - val_loss: 0.6678 - val_binary_accuracy: 0.5625\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3924 - binary_accuracy: 0.8875 - val_loss: 0.6720 - val_binary_accuracy: 0.5375\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3550 - binary_accuracy: 0.9375 - val_loss: 0.6797 - val_binary_accuracy: 0.5625\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3938 - binary_accuracy: 0.9000 - val_loss: 0.6871 - val_binary_accuracy: 0.5500\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4010 - binary_accuracy: 0.9000 - val_loss: 0.6946 - val_binary_accuracy: 0.5250\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3860 - binary_accuracy: 0.9000 - val_loss: 0.7193 - val_binary_accuracy: 0.5375\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3901 - binary_accuracy: 0.9375 - val_loss: 0.7444 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3759 - binary_accuracy: 0.9000 - val_loss: 0.7922 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3950 - binary_accuracy: 0.8875 - val_loss: 0.9257 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3794 - binary_accuracy: 0.8875 - val_loss: 1.0625 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3957 - binary_accuracy: 0.9250 - val_loss: 1.0336 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3939 - binary_accuracy: 0.8750 - val_loss: 0.9539 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3740 - binary_accuracy: 0.8625 - val_loss: 0.8933 - val_binary_accuracy: 0.5125\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6722 - binary_accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.54it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.61it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6625 - binary_accuracy: 0.5750\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7343 - binary_accuracy: 0.4500 - val_loss: 0.6995 - val_binary_accuracy: 0.4875\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.7059 - binary_accuracy: 0.5000 - val_loss: 0.7775 - val_binary_accuracy: 0.4875\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6784 - binary_accuracy: 0.5500 - val_loss: 0.8297 - val_binary_accuracy: 0.4875\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6685 - binary_accuracy: 0.5375 - val_loss: 0.8940 - val_binary_accuracy: 0.4750\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6641 - binary_accuracy: 0.5625 - val_loss: 0.9922 - val_binary_accuracy: 0.4375\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6566 - binary_accuracy: 0.6375 - val_loss: 1.1100 - val_binary_accuracy: 0.5375\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6353 - binary_accuracy: 0.6000 - val_loss: 1.2412 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6245 - binary_accuracy: 0.6000 - val_loss: 1.3210 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6315 - binary_accuracy: 0.5500 - val_loss: 1.3372 - val_binary_accuracy: 0.4625\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6284 - binary_accuracy: 0.5875 - val_loss: 1.2391 - val_binary_accuracy: 0.4875\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6286 - binary_accuracy: 0.6125 - val_loss: 1.1286 - val_binary_accuracy: 0.4875\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6395 - binary_accuracy: 0.6500 - val_loss: 1.0613 - val_binary_accuracy: 0.4875\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5965 - binary_accuracy: 0.7125 - val_loss: 1.0283 - val_binary_accuracy: 0.4875\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6160 - binary_accuracy: 0.6625 - val_loss: 1.0548 - val_binary_accuracy: 0.4875\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6074 - binary_accuracy: 0.7125 - val_loss: 1.0685 - val_binary_accuracy: 0.5125\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6284 - binary_accuracy: 0.5750 - val_loss: 1.0593 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5625 - binary_accuracy: 0.7375 - val_loss: 1.0276 - val_binary_accuracy: 0.4875\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5988 - binary_accuracy: 0.6750 - val_loss: 1.0378 - val_binary_accuracy: 0.4875\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6217 - binary_accuracy: 0.6500 - val_loss: 1.0633 - val_binary_accuracy: 0.4875\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5857 - binary_accuracy: 0.7125 - val_loss: 1.0681 - val_binary_accuracy: 0.4875\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6034 - binary_accuracy: 0.7125 - val_loss: 1.0713 - val_binary_accuracy: 0.4875\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5866 - binary_accuracy: 0.6875 - val_loss: 1.1403 - val_binary_accuracy: 0.4875\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5840 - binary_accuracy: 0.6875 - val_loss: 1.2333 - val_binary_accuracy: 0.4875\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5774 - binary_accuracy: 0.7125 - val_loss: 1.2912 - val_binary_accuracy: 0.4875\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5938 - binary_accuracy: 0.7500 - val_loss: 1.3613 - val_binary_accuracy: 0.4875\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5650 - binary_accuracy: 0.7000 - val_loss: 1.4334 - val_binary_accuracy: 0.4875\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5745 - binary_accuracy: 0.7375 - val_loss: 1.5197 - val_binary_accuracy: 0.4875\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7064 - binary_accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.57it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.50it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6509 - binary_accuracy: 0.6250\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7866 - binary_accuracy: 0.5250 - val_loss: 0.8874 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6852 - binary_accuracy: 0.5500 - val_loss: 1.0121 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6494 - binary_accuracy: 0.6375 - val_loss: 1.1101 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6336 - binary_accuracy: 0.7125 - val_loss: 1.1539 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5811 - binary_accuracy: 0.8125 - val_loss: 1.1584 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5835 - binary_accuracy: 0.7750 - val_loss: 1.1149 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5455 - binary_accuracy: 0.8000 - val_loss: 1.0496 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5278 - binary_accuracy: 0.8250 - val_loss: 0.9914 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5206 - binary_accuracy: 0.8000 - val_loss: 0.9802 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5072 - binary_accuracy: 0.8125 - val_loss: 1.1155 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4962 - binary_accuracy: 0.8500 - val_loss: 1.2774 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4812 - binary_accuracy: 0.8625 - val_loss: 1.4165 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4879 - binary_accuracy: 0.8625 - val_loss: 1.3809 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4456 - binary_accuracy: 0.8875 - val_loss: 1.3775 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4766 - binary_accuracy: 0.8375 - val_loss: 1.2594 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4552 - binary_accuracy: 0.8125 - val_loss: 1.2019 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4555 - binary_accuracy: 0.8875 - val_loss: 1.2639 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4416 - binary_accuracy: 0.8375 - val_loss: 1.1773 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4203 - binary_accuracy: 0.9375 - val_loss: 1.5852 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4346 - binary_accuracy: 0.9000 - val_loss: 2.5554 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4181 - binary_accuracy: 0.9375 - val_loss: 3.3738 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4297 - binary_accuracy: 0.9125 - val_loss: 4.1178 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3973 - binary_accuracy: 0.9125 - val_loss: 5.0822 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3942 - binary_accuracy: 0.9750 - val_loss: 5.5869 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3943 - binary_accuracy: 0.9375 - val_loss: 5.3389 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3907 - binary_accuracy: 0.9375 - val_loss: 5.3204 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3919 - binary_accuracy: 0.9875 - val_loss: 4.0396 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3975 - binary_accuracy: 0.9125 - val_loss: 3.2031 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4203 - binary_accuracy: 0.9000 - val_loss: 2.7890 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3892 - binary_accuracy: 0.9375 - val_loss: 2.3719 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3913 - binary_accuracy: 0.9500 - val_loss: 2.0137 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3708 - binary_accuracy: 0.9625 - val_loss: 1.6103 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3972 - binary_accuracy: 0.9625 - val_loss: 1.8405 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3812 - binary_accuracy: 0.9375 - val_loss: 1.7710 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3940 - binary_accuracy: 0.9375 - val_loss: 1.7216 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3832 - binary_accuracy: 0.9250 - val_loss: 1.6418 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3718 - binary_accuracy: 0.9750 - val_loss: 1.1568 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3604 - binary_accuracy: 0.9750 - val_loss: 0.9570 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3644 - binary_accuracy: 0.9625 - val_loss: 0.9693 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3723 - binary_accuracy: 0.9125 - val_loss: 1.0833 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3633 - binary_accuracy: 0.9375 - val_loss: 1.9199 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3968 - binary_accuracy: 0.9250 - val_loss: 2.7677 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3806 - binary_accuracy: 0.9375 - val_loss: 4.4741 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3708 - binary_accuracy: 0.9500 - val_loss: 6.0999 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3451 - binary_accuracy: 0.9500 - val_loss: 6.6009 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3667 - binary_accuracy: 0.9625 - val_loss: 6.8568 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3544 - binary_accuracy: 0.9875 - val_loss: 6.3979 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3460 - binary_accuracy: 0.9875 - val_loss: 5.3137 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3535 - binary_accuracy: 0.9375 - val_loss: 4.4001 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3694 - binary_accuracy: 0.9375 - val_loss: 3.2002 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3773 - binary_accuracy: 0.9125 - val_loss: 1.9520 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3636 - binary_accuracy: 0.9375 - val_loss: 1.0252 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3456 - binary_accuracy: 0.9500 - val_loss: 0.9905 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3338 - binary_accuracy: 0.9625 - val_loss: 1.9049 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3254 - binary_accuracy: 0.9500 - val_loss: 2.7889 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3474 - binary_accuracy: 0.9625 - val_loss: 2.9849 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3156 - binary_accuracy: 0.9250 - val_loss: 2.5514 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3378 - binary_accuracy: 0.9500 - val_loss: 2.4718 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3355 - binary_accuracy: 0.9625 - val_loss: 2.2236 - val_binary_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3400 - binary_accuracy: 0.9250 - val_loss: 0.7411 - val_binary_accuracy: 0.5375\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3475 - binary_accuracy: 0.9625 - val_loss: 0.7074 - val_binary_accuracy: 0.6000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3432 - binary_accuracy: 0.9250 - val_loss: 1.0014 - val_binary_accuracy: 0.5625\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3436 - binary_accuracy: 0.9500 - val_loss: 1.1849 - val_binary_accuracy: 0.5250\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3230 - binary_accuracy: 0.9750 - val_loss: 1.3069 - val_binary_accuracy: 0.5250\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3389 - binary_accuracy: 0.9625 - val_loss: 1.3311 - val_binary_accuracy: 0.5250\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3182 - binary_accuracy: 0.9625 - val_loss: 1.3145 - val_binary_accuracy: 0.5250\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3335 - binary_accuracy: 0.9500 - val_loss: 1.1135 - val_binary_accuracy: 0.5375\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6634 - binary_accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  5.09it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  5.24it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6472 - binary_accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6624 - binary_accuracy: 0.6375\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7313 - binary_accuracy: 0.5125 - val_loss: 0.7175 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6924 - binary_accuracy: 0.5125 - val_loss: 0.7115 - val_binary_accuracy: 0.5375\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6731 - binary_accuracy: 0.6000 - val_loss: 0.7160 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6528 - binary_accuracy: 0.6500 - val_loss: 0.7251 - val_binary_accuracy: 0.5375\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6259 - binary_accuracy: 0.7000 - val_loss: 0.7387 - val_binary_accuracy: 0.4625\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6057 - binary_accuracy: 0.7250 - val_loss: 0.7813 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5853 - binary_accuracy: 0.7500 - val_loss: 0.9321 - val_binary_accuracy: 0.4875\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5778 - binary_accuracy: 0.7875 - val_loss: 1.1892 - val_binary_accuracy: 0.4875\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5512 - binary_accuracy: 0.7625 - val_loss: 1.7007 - val_binary_accuracy: 0.4875\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5137 - binary_accuracy: 0.8625 - val_loss: 2.0062 - val_binary_accuracy: 0.4875\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5412 - binary_accuracy: 0.7500 - val_loss: 2.3293 - val_binary_accuracy: 0.4875\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5237 - binary_accuracy: 0.8000 - val_loss: 2.5345 - val_binary_accuracy: 0.4875\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5317 - binary_accuracy: 0.8000 - val_loss: 2.6464 - val_binary_accuracy: 0.4875\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4980 - binary_accuracy: 0.8500 - val_loss: 2.8802 - val_binary_accuracy: 0.4875\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4775 - binary_accuracy: 0.8125 - val_loss: 2.9189 - val_binary_accuracy: 0.4875\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4681 - binary_accuracy: 0.8750 - val_loss: 2.9037 - val_binary_accuracy: 0.4875\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4829 - binary_accuracy: 0.8375 - val_loss: 2.9514 - val_binary_accuracy: 0.4875\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4695 - binary_accuracy: 0.9250 - val_loss: 3.2697 - val_binary_accuracy: 0.4875\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4745 - binary_accuracy: 0.8625 - val_loss: 3.5979 - val_binary_accuracy: 0.4875\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4772 - binary_accuracy: 0.8125 - val_loss: 4.2264 - val_binary_accuracy: 0.4875\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4296 - binary_accuracy: 0.9250 - val_loss: 4.9237 - val_binary_accuracy: 0.4875\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4598 - binary_accuracy: 0.9125 - val_loss: 5.0897 - val_binary_accuracy: 0.4875\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4328 - binary_accuracy: 0.8625 - val_loss: 5.2325 - val_binary_accuracy: 0.4875\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4341 - binary_accuracy: 0.9000 - val_loss: 4.8908 - val_binary_accuracy: 0.4875\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4355 - binary_accuracy: 0.9125 - val_loss: 4.2904 - val_binary_accuracy: 0.4875\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4235 - binary_accuracy: 0.9125 - val_loss: 3.7369 - val_binary_accuracy: 0.4875\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4317 - binary_accuracy: 0.8750 - val_loss: 3.1031 - val_binary_accuracy: 0.4875\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4317 - binary_accuracy: 0.8750 - val_loss: 2.7878 - val_binary_accuracy: 0.4875\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4072 - binary_accuracy: 0.9125 - val_loss: 2.7764 - val_binary_accuracy: 0.4875\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4081 - binary_accuracy: 0.9250 - val_loss: 2.4382 - val_binary_accuracy: 0.4875\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4249 - binary_accuracy: 0.9000 - val_loss: 2.3210 - val_binary_accuracy: 0.4875\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3992 - binary_accuracy: 0.9000 - val_loss: 1.8350 - val_binary_accuracy: 0.4875\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4241 - binary_accuracy: 0.8750 - val_loss: 1.9094 - val_binary_accuracy: 0.4875\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4170 - binary_accuracy: 0.8500 - val_loss: 1.8314 - val_binary_accuracy: 0.4875\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3926 - binary_accuracy: 0.9125 - val_loss: 1.6015 - val_binary_accuracy: 0.4875\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4190 - binary_accuracy: 0.9000 - val_loss: 1.4166 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3677 - binary_accuracy: 0.9375 - val_loss: 1.3391 - val_binary_accuracy: 0.5125\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3931 - binary_accuracy: 0.9125 - val_loss: 1.3066 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4034 - binary_accuracy: 0.9125 - val_loss: 1.5648 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4095 - binary_accuracy: 0.9375 - val_loss: 1.8795 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3916 - binary_accuracy: 0.9000 - val_loss: 2.4033 - val_binary_accuracy: 0.4875\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3757 - binary_accuracy: 0.9375 - val_loss: 3.0335 - val_binary_accuracy: 0.4875\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3994 - binary_accuracy: 0.9125 - val_loss: 3.8758 - val_binary_accuracy: 0.4875\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3650 - binary_accuracy: 0.9375 - val_loss: 4.3407 - val_binary_accuracy: 0.4875\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3792 - binary_accuracy: 0.9375 - val_loss: 4.3682 - val_binary_accuracy: 0.4875\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3987 - binary_accuracy: 0.8750 - val_loss: 4.6665 - val_binary_accuracy: 0.4875\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3771 - binary_accuracy: 0.9000 - val_loss: 5.0360 - val_binary_accuracy: 0.4875\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3829 - binary_accuracy: 0.9000 - val_loss: 5.5410 - val_binary_accuracy: 0.4875\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3635 - binary_accuracy: 0.9250 - val_loss: 5.6556 - val_binary_accuracy: 0.4875\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3957 - binary_accuracy: 0.9375 - val_loss: 5.4813 - val_binary_accuracy: 0.4875\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3934 - binary_accuracy: 0.9250 - val_loss: 5.4114 - val_binary_accuracy: 0.4875\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3966 - binary_accuracy: 0.9000 - val_loss: 5.7185 - val_binary_accuracy: 0.4875\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3826 - binary_accuracy: 0.8875 - val_loss: 6.0067 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3613 - binary_accuracy: 0.9375 - val_loss: 6.0137 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3539 - binary_accuracy: 0.9375 - val_loss: 5.6193 - val_binary_accuracy: 0.4875\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3682 - binary_accuracy: 0.9375 - val_loss: 5.0783 - val_binary_accuracy: 0.4875\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3558 - binary_accuracy: 0.9125 - val_loss: 4.9692 - val_binary_accuracy: 0.4875\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3843 - binary_accuracy: 0.9250 - val_loss: 4.9220 - val_binary_accuracy: 0.4875\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3579 - binary_accuracy: 0.9125 - val_loss: 4.6085 - val_binary_accuracy: 0.4875\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3807 - binary_accuracy: 0.9000 - val_loss: 4.0787 - val_binary_accuracy: 0.4875\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3751 - binary_accuracy: 0.9000 - val_loss: 3.1897 - val_binary_accuracy: 0.4875\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3678 - binary_accuracy: 0.9250 - val_loss: 2.6052 - val_binary_accuracy: 0.4875\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3668 - binary_accuracy: 0.9000 - val_loss: 1.6057 - val_binary_accuracy: 0.4875\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3775 - binary_accuracy: 0.9125 - val_loss: 0.9882 - val_binary_accuracy: 0.4375\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3387 - binary_accuracy: 0.9500 - val_loss: 0.9799 - val_binary_accuracy: 0.4875\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3548 - binary_accuracy: 0.9250 - val_loss: 1.1356 - val_binary_accuracy: 0.4875\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3602 - binary_accuracy: 0.8875 - val_loss: 1.3189 - val_binary_accuracy: 0.5125\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3744 - binary_accuracy: 0.9375 - val_loss: 1.1989 - val_binary_accuracy: 0.5125\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3530 - binary_accuracy: 0.9625 - val_loss: 0.9384 - val_binary_accuracy: 0.5500\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3705 - binary_accuracy: 0.9750 - val_loss: 2.1530 - val_binary_accuracy: 0.4875\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3483 - binary_accuracy: 0.9375 - val_loss: 4.1287 - val_binary_accuracy: 0.4875\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3578 - binary_accuracy: 0.9375 - val_loss: 5.2941 - val_binary_accuracy: 0.4875\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3424 - binary_accuracy: 0.9250 - val_loss: 5.2166 - val_binary_accuracy: 0.4875\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3331 - binary_accuracy: 0.9250 - val_loss: 4.7697 - val_binary_accuracy: 0.4875\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3813 - binary_accuracy: 0.9250 - val_loss: 4.2420 - val_binary_accuracy: 0.4875\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.3685 - binary_accuracy: 0.9250 - val_loss: 3.2096 - val_binary_accuracy: 0.4875\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3315 - binary_accuracy: 0.9625 - val_loss: 2.4376 - val_binary_accuracy: 0.4875\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3436 - binary_accuracy: 0.9625 - val_loss: 1.8547 - val_binary_accuracy: 0.4875\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3555 - binary_accuracy: 0.9500 - val_loss: 1.1008 - val_binary_accuracy: 0.4750\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3323 - binary_accuracy: 0.9250 - val_loss: 0.9183 - val_binary_accuracy: 0.4875\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3367 - binary_accuracy: 0.9125 - val_loss: 1.0227 - val_binary_accuracy: 0.4750\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3482 - binary_accuracy: 0.9625 - val_loss: 1.1095 - val_binary_accuracy: 0.5000\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3411 - binary_accuracy: 0.9250 - val_loss: 1.0416 - val_binary_accuracy: 0.4750\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3370 - binary_accuracy: 0.9625 - val_loss: 1.2662 - val_binary_accuracy: 0.4875\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3515 - binary_accuracy: 0.9250 - val_loss: 1.1966 - val_binary_accuracy: 0.4750\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3392 - binary_accuracy: 0.9500 - val_loss: 1.2501 - val_binary_accuracy: 0.4750\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3332 - binary_accuracy: 0.9500 - val_loss: 1.1982 - val_binary_accuracy: 0.4750\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6905 - binary_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.76it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.69it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6605 - binary_accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6564 - binary_accuracy: 0.6375\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7226 - binary_accuracy: 0.6000 - val_loss: 0.6898 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6769 - binary_accuracy: 0.6125 - val_loss: 0.6845 - val_binary_accuracy: 0.5375\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6142 - binary_accuracy: 0.7125 - val_loss: 0.7364 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5749 - binary_accuracy: 0.8125 - val_loss: 1.2738 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5096 - binary_accuracy: 0.8500 - val_loss: 2.6742 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4720 - binary_accuracy: 0.8875 - val_loss: 4.6181 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.4261 - binary_accuracy: 0.9000 - val_loss: 7.8726 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4128 - binary_accuracy: 0.9000 - val_loss: 11.8349 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3850 - binary_accuracy: 0.9375 - val_loss: 15.1197 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3832 - binary_accuracy: 0.9000 - val_loss: 16.7518 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3745 - binary_accuracy: 0.9250 - val_loss: 17.0028 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3581 - binary_accuracy: 0.9250 - val_loss: 17.3531 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3372 - binary_accuracy: 0.9500 - val_loss: 16.6225 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3291 - binary_accuracy: 0.9500 - val_loss: 15.6140 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3339 - binary_accuracy: 0.9500 - val_loss: 14.3145 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3242 - binary_accuracy: 0.9375 - val_loss: 13.3241 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3129 - binary_accuracy: 0.9500 - val_loss: 12.8488 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3408 - binary_accuracy: 0.9125 - val_loss: 11.9126 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3069 - binary_accuracy: 0.9625 - val_loss: 11.0095 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2984 - binary_accuracy: 0.9500 - val_loss: 10.6171 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3016 - binary_accuracy: 0.9375 - val_loss: 10.4551 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3076 - binary_accuracy: 0.9625 - val_loss: 10.2247 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3062 - binary_accuracy: 0.9500 - val_loss: 9.8348 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3150 - binary_accuracy: 0.9500 - val_loss: 9.4209 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2917 - binary_accuracy: 0.9750 - val_loss: 9.3410 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2968 - binary_accuracy: 0.9750 - val_loss: 9.3100 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2990 - binary_accuracy: 0.9750 - val_loss: 9.1319 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2983 - binary_accuracy: 0.9500 - val_loss: 8.4739 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2736 - binary_accuracy: 0.9625 - val_loss: 7.9782 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2657 - binary_accuracy: 0.9875 - val_loss: 7.5262 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2876 - binary_accuracy: 0.9500 - val_loss: 7.3100 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2809 - binary_accuracy: 0.9875 - val_loss: 7.3075 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2738 - binary_accuracy: 0.9875 - val_loss: 7.4776 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2784 - binary_accuracy: 0.9625 - val_loss: 7.4367 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2855 - binary_accuracy: 0.9500 - val_loss: 7.0944 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2877 - binary_accuracy: 0.9750 - val_loss: 5.9123 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2791 - binary_accuracy: 0.9750 - val_loss: 5.2784 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2644 - binary_accuracy: 0.9625 - val_loss: 5.4174 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2440 - binary_accuracy: 0.9750 - val_loss: 5.5840 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2749 - binary_accuracy: 0.9750 - val_loss: 6.0171 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2740 - binary_accuracy: 0.9750 - val_loss: 6.2937 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3001 - binary_accuracy: 0.9500 - val_loss: 6.4994 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2632 - binary_accuracy: 0.9625 - val_loss: 6.4759 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2771 - binary_accuracy: 0.9625 - val_loss: 6.2986 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2609 - binary_accuracy: 0.9750 - val_loss: 6.2798 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2683 - binary_accuracy: 0.9625 - val_loss: 5.7482 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2562 - binary_accuracy: 0.9750 - val_loss: 5.2265 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2737 - binary_accuracy: 0.9875 - val_loss: 4.9163 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2562 - binary_accuracy: 0.9625 - val_loss: 4.7017 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6904 - binary_accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.82it/s]\n",
      "epoching: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "epoching: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6130 - binary_accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6252 - binary_accuracy: 0.5500\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7433 - binary_accuracy: 0.5625 - val_loss: 0.7106 - val_binary_accuracy: 0.5250\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6582 - binary_accuracy: 0.6750 - val_loss: 0.6812 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6161 - binary_accuracy: 0.6750 - val_loss: 0.6552 - val_binary_accuracy: 0.5500\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5634 - binary_accuracy: 0.7875 - val_loss: 0.6450 - val_binary_accuracy: 0.5750\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5213 - binary_accuracy: 0.8250 - val_loss: 0.6382 - val_binary_accuracy: 0.5750\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5092 - binary_accuracy: 0.8625 - val_loss: 0.6298 - val_binary_accuracy: 0.5750\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4967 - binary_accuracy: 0.8000 - val_loss: 0.6242 - val_binary_accuracy: 0.5750\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4759 - binary_accuracy: 0.8375 - val_loss: 0.6269 - val_binary_accuracy: 0.5750\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4679 - binary_accuracy: 0.8250 - val_loss: 0.6248 - val_binary_accuracy: 0.5750\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4395 - binary_accuracy: 0.8000 - val_loss: 0.6234 - val_binary_accuracy: 0.5500\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4734 - binary_accuracy: 0.8000 - val_loss: 0.6295 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4167 - binary_accuracy: 0.8875 - val_loss: 0.6219 - val_binary_accuracy: 0.5250\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4249 - binary_accuracy: 0.8500 - val_loss: 0.6169 - val_binary_accuracy: 0.5750\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4528 - binary_accuracy: 0.8125 - val_loss: 0.6217 - val_binary_accuracy: 0.5750\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4069 - binary_accuracy: 0.8500 - val_loss: 0.6248 - val_binary_accuracy: 0.5750\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4048 - binary_accuracy: 0.9125 - val_loss: 0.6362 - val_binary_accuracy: 0.5250\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3811 - binary_accuracy: 0.9125 - val_loss: 0.6539 - val_binary_accuracy: 0.4750\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3964 - binary_accuracy: 0.8750 - val_loss: 0.6562 - val_binary_accuracy: 0.4750\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4119 - binary_accuracy: 0.9125 - val_loss: 0.6451 - val_binary_accuracy: 0.4750\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4191 - binary_accuracy: 0.8625 - val_loss: 0.6312 - val_binary_accuracy: 0.6250\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3712 - binary_accuracy: 0.9625 - val_loss: 0.6331 - val_binary_accuracy: 0.6000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3708 - binary_accuracy: 0.9375 - val_loss: 0.6654 - val_binary_accuracy: 0.5750\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3780 - binary_accuracy: 0.9000 - val_loss: 0.7072 - val_binary_accuracy: 0.5750\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3950 - binary_accuracy: 0.9000 - val_loss: 0.7307 - val_binary_accuracy: 0.5750\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3590 - binary_accuracy: 0.9250 - val_loss: 0.7588 - val_binary_accuracy: 0.5750\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3596 - binary_accuracy: 0.9000 - val_loss: 0.8204 - val_binary_accuracy: 0.5750\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3352 - binary_accuracy: 0.9375 - val_loss: 0.8757 - val_binary_accuracy: 0.5750\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3636 - binary_accuracy: 0.8750 - val_loss: 0.8881 - val_binary_accuracy: 0.5750\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3515 - binary_accuracy: 0.8875 - val_loss: 0.8790 - val_binary_accuracy: 0.5750\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3774 - binary_accuracy: 0.8875 - val_loss: 0.8462 - val_binary_accuracy: 0.5750\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3621 - binary_accuracy: 0.9125 - val_loss: 0.7973 - val_binary_accuracy: 0.5750\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3750 - binary_accuracy: 0.8875 - val_loss: 0.7330 - val_binary_accuracy: 0.5750\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3400 - binary_accuracy: 0.9250 - val_loss: 0.6796 - val_binary_accuracy: 0.5750\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3770 - binary_accuracy: 0.8750 - val_loss: 0.6628 - val_binary_accuracy: 0.5750\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3601 - binary_accuracy: 0.9125 - val_loss: 0.6702 - val_binary_accuracy: 0.5250\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3961 - binary_accuracy: 0.8500 - val_loss: 0.7010 - val_binary_accuracy: 0.5500\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3601 - binary_accuracy: 0.9125 - val_loss: 0.7161 - val_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5633 - binary_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  5.07it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  5.25it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5636 - binary_accuracy: 0.6500\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.7426 - binary_accuracy: 0.5125 - val_loss: 0.6989 - val_binary_accuracy: 0.5125\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6633 - binary_accuracy: 0.6375 - val_loss: 0.6736 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6198 - binary_accuracy: 0.7500 - val_loss: 0.6471 - val_binary_accuracy: 0.7625\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5687 - binary_accuracy: 0.8875 - val_loss: 0.6447 - val_binary_accuracy: 0.5750\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5209 - binary_accuracy: 0.8750 - val_loss: 0.6636 - val_binary_accuracy: 0.5125\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4670 - binary_accuracy: 0.9125 - val_loss: 0.6511 - val_binary_accuracy: 0.5375\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4584 - binary_accuracy: 0.9000 - val_loss: 0.5507 - val_binary_accuracy: 0.7000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4034 - binary_accuracy: 0.9250 - val_loss: 0.5808 - val_binary_accuracy: 0.6125\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4068 - binary_accuracy: 0.9250 - val_loss: 1.4041 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3607 - binary_accuracy: 0.9375 - val_loss: 2.6040 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3897 - binary_accuracy: 0.9375 - val_loss: 4.0890 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3718 - binary_accuracy: 0.9250 - val_loss: 4.7508 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3635 - binary_accuracy: 0.9250 - val_loss: 3.8841 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3300 - binary_accuracy: 0.9750 - val_loss: 2.9816 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3329 - binary_accuracy: 0.9625 - val_loss: 2.2314 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3174 - binary_accuracy: 0.9625 - val_loss: 1.7412 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3185 - binary_accuracy: 0.9750 - val_loss: 1.3622 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3197 - binary_accuracy: 0.9375 - val_loss: 0.6345 - val_binary_accuracy: 0.5500\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3126 - binary_accuracy: 0.9375 - val_loss: 0.4461 - val_binary_accuracy: 0.8375\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3000 - binary_accuracy: 0.9750 - val_loss: 0.4471 - val_binary_accuracy: 0.8000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2986 - binary_accuracy: 0.9625 - val_loss: 0.4304 - val_binary_accuracy: 0.8500\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2970 - binary_accuracy: 0.9750 - val_loss: 0.6523 - val_binary_accuracy: 0.5125\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2974 - binary_accuracy: 0.9625 - val_loss: 0.4941 - val_binary_accuracy: 0.7125\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3181 - binary_accuracy: 0.9500 - val_loss: 0.4142 - val_binary_accuracy: 0.8500\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2780 - binary_accuracy: 0.9875 - val_loss: 0.7920 - val_binary_accuracy: 0.5625\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2728 - binary_accuracy: 0.9750 - val_loss: 1.3585 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2831 - binary_accuracy: 0.9375 - val_loss: 1.6015 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2824 - binary_accuracy: 0.9750 - val_loss: 1.5198 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2795 - binary_accuracy: 0.9875 - val_loss: 1.4044 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2882 - binary_accuracy: 0.9625 - val_loss: 1.1226 - val_binary_accuracy: 0.5125\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2881 - binary_accuracy: 0.9500 - val_loss: 0.8344 - val_binary_accuracy: 0.5375\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2710 - binary_accuracy: 0.9750 - val_loss: 0.4753 - val_binary_accuracy: 0.7625\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2876 - binary_accuracy: 0.9500 - val_loss: 1.0114 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2679 - binary_accuracy: 0.9875 - val_loss: 1.9560 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2981 - binary_accuracy: 0.9500 - val_loss: 1.1233 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2945 - binary_accuracy: 0.9625 - val_loss: 0.9353 - val_binary_accuracy: 0.5375\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2884 - binary_accuracy: 0.9375 - val_loss: 1.9890 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2656 - binary_accuracy: 0.9625 - val_loss: 2.4189 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2803 - binary_accuracy: 0.9500 - val_loss: 3.0127 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2903 - binary_accuracy: 0.9250 - val_loss: 3.1918 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2828 - binary_accuracy: 0.9375 - val_loss: 3.4734 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2801 - binary_accuracy: 0.9625 - val_loss: 3.7203 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2676 - binary_accuracy: 0.9875 - val_loss: 3.0106 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2608 - binary_accuracy: 0.9625 - val_loss: 1.4653 - val_binary_accuracy: 0.5125\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2497 - binary_accuracy: 0.9625 - val_loss: 0.4429 - val_binary_accuracy: 0.7625\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2746 - binary_accuracy: 0.9625 - val_loss: 1.0223 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2396 - binary_accuracy: 0.9750 - val_loss: 2.0882 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2500 - binary_accuracy: 0.9875 - val_loss: 2.0863 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2322 - binary_accuracy: 0.9875 - val_loss: 1.5581 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2680 - binary_accuracy: 0.9750 - val_loss: 0.4975 - val_binary_accuracy: 0.7125\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2451 - binary_accuracy: 1.0000 - val_loss: 0.5363 - val_binary_accuracy: 0.7250\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2601 - binary_accuracy: 0.9500 - val_loss: 0.8249 - val_binary_accuracy: 0.5375\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2510 - binary_accuracy: 0.9875 - val_loss: 0.5942 - val_binary_accuracy: 0.6500\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2365 - binary_accuracy: 0.9750 - val_loss: 0.7216 - val_binary_accuracy: 0.5375\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2678 - binary_accuracy: 0.9500 - val_loss: 3.2433 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.2424 - binary_accuracy: 0.9625 - val_loss: 5.6682 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2285 - binary_accuracy: 0.9750 - val_loss: 5.9348 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2656 - binary_accuracy: 0.9625 - val_loss: 5.4953 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2416 - binary_accuracy: 0.9625 - val_loss: 4.2975 - val_binary_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2523 - binary_accuracy: 0.9750 - val_loss: 3.1497 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2642 - binary_accuracy: 0.9625 - val_loss: 1.4607 - val_binary_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2413 - binary_accuracy: 0.9750 - val_loss: 0.8491 - val_binary_accuracy: 0.5000\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2516 - binary_accuracy: 0.9750 - val_loss: 0.3802 - val_binary_accuracy: 0.8625\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2571 - binary_accuracy: 0.9500 - val_loss: 0.3691 - val_binary_accuracy: 0.8500\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2494 - binary_accuracy: 0.9750 - val_loss: 0.4247 - val_binary_accuracy: 0.8125\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2431 - binary_accuracy: 0.9625 - val_loss: 1.2750 - val_binary_accuracy: 0.5000\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2498 - binary_accuracy: 0.9625 - val_loss: 2.9145 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - binary_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.91it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3334 - binary_accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3370 - binary_accuracy: 0.8500\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.8149 - binary_accuracy: 0.5000 - val_loss: 0.7642 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6532 - binary_accuracy: 0.6125 - val_loss: 0.7485 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5954 - binary_accuracy: 0.6875 - val_loss: 0.7204 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5286 - binary_accuracy: 0.8375 - val_loss: 0.7211 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.4908 - binary_accuracy: 0.8250 - val_loss: 0.9154 - val_binary_accuracy: 0.5125\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4603 - binary_accuracy: 0.8000 - val_loss: 1.3361 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4120 - binary_accuracy: 0.8500 - val_loss: 1.9848 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3981 - binary_accuracy: 0.8250 - val_loss: 2.7106 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3444 - binary_accuracy: 0.8750 - val_loss: 3.1101 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3314 - binary_accuracy: 0.8625 - val_loss: 2.9992 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3813 - binary_accuracy: 0.8375 - val_loss: 2.8003 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3269 - binary_accuracy: 0.8750 - val_loss: 2.8850 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3502 - binary_accuracy: 0.9250 - val_loss: 3.0253 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3243 - binary_accuracy: 0.8875 - val_loss: 3.1745 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3235 - binary_accuracy: 0.8875 - val_loss: 3.4632 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3041 - binary_accuracy: 0.8875 - val_loss: 3.9146 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2837 - binary_accuracy: 0.9250 - val_loss: 4.1020 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3243 - binary_accuracy: 0.8625 - val_loss: 4.5022 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3115 - binary_accuracy: 0.9125 - val_loss: 5.0784 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3038 - binary_accuracy: 0.8875 - val_loss: 5.7533 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2999 - binary_accuracy: 0.8875 - val_loss: 6.5300 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2823 - binary_accuracy: 0.9500 - val_loss: 6.8255 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2943 - binary_accuracy: 0.9125 - val_loss: 6.7496 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2855 - binary_accuracy: 0.9500 - val_loss: 6.3904 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2721 - binary_accuracy: 0.9250 - val_loss: 6.0052 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2597 - binary_accuracy: 0.9750 - val_loss: 5.5535 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2829 - binary_accuracy: 0.9500 - val_loss: 4.9221 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2777 - binary_accuracy: 0.9250 - val_loss: 4.1940 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2646 - binary_accuracy: 0.9625 - val_loss: 3.3665 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2959 - binary_accuracy: 0.9125 - val_loss: 2.7904 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2636 - binary_accuracy: 0.9375 - val_loss: 1.9140 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2959 - binary_accuracy: 0.9125 - val_loss: 1.0479 - val_binary_accuracy: 0.5250\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2736 - binary_accuracy: 0.9375 - val_loss: 0.7173 - val_binary_accuracy: 0.6125\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2561 - binary_accuracy: 0.9375 - val_loss: 0.6539 - val_binary_accuracy: 0.6875\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2704 - binary_accuracy: 0.9375 - val_loss: 0.6788 - val_binary_accuracy: 0.6375\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2840 - binary_accuracy: 0.9375 - val_loss: 0.6010 - val_binary_accuracy: 0.7625\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2690 - binary_accuracy: 0.9625 - val_loss: 0.6079 - val_binary_accuracy: 0.7625\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2813 - binary_accuracy: 0.9625 - val_loss: 0.5779 - val_binary_accuracy: 0.7750\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2734 - binary_accuracy: 0.9375 - val_loss: 0.5303 - val_binary_accuracy: 0.7625\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2960 - binary_accuracy: 0.9125 - val_loss: 0.5187 - val_binary_accuracy: 0.7125\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2793 - binary_accuracy: 0.9375 - val_loss: 0.5224 - val_binary_accuracy: 0.7250\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2677 - binary_accuracy: 0.9375 - val_loss: 0.5684 - val_binary_accuracy: 0.7250\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3245 - binary_accuracy: 0.8750 - val_loss: 0.6766 - val_binary_accuracy: 0.6250\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2685 - binary_accuracy: 0.9625 - val_loss: 0.7420 - val_binary_accuracy: 0.5250\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3045 - binary_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.95it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.79it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7281 - binary_accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6730 - binary_accuracy: 0.6375\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.7111 - binary_accuracy: 0.5500 - val_loss: 0.7806 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6614 - binary_accuracy: 0.5875 - val_loss: 0.7829 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6544 - binary_accuracy: 0.6375 - val_loss: 0.7787 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6279 - binary_accuracy: 0.7000 - val_loss: 0.7580 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6197 - binary_accuracy: 0.7625 - val_loss: 0.7313 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5728 - binary_accuracy: 0.8500 - val_loss: 0.6916 - val_binary_accuracy: 0.5625\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5689 - binary_accuracy: 0.8625 - val_loss: 0.8106 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5354 - binary_accuracy: 0.9500 - val_loss: 1.2875 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5127 - binary_accuracy: 0.9250 - val_loss: 1.8902 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4878 - binary_accuracy: 0.9125 - val_loss: 2.7243 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5036 - binary_accuracy: 0.8750 - val_loss: 3.3603 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4777 - binary_accuracy: 0.8625 - val_loss: 4.0447 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4544 - binary_accuracy: 0.9625 - val_loss: 4.6478 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4719 - binary_accuracy: 0.8875 - val_loss: 4.7724 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4557 - binary_accuracy: 0.9250 - val_loss: 4.6165 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4288 - binary_accuracy: 0.9125 - val_loss: 4.3001 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4373 - binary_accuracy: 0.9000 - val_loss: 4.2109 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4176 - binary_accuracy: 0.9625 - val_loss: 4.1207 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4049 - binary_accuracy: 0.9375 - val_loss: 3.9079 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4096 - binary_accuracy: 0.8750 - val_loss: 3.7189 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3884 - binary_accuracy: 0.9250 - val_loss: 3.6315 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4097 - binary_accuracy: 0.9000 - val_loss: 3.4548 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3950 - binary_accuracy: 0.9750 - val_loss: 3.1454 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4222 - binary_accuracy: 0.8750 - val_loss: 2.9032 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3817 - binary_accuracy: 0.9625 - val_loss: 2.5185 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3599 - binary_accuracy: 0.9500 - val_loss: 2.3531 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3654 - binary_accuracy: 0.9750 - val_loss: 2.2860 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3717 - binary_accuracy: 0.9750 - val_loss: 2.1483 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3678 - binary_accuracy: 0.9500 - val_loss: 2.0455 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3819 - binary_accuracy: 0.9375 - val_loss: 2.0391 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3636 - binary_accuracy: 0.9625 - val_loss: 2.1399 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3864 - binary_accuracy: 0.9500 - val_loss: 2.4562 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3827 - binary_accuracy: 0.9500 - val_loss: 2.7257 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3594 - binary_accuracy: 0.9250 - val_loss: 2.5261 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3552 - binary_accuracy: 0.9500 - val_loss: 2.0939 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3950 - binary_accuracy: 0.9125 - val_loss: 1.6910 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3681 - binary_accuracy: 0.9500 - val_loss: 1.3623 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3616 - binary_accuracy: 0.9250 - val_loss: 1.3200 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3672 - binary_accuracy: 0.9500 - val_loss: 1.3774 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3592 - binary_accuracy: 0.9375 - val_loss: 1.3748 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3461 - binary_accuracy: 0.9500 - val_loss: 1.4270 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3582 - binary_accuracy: 0.9625 - val_loss: 1.4229 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3642 - binary_accuracy: 0.9500 - val_loss: 1.2345 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3481 - binary_accuracy: 0.9375 - val_loss: 1.0194 - val_binary_accuracy: 0.4875\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3512 - binary_accuracy: 0.9750 - val_loss: 0.8906 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3723 - binary_accuracy: 0.9500 - val_loss: 0.9036 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3466 - binary_accuracy: 0.9625 - val_loss: 0.9415 - val_binary_accuracy: 0.4875\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3405 - binary_accuracy: 0.9375 - val_loss: 0.9705 - val_binary_accuracy: 0.4875\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3523 - binary_accuracy: 0.9375 - val_loss: 1.0279 - val_binary_accuracy: 0.4875\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3557 - binary_accuracy: 0.9250 - val_loss: 1.1031 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3530 - binary_accuracy: 0.9500 - val_loss: 1.3080 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3490 - binary_accuracy: 0.9500 - val_loss: 1.6567 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3690 - binary_accuracy: 0.9375 - val_loss: 1.8360 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3211 - binary_accuracy: 0.9375 - val_loss: 2.1401 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3131 - binary_accuracy: 0.9750 - val_loss: 2.4039 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3271 - binary_accuracy: 0.9500 - val_loss: 2.4563 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3342 - binary_accuracy: 0.9375 - val_loss: 2.2192 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3514 - binary_accuracy: 0.9250 - val_loss: 1.7008 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3366 - binary_accuracy: 0.9500 - val_loss: 1.2186 - val_binary_accuracy: 0.5000\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3609 - binary_accuracy: 0.9375 - val_loss: 1.1411 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3512 - binary_accuracy: 0.9625 - val_loss: 1.1275 - val_binary_accuracy: 0.5000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3164 - binary_accuracy: 0.9750 - val_loss: 0.9451 - val_binary_accuracy: 0.5000\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3582 - binary_accuracy: 0.9375 - val_loss: 1.0553 - val_binary_accuracy: 0.5000\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3334 - binary_accuracy: 0.9500 - val_loss: 1.1907 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3378 - binary_accuracy: 0.9625 - val_loss: 1.3255 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6942 - binary_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.88it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7009 - binary_accuracy: 0.6250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7667 - binary_accuracy: 0.6125\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7321 - binary_accuracy: 0.5500 - val_loss: 0.7166 - val_binary_accuracy: 0.5125\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6660 - binary_accuracy: 0.6125 - val_loss: 0.6910 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6211 - binary_accuracy: 0.6750 - val_loss: 0.6679 - val_binary_accuracy: 0.5625\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5854 - binary_accuracy: 0.7000 - val_loss: 0.6724 - val_binary_accuracy: 0.5500\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5532 - binary_accuracy: 0.7625 - val_loss: 0.7252 - val_binary_accuracy: 0.5500\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5400 - binary_accuracy: 0.6875 - val_loss: 0.8525 - val_binary_accuracy: 0.5375\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5576 - binary_accuracy: 0.6875 - val_loss: 1.0875 - val_binary_accuracy: 0.5125\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5121 - binary_accuracy: 0.7250 - val_loss: 1.4929 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5262 - binary_accuracy: 0.7250 - val_loss: 1.8845 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4948 - binary_accuracy: 0.7750 - val_loss: 2.2697 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5042 - binary_accuracy: 0.7625 - val_loss: 2.6351 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4926 - binary_accuracy: 0.8125 - val_loss: 2.9630 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4668 - binary_accuracy: 0.8000 - val_loss: 3.1391 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4762 - binary_accuracy: 0.7625 - val_loss: 3.4448 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4529 - binary_accuracy: 0.8375 - val_loss: 3.8842 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4312 - binary_accuracy: 0.8625 - val_loss: 4.2829 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4291 - binary_accuracy: 0.8625 - val_loss: 4.7787 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4490 - binary_accuracy: 0.8500 - val_loss: 5.1370 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4240 - binary_accuracy: 0.8125 - val_loss: 5.3187 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4411 - binary_accuracy: 0.8250 - val_loss: 5.3663 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4316 - binary_accuracy: 0.8375 - val_loss: 5.2668 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4318 - binary_accuracy: 0.8250 - val_loss: 5.2487 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4537 - binary_accuracy: 0.8500 - val_loss: 5.0485 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4351 - binary_accuracy: 0.8125 - val_loss: 4.9809 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4152 - binary_accuracy: 0.8500 - val_loss: 4.9210 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4212 - binary_accuracy: 0.8500 - val_loss: 5.1302 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4168 - binary_accuracy: 0.8750 - val_loss: 5.3124 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4163 - binary_accuracy: 0.8750 - val_loss: 5.3596 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4164 - binary_accuracy: 0.8500 - val_loss: 5.3033 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4252 - binary_accuracy: 0.8625 - val_loss: 5.4230 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4113 - binary_accuracy: 0.8750 - val_loss: 5.2859 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4152 - binary_accuracy: 0.8875 - val_loss: 5.3948 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4242 - binary_accuracy: 0.8875 - val_loss: 5.7513 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3941 - binary_accuracy: 0.8750 - val_loss: 5.8652 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3990 - binary_accuracy: 0.8625 - val_loss: 5.9168 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3971 - binary_accuracy: 0.9125 - val_loss: 6.0713 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3821 - binary_accuracy: 0.8750 - val_loss: 6.1475 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3995 - binary_accuracy: 0.8625 - val_loss: 6.1746 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3998 - binary_accuracy: 0.9000 - val_loss: 6.3122 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4221 - binary_accuracy: 0.8500 - val_loss: 6.6276 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3890 - binary_accuracy: 0.9500 - val_loss: 6.4458 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4027 - binary_accuracy: 0.8875 - val_loss: 6.0207 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4017 - binary_accuracy: 0.8875 - val_loss: 5.6760 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3938 - binary_accuracy: 0.8625 - val_loss: 4.9987 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3839 - binary_accuracy: 0.9250 - val_loss: 4.3527 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4196 - binary_accuracy: 0.8750 - val_loss: 3.8815 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4114 - binary_accuracy: 0.8500 - val_loss: 3.5355 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9088 - binary_accuracy: 0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.58it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.53it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6197 - binary_accuracy: 0.7125\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.7045 - binary_accuracy: 0.5375 - val_loss: 0.6822 - val_binary_accuracy: 0.5250\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6500 - binary_accuracy: 0.6125 - val_loss: 0.6698 - val_binary_accuracy: 0.5500\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6272 - binary_accuracy: 0.7375 - val_loss: 0.6548 - val_binary_accuracy: 0.6500\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5924 - binary_accuracy: 0.7625 - val_loss: 0.6648 - val_binary_accuracy: 0.5625\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5514 - binary_accuracy: 0.8750 - val_loss: 0.7999 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4996 - binary_accuracy: 0.8875 - val_loss: 1.3842 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4817 - binary_accuracy: 0.9125 - val_loss: 2.6823 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4326 - binary_accuracy: 0.9625 - val_loss: 4.7549 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4436 - binary_accuracy: 0.9625 - val_loss: 7.2114 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3996 - binary_accuracy: 0.9125 - val_loss: 9.6308 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4068 - binary_accuracy: 0.9250 - val_loss: 11.8966 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4004 - binary_accuracy: 0.9250 - val_loss: 13.8665 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3923 - binary_accuracy: 0.9500 - val_loss: 15.1690 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3791 - binary_accuracy: 0.9500 - val_loss: 16.0201 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3735 - binary_accuracy: 0.9500 - val_loss: 16.6105 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3694 - binary_accuracy: 0.9250 - val_loss: 16.2556 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3614 - binary_accuracy: 0.9500 - val_loss: 15.1391 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3484 - binary_accuracy: 0.9625 - val_loss: 13.8152 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3689 - binary_accuracy: 0.9500 - val_loss: 12.2570 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3240 - binary_accuracy: 1.0000 - val_loss: 10.0306 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3229 - binary_accuracy: 0.9750 - val_loss: 8.3631 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3519 - binary_accuracy: 0.9375 - val_loss: 7.2253 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3157 - binary_accuracy: 0.9500 - val_loss: 6.9481 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3777 - binary_accuracy: 0.9125 - val_loss: 6.5628 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3451 - binary_accuracy: 0.9375 - val_loss: 6.0737 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3106 - binary_accuracy: 0.9750 - val_loss: 5.3700 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3095 - binary_accuracy: 0.9875 - val_loss: 4.5189 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3358 - binary_accuracy: 0.9500 - val_loss: 4.0493 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3289 - binary_accuracy: 0.9375 - val_loss: 3.5043 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3158 - binary_accuracy: 0.9750 - val_loss: 3.3061 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3155 - binary_accuracy: 0.9750 - val_loss: 3.7090 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3217 - binary_accuracy: 0.9625 - val_loss: 4.2228 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3301 - binary_accuracy: 0.9625 - val_loss: 4.5517 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3166 - binary_accuracy: 0.9625 - val_loss: 5.0728 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3083 - binary_accuracy: 0.9625 - val_loss: 5.3385 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3124 - binary_accuracy: 0.9625 - val_loss: 5.8273 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3179 - binary_accuracy: 0.9875 - val_loss: 5.5067 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3141 - binary_accuracy: 0.9875 - val_loss: 4.8980 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3020 - binary_accuracy: 0.9750 - val_loss: 4.6329 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3369 - binary_accuracy: 0.9250 - val_loss: 4.2821 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3036 - binary_accuracy: 0.9500 - val_loss: 4.0513 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3201 - binary_accuracy: 0.9625 - val_loss: 3.7282 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3327 - binary_accuracy: 0.9500 - val_loss: 3.4828 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3155 - binary_accuracy: 0.9375 - val_loss: 3.3370 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2860 - binary_accuracy: 0.9875 - val_loss: 3.2431 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3144 - binary_accuracy: 0.9750 - val_loss: 3.0239 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3143 - binary_accuracy: 0.9500 - val_loss: 2.9982 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2968 - binary_accuracy: 0.9500 - val_loss: 2.7769 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2741 - binary_accuracy: 0.9750 - val_loss: 2.5864 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3032 - binary_accuracy: 0.9875 - val_loss: 2.6062 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3268 - binary_accuracy: 0.9250 - val_loss: 2.6161 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3100 - binary_accuracy: 0.9625 - val_loss: 2.5189 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3065 - binary_accuracy: 0.9875 - val_loss: 2.3979 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2964 - binary_accuracy: 0.9750 - val_loss: 2.3234 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3078 - binary_accuracy: 0.9875 - val_loss: 2.4419 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3077 - binary_accuracy: 1.0000 - val_loss: 2.5913 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2787 - binary_accuracy: 0.9750 - val_loss: 2.5790 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3180 - binary_accuracy: 0.9500 - val_loss: 2.0922 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3001 - binary_accuracy: 0.9375 - val_loss: 1.8465 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6351 - binary_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.55it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.59it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6945 - binary_accuracy: 0.5000\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.7791 - binary_accuracy: 0.5250 - val_loss: 0.6919 - val_binary_accuracy: 0.4875\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6874 - binary_accuracy: 0.5750 - val_loss: 0.6923 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6682 - binary_accuracy: 0.6500 - val_loss: 0.6868 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6407 - binary_accuracy: 0.7000 - val_loss: 0.6828 - val_binary_accuracy: 0.6125\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6419 - binary_accuracy: 0.6625 - val_loss: 0.6951 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6035 - binary_accuracy: 0.7625 - val_loss: 0.7785 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5977 - binary_accuracy: 0.8125 - val_loss: 1.1280 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5815 - binary_accuracy: 0.7500 - val_loss: 1.7696 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5611 - binary_accuracy: 0.8750 - val_loss: 2.4694 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5364 - binary_accuracy: 0.7500 - val_loss: 2.9232 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5388 - binary_accuracy: 0.8625 - val_loss: 2.9564 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5361 - binary_accuracy: 0.8125 - val_loss: 2.3942 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5055 - binary_accuracy: 0.8375 - val_loss: 1.8077 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4898 - binary_accuracy: 0.8625 - val_loss: 1.3837 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5086 - binary_accuracy: 0.7375 - val_loss: 1.1859 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5215 - binary_accuracy: 0.7625 - val_loss: 0.9544 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4884 - binary_accuracy: 0.8375 - val_loss: 0.8888 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4761 - binary_accuracy: 0.8125 - val_loss: 0.8583 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4566 - binary_accuracy: 0.8750 - val_loss: 0.7171 - val_binary_accuracy: 0.5625\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4702 - binary_accuracy: 0.8250 - val_loss: 0.6998 - val_binary_accuracy: 0.5375\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4798 - binary_accuracy: 0.8250 - val_loss: 0.8780 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4661 - binary_accuracy: 0.8375 - val_loss: 0.8937 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4398 - binary_accuracy: 0.9000 - val_loss: 0.7301 - val_binary_accuracy: 0.5625\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4405 - binary_accuracy: 0.9250 - val_loss: 0.6876 - val_binary_accuracy: 0.5750\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4471 - binary_accuracy: 0.8375 - val_loss: 0.7756 - val_binary_accuracy: 0.5375\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4415 - binary_accuracy: 0.8500 - val_loss: 0.9194 - val_binary_accuracy: 0.5125\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4323 - binary_accuracy: 0.8625 - val_loss: 0.9730 - val_binary_accuracy: 0.5125\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4448 - binary_accuracy: 0.8625 - val_loss: 1.1051 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4627 - binary_accuracy: 0.8250 - val_loss: 1.1086 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4077 - binary_accuracy: 0.9000 - val_loss: 1.2002 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4217 - binary_accuracy: 0.8750 - val_loss: 1.3775 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4270 - binary_accuracy: 0.9000 - val_loss: 1.2882 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4261 - binary_accuracy: 0.8500 - val_loss: 1.2034 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3971 - binary_accuracy: 0.9125 - val_loss: 1.0282 - val_binary_accuracy: 0.5125\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4403 - binary_accuracy: 0.8875 - val_loss: 0.9328 - val_binary_accuracy: 0.5250\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3975 - binary_accuracy: 0.9250 - val_loss: 0.7723 - val_binary_accuracy: 0.5625\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4122 - binary_accuracy: 0.8750 - val_loss: 0.7188 - val_binary_accuracy: 0.5250\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4002 - binary_accuracy: 0.9125 - val_loss: 0.7021 - val_binary_accuracy: 0.5250\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3808 - binary_accuracy: 0.9125 - val_loss: 0.7067 - val_binary_accuracy: 0.5250\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4157 - binary_accuracy: 0.8750 - val_loss: 0.7412 - val_binary_accuracy: 0.5375\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4102 - binary_accuracy: 0.9000 - val_loss: 0.8201 - val_binary_accuracy: 0.5500\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4395 - binary_accuracy: 0.8375 - val_loss: 1.0370 - val_binary_accuracy: 0.5125\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3930 - binary_accuracy: 0.9250 - val_loss: 1.2650 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4165 - binary_accuracy: 0.8875 - val_loss: 1.3052 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3657 - binary_accuracy: 0.9500 - val_loss: 1.1244 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3922 - binary_accuracy: 0.9000 - val_loss: 1.0051 - val_binary_accuracy: 0.5125\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3591 - binary_accuracy: 0.9250 - val_loss: 0.8143 - val_binary_accuracy: 0.5125\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4121 - binary_accuracy: 0.9000 - val_loss: 0.6983 - val_binary_accuracy: 0.6125\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3783 - binary_accuracy: 0.9500 - val_loss: 0.7697 - val_binary_accuracy: 0.5500\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3983 - binary_accuracy: 0.8875 - val_loss: 0.7699 - val_binary_accuracy: 0.5500\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3358 - binary_accuracy: 0.9750 - val_loss: 0.7405 - val_binary_accuracy: 0.5500\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3570 - binary_accuracy: 0.9250 - val_loss: 0.6843 - val_binary_accuracy: 0.6125\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3936 - binary_accuracy: 0.9000 - val_loss: 0.7345 - val_binary_accuracy: 0.5250\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3370 - binary_accuracy: 0.9500 - val_loss: 0.9199 - val_binary_accuracy: 0.5125\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3505 - binary_accuracy: 0.9625 - val_loss: 1.0865 - val_binary_accuracy: 0.5125\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3656 - binary_accuracy: 0.9125 - val_loss: 1.1182 - val_binary_accuracy: 0.5125\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3516 - binary_accuracy: 0.9125 - val_loss: 1.3099 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3833 - binary_accuracy: 0.9375 - val_loss: 1.3164 - val_binary_accuracy: 0.5125\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3628 - binary_accuracy: 0.9125 - val_loss: 1.3083 - val_binary_accuracy: 0.5125\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3737 - binary_accuracy: 0.9375 - val_loss: 1.3290 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3557 - binary_accuracy: 0.9375 - val_loss: 1.4264 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6970 - binary_accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.58it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4938 - binary_accuracy: 0.8500\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.7229 - binary_accuracy: 0.5125 - val_loss: 0.6826 - val_binary_accuracy: 0.5875\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.6666 - binary_accuracy: 0.6375 - val_loss: 0.7423 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6125 - binary_accuracy: 0.7125 - val_loss: 1.1480 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5508 - binary_accuracy: 0.8250 - val_loss: 1.9887 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5256 - binary_accuracy: 0.8250 - val_loss: 2.9890 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4639 - binary_accuracy: 0.8375 - val_loss: 3.6575 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4410 - binary_accuracy: 0.8625 - val_loss: 3.8981 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3936 - binary_accuracy: 0.9000 - val_loss: 4.1709 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3899 - binary_accuracy: 0.9000 - val_loss: 4.2980 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3786 - binary_accuracy: 0.8750 - val_loss: 4.0445 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3691 - binary_accuracy: 0.8875 - val_loss: 3.7268 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3617 - binary_accuracy: 0.8750 - val_loss: 3.0271 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3882 - binary_accuracy: 0.8375 - val_loss: 2.4487 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3542 - binary_accuracy: 0.8250 - val_loss: 2.1463 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3547 - binary_accuracy: 0.8625 - val_loss: 1.7693 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3304 - binary_accuracy: 0.8750 - val_loss: 1.4575 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3226 - binary_accuracy: 0.9250 - val_loss: 1.2320 - val_binary_accuracy: 0.5125\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3224 - binary_accuracy: 0.9125 - val_loss: 1.4670 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3166 - binary_accuracy: 0.8875 - val_loss: 1.9697 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3204 - binary_accuracy: 0.9375 - val_loss: 2.3418 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2934 - binary_accuracy: 0.9250 - val_loss: 2.5745 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3349 - binary_accuracy: 0.9000 - val_loss: 2.5952 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2851 - binary_accuracy: 0.9500 - val_loss: 2.4237 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3294 - binary_accuracy: 0.9125 - val_loss: 2.3065 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2903 - binary_accuracy: 0.9500 - val_loss: 2.6614 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3108 - binary_accuracy: 0.9500 - val_loss: 3.3431 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2677 - binary_accuracy: 0.9625 - val_loss: 3.8865 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3096 - binary_accuracy: 0.9750 - val_loss: 3.9651 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2889 - binary_accuracy: 0.9125 - val_loss: 3.6119 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2812 - binary_accuracy: 0.9375 - val_loss: 3.3357 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3049 - binary_accuracy: 0.9500 - val_loss: 2.8189 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2867 - binary_accuracy: 0.9500 - val_loss: 1.7108 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2884 - binary_accuracy: 0.9500 - val_loss: 1.3585 - val_binary_accuracy: 0.5250\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2785 - binary_accuracy: 0.9375 - val_loss: 1.4196 - val_binary_accuracy: 0.5250\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3016 - binary_accuracy: 0.9500 - val_loss: 1.2722 - val_binary_accuracy: 0.5375\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3333 - binary_accuracy: 0.9125 - val_loss: 1.5542 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2831 - binary_accuracy: 0.9500 - val_loss: 1.9245 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4876 - binary_accuracy: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n",
      "epoching: 100%|██████████| 2/2 [00:00<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7043 - binary_accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6828 - binary_accuracy: 0.5625\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.7481 - binary_accuracy: 0.5125 - val_loss: 0.7251 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6910 - binary_accuracy: 0.5375 - val_loss: 0.7521 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6783 - binary_accuracy: 0.6000 - val_loss: 0.7421 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6692 - binary_accuracy: 0.6250 - val_loss: 0.7201 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6484 - binary_accuracy: 0.6625 - val_loss: 0.7008 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6271 - binary_accuracy: 0.7000 - val_loss: 0.7001 - val_binary_accuracy: 0.4875\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6115 - binary_accuracy: 0.6250 - val_loss: 0.7554 - val_binary_accuracy: 0.5125\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6266 - binary_accuracy: 0.7000 - val_loss: 0.9822 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5718 - binary_accuracy: 0.7375 - val_loss: 1.4023 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5663 - binary_accuracy: 0.7125 - val_loss: 1.7630 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5965 - binary_accuracy: 0.7500 - val_loss: 2.1597 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5441 - binary_accuracy: 0.7625 - val_loss: 2.6305 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5694 - binary_accuracy: 0.7125 - val_loss: 3.1812 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5753 - binary_accuracy: 0.7625 - val_loss: 3.5863 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5433 - binary_accuracy: 0.7750 - val_loss: 3.7549 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5076 - binary_accuracy: 0.8375 - val_loss: 3.8297 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4767 - binary_accuracy: 0.8625 - val_loss: 3.9968 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5020 - binary_accuracy: 0.8000 - val_loss: 3.9791 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5084 - binary_accuracy: 0.8000 - val_loss: 4.0767 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4624 - binary_accuracy: 0.8375 - val_loss: 4.2044 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4850 - binary_accuracy: 0.8250 - val_loss: 4.3212 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5079 - binary_accuracy: 0.8000 - val_loss: 4.3431 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4732 - binary_accuracy: 0.8500 - val_loss: 4.2916 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4777 - binary_accuracy: 0.8500 - val_loss: 4.2332 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4517 - binary_accuracy: 0.8750 - val_loss: 4.2884 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4420 - binary_accuracy: 0.8500 - val_loss: 4.4124 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4453 - binary_accuracy: 0.8750 - val_loss: 4.2368 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4391 - binary_accuracy: 0.8875 - val_loss: 4.2512 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3930 - binary_accuracy: 0.9000 - val_loss: 3.9942 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4184 - binary_accuracy: 0.9000 - val_loss: 4.1214 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4092 - binary_accuracy: 0.9000 - val_loss: 4.2689 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4169 - binary_accuracy: 0.8750 - val_loss: 4.1612 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4270 - binary_accuracy: 0.8375 - val_loss: 4.2190 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4131 - binary_accuracy: 0.8875 - val_loss: 4.2282 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3988 - binary_accuracy: 0.8625 - val_loss: 4.1744 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4096 - binary_accuracy: 0.8875 - val_loss: 4.0678 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3984 - binary_accuracy: 0.9000 - val_loss: 3.8457 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3787 - binary_accuracy: 0.9125 - val_loss: 4.0778 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3913 - binary_accuracy: 0.9000 - val_loss: 4.1290 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3917 - binary_accuracy: 0.8625 - val_loss: 3.9745 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3910 - binary_accuracy: 0.8750 - val_loss: 3.5799 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3811 - binary_accuracy: 0.9000 - val_loss: 3.4975 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3838 - binary_accuracy: 0.9250 - val_loss: 3.4930 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3739 - binary_accuracy: 0.9125 - val_loss: 3.1365 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3448 - binary_accuracy: 0.9125 - val_loss: 2.9507 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3538 - binary_accuracy: 0.9500 - val_loss: 2.9536 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3469 - binary_accuracy: 0.9375 - val_loss: 3.2578 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3283 - binary_accuracy: 0.9625 - val_loss: 3.2531 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3496 - binary_accuracy: 0.9000 - val_loss: 3.2132 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3610 - binary_accuracy: 0.8750 - val_loss: 3.2176 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3413 - binary_accuracy: 0.9250 - val_loss: 3.9423 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3439 - binary_accuracy: 0.9250 - val_loss: 4.6176 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3491 - binary_accuracy: 0.9000 - val_loss: 5.3310 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3455 - binary_accuracy: 0.9125 - val_loss: 5.6939 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3539 - binary_accuracy: 0.8750 - val_loss: 5.9181 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3474 - binary_accuracy: 0.9125 - val_loss: 5.8614 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3634 - binary_accuracy: 0.8125 - val_loss: 5.5400 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3355 - binary_accuracy: 0.9125 - val_loss: 5.1157 - val_binary_accuracy: 0.5000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7133 - binary_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = pd.DataFrame( index=valid_dataset ,  columns= [\"base\", \"fine_tuned\"])\n",
    "\n",
    "for key in valid_dataset :\n",
    "\n",
    "    # extrait les données à partir de mne\n",
    "    # les converties en CSV\n",
    "\n",
    "    key_valid_train  = create_key([key] , train = 1 , test = 0 )\n",
    "    key_valid_test  = create_key([key] , train = 0 , test = 1 )\n",
    "\n",
    "\n",
    "    mask =np.array([True,False] *  int(key_valid_test.shape[0]/2))\n",
    "    np.random.shuffle(mask)\n",
    "    key_test = key_valid_test[mask]\n",
    "    key_valid = key_valid_test[~mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_valid_train, Y_valid_train = epoching(dic_data,key_valid_train, steps_preprocess)\n",
    "    X_valid, Y_valid = epoching(dic_data,key_valid, steps_preprocess)\n",
    "    X_test, Y_test = epoching(dic_data,key_test, steps_preprocess)\n",
    "\n",
    "\n",
    "    # read the model\n",
    "\n",
    "    model = load_model(directory_model)\n",
    "    accuracy.base[key]= model.evaluate(X_test, Y_test)[1]\n",
    "\n",
    "    #Fine tune le model sur le train\n",
    "\n",
    "    # Allow to finetuned te model only on some layers\n",
    "    for layer in model.layers :\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.layers[-2].trainable = True   # last layer Dense\n",
    "    #reset the weight of the layers\n",
    "\n",
    "    ix = -2\n",
    "    layer = model.layers[-2]\n",
    "    if hasattr(model.layers[ix], 'kernel_initializer') and hasattr(model.layers[ix], 'bias_initializer'):\n",
    "        weight_initializer = model.layers[ix].kernel_initializer\n",
    "        bias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "        old_weights, old_biases = model.layers[ix].get_weights()\n",
    "\n",
    "        model.layers[ix].set_weights([\n",
    "            weight_initializer(shape=old_weights.shape),\n",
    "            bias_initializer(shape=len(old_biases))])\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(x = X_valid_train, y = Y_valid_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = n_epochs ,\n",
    "              callbacks= my_callbacks,\n",
    "              validation_data= (X_valid,Y_valid))\n",
    "\n",
    "    # Test le model\n",
    "\n",
    "    model = load_model(\"./model/best_model_finetuned.h5\")\n",
    "\n",
    "    #enregistre l'accuracy\n",
    "    accuracy.fine_tuned[key]= model.evaluate(X_test, Y_test)[1]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "for layer in model.layers[0:5] :\n",
    "    layer.trainable = False\n",
    "\n",
    "model.layers[-2].trainable = True   # last layer Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 27, 1024, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 27, 1024, 8)       512       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 27, 1024, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthwi  (None, 1, 1024, 16)      432       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1, 1024, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 1024, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 1, 256, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d (SpatialD  (None, 1, 256, 16)       0         \n",
      " ropout2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 1, 256, 16)       512       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1, 256, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 256, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 1, 32, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d_1 (Spatia  (None, 1, 32, 16)        0         \n",
      " lDropout2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 1026      \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,642\n",
      "Trainable params: 1,570\n",
      "Non-trainable params: 1,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "data2.to_csv(\"./results/temporary_acc.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "{(19, 23): ['A25',\n  'A26',\n  'A56',\n  'B63',\n  'B65',\n  'B68',\n  'B70',\n  'B75',\n  'B76',\n  'B78',\n  'C84',\n  'C86',\n  'C87'],\n (23, 24): ['A7',\n  'A10',\n  'A11',\n  'A13',\n  'A17',\n  'A29',\n  'A48',\n  'A50',\n  'A52',\n  'B71',\n  'B81',\n  'C83'],\n (24, 27): ['A9',\n  'A14',\n  'A16',\n  'A18',\n  'A20',\n  'A23',\n  'A28',\n  'A30',\n  'A39',\n  'A42',\n  'A55',\n  'A57',\n  'A58',\n  'B74',\n  'B79',\n  'B80',\n  'C82'],\n (27, 30): ['A1',\n  'A2',\n  'A8',\n  'A12',\n  'A33',\n  'A34',\n  'A35',\n  'A46',\n  'A53',\n  'A59',\n  'B61',\n  'B72',\n  'C85'],\n (30, 40): ['A4',\n  'A5',\n  'A15',\n  'A19',\n  'A21',\n  'A22',\n  'A24',\n  'A27',\n  'A36',\n  'A41',\n  'A44',\n  'A47',\n  'A49',\n  'A54',\n  'B64',\n  'B69'],\n (40, 62): ['A3',\n  'A6',\n  'A31',\n  'A32',\n  'A37',\n  'A38',\n  'A43',\n  'A45',\n  'A51',\n  'A60',\n  'B66',\n  'B67',\n  'B73',\n  'B77']}"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_age"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "winsound.Beep(440, 500)\n",
    "winsound.Beep(330, 400)\n",
    "winsound.Beep(550, 500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Comparaison des performances entre deux models')"
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inline_accuracy = [84.375,55.625,98.125,51.25,51.25,65.625,47.5,56.225,66.25,82.5,51.875,60,65,49.375,75.625,49.375,45.625,82.5,98.125,83.125,56.875,88.75,51.875,93.125,81.25,65.625,45.625,48.125,52.5, 40.625, 52.5, 55.5, 62.5, 48.125, 90.625, 70, 47.5, 62.5, 81.25, 49.0625, 51.875, 51.875, 55, 56.25, 54.375, 54.375, 46.25, 56.625, 55, 52.5, 64.375, 88.75, 46.25, 47.5, 91.875, 99.375, 48.75, 66.25, 60, 56.25, 84.375, 90.625, 60, 50, 82.5, 58.75, 51.875, 55, 60.625, 55.625, 47.5, 44.375, 86.25, 68.125, 71.875, 80.625, 53.75, 55, 97.5, 49.375, 55, 49.375, 44.375, 76.25, 80.625, 62.5 ,73.125]\n",
    "\n",
    "inline_order = [\"A1\"  ,\"A2\" ,\"A3\" ,\"A4\" ,\"A5\" ,\"A6\" ,\"A7\" ,\"A8\" ,\"A9\" ,\"A10\" ,\"A11\" ,\"A12\" ,\"A13\" ,\"A14\" ,\"A15\" ,\"A16\" ,\"A17\" ,\"A18\" ,\"A19\" ,\"A20\" ,\"A21\" ,\"A22\" ,\"A23\" ,\"A24\" ,\"A25\" ,\"A26\" ,\"A27\" ,\"A28\" ,\"A29\" ,\"A30\" ,\"A31\" ,\"A32\" ,\"A33\" ,\"A34\" ,\"A35\" ,\"A36\" ,\"A37\" ,\"A38\" ,\"A39\" ,\"A40\" ,\"A41\" ,\"A42\" ,\"A43\" ,\"A44\" ,\"A45\" ,\"A46\" ,\"A47\" ,\"A48\" ,\"A49\" ,\"A50\" ,\"A51\" ,\"A52\" ,\"A53\" ,\"A54\" ,\"A55\" ,\"A56\" ,\"A57\" ,\"A58\" ,\"A59\" ,\"A60\" ,\"B61\" ,\"B62\" ,\"B63\" ,\"B64\" ,\"B65\" ,\"B66\" ,\"B67\" ,\"B68\" ,\"B69\" ,\"B70\" ,\"B71\" ,\"B72\" ,\"B73\" ,\"B74\" ,\"B75\" ,\"B76\" ,\"B77\" ,\"B78\" ,\"B79\" ,\"B80\" ,\"B81\" ,\"C82\" ,\"C83\" ,\"C84\" ,\"C85\" ,\"C86\" ,\"C87\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inline_results = pd.DataFrame(inline_accuracy, inline_order, columns= [\"inline\"])\n",
    "inline_results = inline_results/100\n",
    "\n",
    "accuracy[\"inline\"] = inline_results[\"inline\"][accuracy.index]\n",
    "\n",
    "ax1 = accuracy.plot.scatter(x='inline',y='fine_tuned', c='DarkBlue')\n",
    "ax1.plot([0.4,1],[0.4,1], c=\"red\")\n",
    "ax1.set_title(\"Comparaison des performances entre deux models\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 27, 1024, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 27, 1024, 8)       512       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 27, 1024, 8)      32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthwi  (None, 1, 1024, 16)      432       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1, 1024, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 1024, 16)       0         \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 1, 256, 16)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d (SpatialD  (None, 1, 256, 16)       0         \n",
      " ropout2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 1, 256, 16)       512       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1, 256, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 256, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 1, 32, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d_1 (Spatia  (None, 1, 32, 16)        0         \n",
      " lDropout2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 1026      \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,642\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [234]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m5\u001B[39m]\u001B[38;5;241m.\u001B[39mtrainable\u001B[38;5;241m=\u001B[39m  \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'trainable'"
     ]
    }
   ],
   "source": [
    "\n",
    "flatten      = Flatten(name = 'flatten')(block2)\n",
    "\n",
    "dense        = Dense(nb_classes, name = 'dense',\n",
    "                     kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "softmax      = Activation('softmax', name = 'softmax')(dense)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01889907 -0.0188991 ]\n",
      "[0.05963019 0.09490354]\n"
     ]
    }
   ],
   "source": [
    "model = load_model(directory_model)\n",
    "print(model.layers[-2].get_weights()[0][0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model.layers[-2].get_weights()[0][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6624 - binary_accuracy: 0.5750\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6624225378036499, 0.574999988079071]"
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = X_valid_train, y = Y_valid_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.01889907, -0.0188991 ],\n       [-0.00867759,  0.00867755],\n       [-0.01202742,  0.01202741],\n       ...,\n       [ 0.00725783, -0.00725794],\n       [ 0.01566049, -0.01566039],\n       [ 0.00198506, -0.00198509]], dtype=float32)"
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-2].get_weights()[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if hasattr(layer, 'kernel_initializer'):\n",
    "    layer.kernel.initializer.run(session=session)\n",
    "if hasattr(layer, 'bias_initializer'):\n",
    "    layer.bias.initializer.run(session=session)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "winsound.Beep(440, 5000)\n",
    "winsound.Beep(330, 4000)\n",
    "winsound.Beep(550, 5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "inline_accuracy = [84.375, 55.625, 98.125, 51.25, 51.25, 65.625, 47.5, 56.225, 66.25, 82.5, 51.875, 60, 65, 49.375,\n",
    "                   75.625, 49.375, 45.625, 82.5, 98.125, 83.125, 56.875, 88.75, 51.875, 93.125, 81.25, 65.625, 45.625,\n",
    "                   48.125, 52.5, 40.625, 52.5, 55.5, 62.5, 48.125, 90.625, 70, 47.5, 62.5, 81.25, 49.0625, 51.875,\n",
    "                   51.875, 55, 56.25, 54.375, 54.375, 46.25, 56.625, 55, 52.5, 64.375, 88.75, 46.25, 47.5, 91.875,\n",
    "                   99.375, 48.75, 66.25, 60, 56.25, 84.375, 90.625, 60, 50, 82.5, 58.75, 51.875, 55, 60.625, 55.625,\n",
    "                   47.5, 44.375, 86.25, 68.125, 71.875, 80.625, 53.75, 55, 97.5, 49.375, 55, 49.375, 44.375, 76.25,\n",
    "                   80.625, 62.5, 73.125]\n",
    "\n",
    "inline_order = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\",\n",
    "                \"A17\", \"A18\", \"A19\", \"A20\", \"A21\", \"A22\", \"A23\", \"A24\", \"A25\", \"A26\", \"A27\", \"A28\", \"A29\", \"A30\", \"A31\",\n",
    "                \"A32\", \"A33\", \"A34\", \"A35\", \"A36\", \"A37\", \"A38\", \"A39\", \"A40\", \"A41\", \"A42\", \"A43\", \"A44\", \"A45\", \"A46\",\n",
    "                \"A47\", \"A48\", \"A49\", \"A50\", \"A51\", \"A52\", \"A53\", \"A54\", \"A55\", \"A56\", \"A57\", \"A58\", \"A59\", \"A60\", \"B61\",\n",
    "                \"B62\", \"B63\", \"B64\", \"B65\", \"B66\", \"B67\", \"B68\", \"B69\", \"B70\", \"B71\", \"B72\", \"B73\", \"B74\", \"B75\", \"B76\",\n",
    "                \"B77\", \"B78\", \"B79\", \"B80\", \"B81\", \"C82\", \"C83\", \"C84\", \"C85\", \"C86\", \"C87\"]\n",
    "\n",
    "inline_age = [1993, 1993, 1969, 1982, 1985, 1970, 1997, 1992, 1996, 1997, 1997, 1993, 1997, 1994, 1988, 1996, 1997,\n",
    "              1995, 1985, 1996, 1988, 1989, 1994, 1985, 1999, 1998, 1981, 1995, 1997, 1996, 1978, 1969, 1992, 1993,\n",
    "              1993, 1990, 1959, 1973, 1996, 1999, 1989, 1994, 1980, 1988, 1977, 1993, 1990, 1997, 1981, 1997, 1975,\n",
    "              1997, 1991, 1989, 1996, 1998, 1996, 1996, 1991, 1968, 1992, 2002, 2000, 1985, 1998, 1979, 1978, 1999,\n",
    "              1984, 1998, 1997, 1993, 1969, 1996, 1998, 1998, 1978, 1999, 1994, 1995, 1997, 1995, 1997, 2001, 1991,\n",
    "              2000, 2000]\n",
    "data = pd.DataFrame({\"accuracy\": inline_accuracy, \"age\": inline_age}, index=[inline_order])\n",
    "data[\"age\"] = 2021 - data[\"age\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "age_cat = [(19, 23), (23, 25), (25,30), (30,40), (40, 61)]\n",
    "\n",
    "dict_age =  {}\n",
    "for age_min, age_max in age_cat :\n",
    "\n",
    "    dict_age[(age_min,age_max)] = list(data[np.logical_and(data[\"age\"] > age_min , data[\"age\"] <= age_max)].index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "21\n",
      "21\n",
      "16\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for val in dict_age.values():\n",
    "    print(len(val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shalllow FBCSP net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}